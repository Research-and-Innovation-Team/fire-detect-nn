{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/tomek-l/fire-detect-nn/blob/master/train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_hYGCymn0wW7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded 114 training batches and 13 validation batches\n"
     ]
    }
   ],
   "source": [
    "from model import Model, load_dataset, accuracy\n",
    "import numpy as np\n",
    "\n",
    "BACKBONES = ['resnet18','resnet34','resnet50','resnet101', 'densenet121', 'mobilenet']\n",
    "BACKBONES = ['resnet50'] # override with just one backbone\n",
    "\n",
    "# dunnings dataset: /home/013855803/fire-dataset-dunnings/images-224x224/train\n",
    "train, valid = load_dataset()\n",
    "print(f'loaded {len(train)} training batches and {len(valid)} validation batches')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, valid = list(train), list(valid) # completely memory extravagant but I have 256GB of RAM to use :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lwJwVugdDpEj"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1, batch: 19, loss: 0.6273656368255616, accuracy: 0.66875\n",
      "epoch: 1, batch: 39, loss: 0.5548934042453766, accuracy: 0.7765625\n",
      "epoch: 1, batch: 59, loss: 0.4898707032203674, accuracy: 0.821875\n",
      "epoch: 1, batch: 79, loss: 0.4304869767278433, accuracy: 0.85703125\n",
      "epoch: 1, batch: 99, loss: 0.3787643563747406, accuracy: 0.88125\n",
      "validation accuracy 0.9615\n",
      "Saved weights/resnet50-epoch-0-acc=0.9615.pt\n",
      "epoch: 2, batch: 19, loss: 0.11945381164550781, accuracy: 0.971875\n",
      "epoch: 2, batch: 39, loss: 0.13745041200891137, accuracy: 0.965625\n",
      "epoch: 2, batch: 59, loss: 0.12884291981657345, accuracy: 0.9666666666666667\n",
      "epoch: 2, batch: 79, loss: 0.11534449709579349, accuracy: 0.9734375\n",
      "epoch: 2, batch: 99, loss: 0.10198679959401488, accuracy: 0.978125\n",
      "validation accuracy 0.9712\n",
      "Saved weights/resnet50-epoch-1-acc=0.9712.pt\n",
      "epoch: 3, batch: 19, loss: 0.03770665731281042, accuracy: 0.996875\n",
      "epoch: 3, batch: 39, loss: 0.04911119150929153, accuracy: 0.990625\n",
      "epoch: 3, batch: 59, loss: 0.046454917375619215, accuracy: 0.9916666666666667\n",
      "epoch: 3, batch: 79, loss: 0.041794271010439844, accuracy: 0.99296875\n",
      "epoch: 3, batch: 99, loss: 0.03802416090853512, accuracy: 0.99375\n",
      "validation accuracy 0.9712\n",
      "Saved weights/resnet50-epoch-2-acc=0.9712.pt\n",
      "epoch: 4, batch: 19, loss: 0.015725807240232825, accuracy: 1.0\n",
      "epoch: 4, batch: 39, loss: 0.02323325739707798, accuracy: 0.9984375\n",
      "epoch: 4, batch: 59, loss: 0.023500568264474473, accuracy: 0.9979166666666667\n",
      "epoch: 4, batch: 79, loss: 0.021074482513358816, accuracy: 0.9984375\n",
      "epoch: 4, batch: 99, loss: 0.019591378746554255, accuracy: 0.998125\n",
      "validation accuracy 0.9808\n",
      "Saved weights/resnet50-epoch-3-acc=0.9808.pt\n",
      "epoch: 5, batch: 19, loss: 0.008693577104713768, accuracy: 1.0\n",
      "epoch: 5, batch: 39, loss: 0.013903055415721611, accuracy: 0.9984375\n",
      "epoch: 5, batch: 59, loss: 0.014743856069010993, accuracy: 0.9979166666666667\n",
      "epoch: 5, batch: 79, loss: 0.013303945917868987, accuracy: 0.9984375\n",
      "epoch: 5, batch: 99, loss: 0.012517309363465757, accuracy: 0.998125\n",
      "validation accuracy 0.9808\n",
      "Saved weights/resnet50-epoch-4-acc=0.9808.pt\n",
      "epoch: 6, batch: 19, loss: 0.005685307644307613, accuracy: 1.0\n",
      "epoch: 6, batch: 39, loss: 0.00914438783074729, accuracy: 0.9984375\n",
      "epoch: 6, batch: 59, loss: 0.009838881983887405, accuracy: 0.9979166666666667\n",
      "epoch: 6, batch: 79, loss: 0.009020384366158396, accuracy: 0.9984375\n",
      "epoch: 6, batch: 99, loss: 0.008296774136833846, accuracy: 0.99875\n",
      "validation accuracy 0.9856\n",
      "Saved weights/resnet50-epoch-5-acc=0.9856.pt\n",
      "Finished Training: resnet50\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "device = torch.device(\"cuda:0\")\n",
    "validate = True\n",
    "for b in BACKBONES:\n",
    "\n",
    "    import torch.optim as optim\n",
    "\n",
    "    m = Model(backbone=b)\n",
    "    m = m.to(device)\n",
    "\n",
    "    criterion = torch.nn.BCELoss()\n",
    "    optimizer = optim.Adam(m.parameters(), lr=1e-5, weight_decay=1e-5)\n",
    "\n",
    "    for epoch in range(6):  # epochs\n",
    "\n",
    "        running_loss = []\n",
    "        running_acc = []\n",
    "\n",
    "        # epoch training\n",
    "        for i, data in enumerate(train):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            inputs = data[0].to(device)\n",
    "            labels = data[1].to(device)\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = m(inputs)\n",
    "            loss = criterion(outputs[:,0], labels.type_as(outputs[:,0]))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            acc = accuracy(outputs, labels)\n",
    "            # print statistics\n",
    "            \n",
    "            running_loss.append(loss.item())\n",
    "            running_acc.append(acc)\n",
    "\n",
    "            if i%20 == 19: print(f'epoch: {epoch+1}, batch: {i}, loss: {np.mean(running_loss)}, accuracy: {np.mean(running_acc)}')\n",
    "        \n",
    "        if validate:\n",
    "            valid_acc = []\n",
    "            # epoch validation\n",
    "            for i, data in enumerate(valid):\n",
    "                # get the inputs; data is a list of [inputs, labels]\n",
    "                inputs = data[0].to(device)\n",
    "                labels = data[1].to(device)\n",
    "\n",
    "                # could pehaps do:\n",
    "                # for param in m.parameters():\n",
    "                #     param.requires_grad = False\n",
    "\n",
    "                outputs = m(inputs)\n",
    "                valid_acc.append(accuracy(outputs, labels))\n",
    "            va = round(np.mean(valid_acc), 4)\n",
    "            print(f'validation accuracy {va}')\n",
    "        else:\n",
    "            va = '-1'\n",
    "        fname =  f'weights/{b}-epoch-{epoch}-acc={va}.pt'\n",
    "        print(f'Saved {fname}')\n",
    "        torch.save(m, fname)\n",
    "        \n",
    "\n",
    "    print(f'Finished Training: {b}')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "train-pytorch",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
