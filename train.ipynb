{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/tomek-l/fire-detect-nn/blob/master/train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_hYGCymn0wW7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded 1317 training batches and 147 validation batches\n",
      "loaded 184 test batches\n"
     ]
    }
   ],
   "source": [
    "from model import Model, load_dataset, accuracy\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "BACKBONES = ['resnet18','resnet34','resnet50','resnet101', 'densenet121', 'mobilenet']\n",
    "#BACKBONES = ['resnet50'] # override with just one backbone\n",
    "\n",
    "dataset_paths = {'mine': '/home/013855803/fire_aerial2k_dataset/',\n",
    "                 'dunnings': '/home/013855803/fire-dataset-dunnings/images-224x224/train',\n",
    "                 'dunnings_test': '/home/013855803/fire-dataset-dunnings/images-224x224/test'}\n",
    "\n",
    "train, valid = load_dataset(dataset_paths['dunnings'])\n",
    "\n",
    "tr = torchvision.transforms.Compose([torchvision.transforms.Resize((224,224)),\n",
    "                            torchvision.transforms.ToTensor()])\n",
    "\n",
    "test_dataset = torchvision.datasets.ImageFolder(root=dataset_paths['dunnings_test'],\n",
    "                                                transform=tr)\n",
    "\n",
    "\n",
    "test = torch.utils.data.DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=16,\n",
    "    num_workers=0,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "print(f'loaded {len(train)} training batches and {len(valid)} validation batches')\n",
    "print(f'loaded {len(test)} test batches')\n",
    "\n",
    "# Can be useful if we're retraining many times on the entire dataset\n",
    "# completely memory extravagant but I have 256GB of RAM to use :)\n",
    "# train, valid = list(train), list(valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lwJwVugdDpEj"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1, batch: 19,                 loss: 0.6753677502274513, training accuracy: 0.559375\n",
      "epoch: 1, batch: 39,                 loss: 0.6138441137969494, training accuracy: 0.6078125\n",
      "epoch: 1, batch: 59,                 loss: 0.5539256597558657, training accuracy: 0.671875\n",
      "epoch: 1, batch: 79,                 loss: 0.5070727933198214, training accuracy: 0.71875\n",
      "epoch: 1, batch: 99,                 loss: 0.461392689794302, training accuracy: 0.758125\n",
      "epoch: 1, batch: 119,                 loss: 0.43055068825682, training accuracy: 0.7838541666666666\n",
      "epoch: 1, batch: 139,                 loss: 0.3988972414284945, training accuracy: 0.8066964285714285\n",
      "epoch: 1, batch: 159,                 loss: 0.3772536959964782, training accuracy: 0.82109375\n",
      "epoch: 1, batch: 179,                 loss: 0.35553770682050123, training accuracy: 0.8350694444444444\n",
      "epoch: 1, batch: 199,                 loss: 0.33606252558529376, training accuracy: 0.8475\n",
      "epoch: 1, batch: 219,                 loss: 0.3202396170659499, training accuracy: 0.8568181818181818\n",
      "epoch: 1, batch: 239,                 loss: 0.30422049057669937, training accuracy: 0.8658854166666666\n",
      "epoch: 1, batch: 259,                 loss: 0.29295450582240634, training accuracy: 0.8716346153846154\n",
      "epoch: 1, batch: 279,                 loss: 0.2810225599711495, training accuracy: 0.8774553571428572\n",
      "epoch: 1, batch: 299,                 loss: 0.2728985401739677, training accuracy: 0.8825\n",
      "epoch: 1, batch: 319,                 loss: 0.26560432274127377, training accuracy: 0.8861328125\n",
      "epoch: 1, batch: 339,                 loss: 0.2565557993071921, training accuracy: 0.8904411764705882\n",
      "epoch: 1, batch: 359,                 loss: 0.24987628158802788, training accuracy: 0.8934027777777778\n",
      "epoch: 1, batch: 379,                 loss: 0.24311667920433377, training accuracy: 0.896875\n",
      "epoch: 1, batch: 399,                 loss: 0.23747346344403922, training accuracy: 0.89984375\n",
      "epoch: 1, batch: 419,                 loss: 0.232499122344667, training accuracy: 0.9020833333333333\n",
      "epoch: 1, batch: 439,                 loss: 0.22741311093030328, training accuracy: 0.9046875\n",
      "epoch: 1, batch: 459,                 loss: 0.2220445265305107, training accuracy: 0.9073369565217392\n",
      "epoch: 1, batch: 479,                 loss: 0.21807757517478119, training accuracy: 0.9088541666666666\n",
      "epoch: 1, batch: 499,                 loss: 0.21340303315222264, training accuracy: 0.911375\n",
      "epoch: 1, batch: 519,                 loss: 0.2102712753587044, training accuracy: 0.9134615384615384\n",
      "epoch: 1, batch: 539,                 loss: 0.2073346363656499, training accuracy: 0.9149305555555556\n",
      "epoch: 1, batch: 559,                 loss: 0.20289929236085819, training accuracy: 0.9169642857142857\n",
      "epoch: 1, batch: 579,                 loss: 0.20010978927643136, training accuracy: 0.918426724137931\n",
      "epoch: 1, batch: 599,                 loss: 0.19656366954557597, training accuracy: 0.9203125\n",
      "epoch: 1, batch: 619,                 loss: 0.19265942440458364, training accuracy: 0.9222782258064516\n",
      "epoch: 1, batch: 639,                 loss: 0.18996571138559376, training accuracy: 0.92333984375\n",
      "epoch: 1, batch: 659,                 loss: 0.1871149610332919, training accuracy: 0.9246212121212121\n",
      "epoch: 1, batch: 679,                 loss: 0.1831374543636818, training accuracy: 0.9263786764705882\n",
      "epoch: 1, batch: 699,                 loss: 0.17965806320708777, training accuracy: 0.9279464285714286\n",
      "epoch: 1, batch: 719,                 loss: 0.1771720950026065, training accuracy: 0.9290798611111111\n",
      "epoch: 1, batch: 739,                 loss: 0.17422791613593094, training accuracy: 0.9304054054054054\n",
      "epoch: 1, batch: 759,                 loss: 0.171880492917262, training accuracy: 0.9313322368421053\n",
      "epoch: 1, batch: 779,                 loss: 0.16958218227880886, training accuracy: 0.9323717948717949\n",
      "epoch: 1, batch: 799,                 loss: 0.16696796098607591, training accuracy: 0.93359375\n",
      "epoch: 1, batch: 819,                 loss: 0.1647028735549212, training accuracy: 0.9348323170731707\n",
      "epoch: 1, batch: 839,                 loss: 0.16255441460525616, training accuracy: 0.9357886904761905\n",
      "epoch: 1, batch: 859,                 loss: 0.1600813050467391, training accuracy: 0.9370639534883721\n",
      "epoch: 1, batch: 879,                 loss: 0.15847137128373354, training accuracy: 0.9377130681818182\n",
      "epoch: 1, batch: 899,                 loss: 0.15582462834453004, training accuracy: 0.9388888888888889\n",
      "epoch: 1, batch: 919,                 loss: 0.15413511827557713, training accuracy: 0.9397418478260869\n",
      "epoch: 1, batch: 939,                 loss: 0.15309582905635793, training accuracy: 0.9402260638297872\n",
      "epoch: 1, batch: 959,                 loss: 0.15113093614393922, training accuracy: 0.9410807291666666\n",
      "epoch: 1, batch: 979,                 loss: 0.14923761350302292, training accuracy: 0.9419642857142857\n",
      "epoch: 1, batch: 999,                 loss: 0.14735955390380695, training accuracy: 0.9428125\n",
      "epoch: 1, batch: 1019,                 loss: 0.1455350228735958, training accuracy: 0.9435661764705883\n",
      "epoch: 1, batch: 1039,                 loss: 0.14366498661514085, training accuracy: 0.9443509615384615\n",
      "epoch: 1, batch: 1059,                 loss: 0.14215657737914403, training accuracy: 0.9449292452830189\n",
      "epoch: 1, batch: 1079,                 loss: 0.14121940519953904, training accuracy: 0.9452546296296296\n",
      "epoch: 1, batch: 1099,                 loss: 0.13954261154190384, training accuracy: 0.945965909090909\n",
      "epoch: 1, batch: 1119,                 loss: 0.13877097247750497, training accuracy: 0.9463727678571429\n",
      "epoch: 1, batch: 1139,                 loss: 0.13693039632819004, training accuracy: 0.9471491228070176\n",
      "epoch: 1, batch: 1159,                 loss: 0.1353617568090879, training accuracy: 0.9478448275862069\n",
      "epoch: 1, batch: 1179,                 loss: 0.1343958406630209, training accuracy: 0.9483050847457627\n",
      "epoch: 1, batch: 1199,                 loss: 0.1333709168798911, training accuracy: 0.9486979166666667\n",
      "epoch: 1, batch: 1219,                 loss: 0.1318279090757314, training accuracy: 0.9493852459016393\n",
      "epoch: 1, batch: 1239,                 loss: 0.13043080128902088, training accuracy: 0.95\n",
      "epoch: 1, batch: 1259,                 loss: 0.1302663562534791, training accuracy: 0.9501488095238095\n",
      "epoch: 1, batch: 1279,                 loss: 0.12921429389134573, training accuracy: 0.9505859375\n",
      "epoch: 1, batch: 1299,                 loss: 0.12806300547475424, training accuracy: 0.9510576923076923\n",
      "validation accuracy 0.9838\n",
      "test_accuracy 0.5711\n",
      "Saved weights/resnet18-epoch-0-valid_acc=0.9838-test_acc=0.5711.pt\n",
      "epoch: 2, batch: 19,                 loss: 0.04285636777058244, training accuracy: 0.990625\n",
      "epoch: 2, batch: 39,                 loss: 0.03597283342387527, training accuracy: 0.9890625\n",
      "epoch: 2, batch: 59,                 loss: 0.0352007075600947, training accuracy: 0.9885416666666667\n",
      "epoch: 2, batch: 79,                 loss: 0.03503962569520809, training accuracy: 0.9890625\n",
      "epoch: 2, batch: 99,                 loss: 0.0346671413583681, training accuracy: 0.988125\n",
      "epoch: 2, batch: 119,                 loss: 0.03634365361649543, training accuracy: 0.9869791666666666\n",
      "epoch: 2, batch: 139,                 loss: 0.03727315567500357, training accuracy: 0.9875\n",
      "epoch: 2, batch: 159,                 loss: 0.03778278447280172, training accuracy: 0.9875\n",
      "epoch: 2, batch: 179,                 loss: 0.03897934430020137, training accuracy: 0.9864583333333333\n",
      "epoch: 2, batch: 199,                 loss: 0.039876599956769496, training accuracy: 0.9865625\n",
      "epoch: 2, batch: 219,                 loss: 0.04006232759407298, training accuracy: 0.9866477272727273\n",
      "epoch: 2, batch: 239,                 loss: 0.04247826905242012, training accuracy: 0.9856770833333334\n",
      "epoch: 2, batch: 259,                 loss: 0.043047307878553584, training accuracy: 0.9858173076923077\n",
      "epoch: 2, batch: 279,                 loss: 0.04200669346859546, training accuracy: 0.9861607142857143\n",
      "epoch: 2, batch: 299,                 loss: 0.041343605601384, training accuracy: 0.9864583333333333\n",
      "epoch: 2, batch: 319,                 loss: 0.04039863201105618, training accuracy: 0.987109375\n",
      "epoch: 2, batch: 339,                 loss: 0.04113620971671908, training accuracy: 0.9869485294117647\n",
      "epoch: 2, batch: 359,                 loss: 0.04123199729365297, training accuracy: 0.9869791666666666\n",
      "epoch: 2, batch: 379,                 loss: 0.040776723850591994, training accuracy: 0.9871710526315789\n",
      "epoch: 2, batch: 399,                 loss: 0.0404817624745192, training accuracy: 0.9871875\n",
      "epoch: 2, batch: 419,                 loss: 0.0396863951552881, training accuracy: 0.9876488095238095\n",
      "epoch: 2, batch: 439,                 loss: 0.039806448735444894, training accuracy: 0.9877840909090909\n",
      "epoch: 2, batch: 459,                 loss: 0.040738192827784986, training accuracy: 0.9875\n",
      "epoch: 2, batch: 479,                 loss: 0.04087781241930012, training accuracy: 0.9873697916666667\n",
      "epoch: 2, batch: 499,                 loss: 0.040238833340816196, training accuracy: 0.987625\n",
      "epoch: 2, batch: 519,                 loss: 0.0411550428189982, training accuracy: 0.9873798076923077\n",
      "epoch: 2, batch: 539,                 loss: 0.04188024152535945, training accuracy: 0.9869212962962963\n",
      "epoch: 2, batch: 559,                 loss: 0.04172979182996122, training accuracy: 0.9869419642857142\n",
      "epoch: 2, batch: 579,                 loss: 0.042304120480950023, training accuracy: 0.9866379310344827\n",
      "epoch: 2, batch: 599,                 loss: 0.04177231376602625, training accuracy: 0.986875\n",
      "epoch: 2, batch: 619,                 loss: 0.042344578470839486, training accuracy: 0.9865927419354839\n",
      "epoch: 2, batch: 639,                 loss: 0.04197881136533397, training accuracy: 0.98681640625\n",
      "epoch: 2, batch: 659,                 loss: 0.04278918432008306, training accuracy: 0.9864583333333333\n",
      "epoch: 2, batch: 679,                 loss: 0.042665711224339355, training accuracy: 0.9864889705882353\n",
      "epoch: 2, batch: 699,                 loss: 0.04253745096303257, training accuracy: 0.9865178571428571\n",
      "epoch: 2, batch: 719,                 loss: 0.041950364695124635, training accuracy: 0.9868055555555556\n",
      "epoch: 2, batch: 739,                 loss: 0.041674854573353216, training accuracy: 0.9869087837837838\n",
      "epoch: 2, batch: 759,                 loss: 0.041613318706482744, training accuracy: 0.9868421052631579\n",
      "epoch: 2, batch: 779,                 loss: 0.041593782199272074, training accuracy: 0.9868589743589744\n",
      "epoch: 2, batch: 799,                 loss: 0.04117827232432319, training accuracy: 0.98703125\n",
      "epoch: 2, batch: 819,                 loss: 0.04104493645008472, training accuracy: 0.9870426829268293\n",
      "epoch: 2, batch: 839,                 loss: 0.040890558470606006, training accuracy: 0.987202380952381\n",
      "epoch: 2, batch: 859,                 loss: 0.04031995782265873, training accuracy: 0.9875\n",
      "epoch: 2, batch: 879,                 loss: 0.039762739837698804, training accuracy: 0.9877130681818181\n",
      "epoch: 2, batch: 899,                 loss: 0.0391959838090568, training accuracy: 0.9879861111111111\n",
      "epoch: 2, batch: 919,                 loss: 0.03885159874410855, training accuracy: 0.9881114130434783\n",
      "epoch: 2, batch: 939,                 loss: 0.038606297863805865, training accuracy: 0.9882313829787234\n",
      "epoch: 2, batch: 959,                 loss: 0.03876139286391359, training accuracy: 0.9881510416666667\n",
      "epoch: 2, batch: 979,                 loss: 0.039087488442155705, training accuracy: 0.9880102040816326\n",
      "epoch: 2, batch: 999,                 loss: 0.03911907021305524, training accuracy: 0.987875\n",
      "epoch: 2, batch: 1019,                 loss: 0.039661912705895364, training accuracy: 0.9876838235294118\n",
      "epoch: 2, batch: 1039,                 loss: 0.039495231914826526, training accuracy: 0.9878004807692308\n",
      "epoch: 2, batch: 1059,                 loss: 0.039389442300362475, training accuracy: 0.9877948113207548\n",
      "epoch: 2, batch: 1079,                 loss: 0.039235866948944965, training accuracy: 0.9877893518518519\n",
      "epoch: 2, batch: 1099,                 loss: 0.03896805018885061, training accuracy: 0.9877840909090909\n",
      "epoch: 2, batch: 1119,                 loss: 0.03864352548386835, training accuracy: 0.987890625\n",
      "epoch: 2, batch: 1139,                 loss: 0.03843159209467111, training accuracy: 0.9879385964912281\n",
      "epoch: 2, batch: 1159,                 loss: 0.03808141459534266, training accuracy: 0.9880926724137931\n",
      "epoch: 2, batch: 1179,                 loss: 0.03841991469942791, training accuracy: 0.988082627118644\n",
      "epoch: 2, batch: 1199,                 loss: 0.03837089794416291, training accuracy: 0.988125\n",
      "epoch: 2, batch: 1219,                 loss: 0.038270941051486575, training accuracy: 0.9881659836065574\n",
      "epoch: 2, batch: 1239,                 loss: 0.03852252028093884, training accuracy: 0.9878528225806451\n",
      "epoch: 2, batch: 1259,                 loss: 0.03830389788315173, training accuracy: 0.9879960317460318\n",
      "epoch: 2, batch: 1279,                 loss: 0.03812461689194606, training accuracy: 0.988037109375\n",
      "epoch: 2, batch: 1299,                 loss: 0.03798229428778331, training accuracy: 0.9880288461538461\n",
      "validation accuracy 0.9885\n",
      "test_accuracy 0.5721\n",
      "Saved weights/resnet18-epoch-1-valid_acc=0.9885-test_acc=0.5721.pt\n",
      "epoch: 3, batch: 19,                 loss: 0.020513897656928747, training accuracy: 0.996875\n",
      "epoch: 3, batch: 39,                 loss: 0.026239867793628947, training accuracy: 0.9921875\n",
      "epoch: 3, batch: 59,                 loss: 0.02703937739909937, training accuracy: 0.9885416666666667\n",
      "epoch: 3, batch: 79,                 loss: 0.027788860333384947, training accuracy: 0.98984375\n",
      "epoch: 3, batch: 99,                 loss: 0.025399511891882866, training accuracy: 0.99125\n",
      "epoch: 3, batch: 119,                 loss: 0.023338800608568515, training accuracy: 0.9921875\n",
      "epoch: 3, batch: 139,                 loss: 0.02508801022777334, training accuracy: 0.9919642857142857\n",
      "epoch: 3, batch: 159,                 loss: 0.023979401386895915, training accuracy: 0.992578125\n",
      "epoch: 3, batch: 179,                 loss: 0.02316254886876171, training accuracy: 0.9927083333333333\n",
      "epoch: 3, batch: 199,                 loss: 0.023349421356106178, training accuracy: 0.9921875\n",
      "epoch: 3, batch: 219,                 loss: 0.022645269380882384, training accuracy: 0.9923295454545454\n",
      "epoch: 3, batch: 239,                 loss: 0.023143163155570315, training accuracy: 0.9919270833333333\n",
      "epoch: 3, batch: 259,                 loss: 0.022486843956777684, training accuracy: 0.9923076923076923\n",
      "epoch: 3, batch: 279,                 loss: 0.02221834650762113, training accuracy: 0.9924107142857143\n",
      "epoch: 3, batch: 299,                 loss: 0.022504968168990065, training accuracy: 0.9925\n",
      "epoch: 3, batch: 319,                 loss: 0.022712771584338043, training accuracy: 0.9921875\n",
      "epoch: 3, batch: 339,                 loss: 0.02204323119470192, training accuracy: 0.9926470588235294\n",
      "epoch: 3, batch: 359,                 loss: 0.022336983631571963, training accuracy: 0.9928819444444444\n",
      "epoch: 3, batch: 379,                 loss: 0.022358684778201247, training accuracy: 0.9929276315789474\n",
      "epoch: 3, batch: 399,                 loss: 0.02236328638944542, training accuracy: 0.99296875\n",
      "epoch: 3, batch: 419,                 loss: 0.023596658177086196, training accuracy: 0.9927083333333333\n",
      "epoch: 3, batch: 439,                 loss: 0.023040859233217567, training accuracy: 0.9928977272727273\n",
      "epoch: 3, batch: 459,                 loss: 0.02264840111956405, training accuracy: 0.993070652173913\n",
      "epoch: 3, batch: 479,                 loss: 0.022871932048534896, training accuracy: 0.9930989583333333\n",
      "epoch: 3, batch: 499,                 loss: 0.02273872086056508, training accuracy: 0.993125\n",
      "epoch: 3, batch: 519,                 loss: 0.023242804312030785, training accuracy: 0.9927884615384616\n",
      "epoch: 3, batch: 539,                 loss: 0.022756895520595007, training accuracy: 0.9930555555555556\n",
      "epoch: 3, batch: 559,                 loss: 0.023024255727276406, training accuracy: 0.9930803571428571\n",
      "epoch: 3, batch: 579,                 loss: 0.022819824900943787, training accuracy: 0.993103448275862\n",
      "epoch: 3, batch: 599,                 loss: 0.022833644993564425, training accuracy: 0.9930208333333334\n",
      "epoch: 3, batch: 619,                 loss: 0.022493412804361734, training accuracy: 0.9932459677419355\n",
      "epoch: 3, batch: 639,                 loss: 0.022063133786468826, training accuracy: 0.99345703125\n",
      "epoch: 3, batch: 659,                 loss: 0.021766120060276464, training accuracy: 0.993655303030303\n",
      "epoch: 3, batch: 679,                 loss: 0.021568307580994716, training accuracy: 0.99375\n",
      "epoch: 3, batch: 699,                 loss: 0.022022607676917688, training accuracy: 0.9935714285714285\n",
      "epoch: 3, batch: 719,                 loss: 0.022138307820326494, training accuracy: 0.9935763888888889\n",
      "epoch: 3, batch: 739,                 loss: 0.022281586391634207, training accuracy: 0.9935810810810811\n",
      "epoch: 3, batch: 759,                 loss: 0.02227860527537383, training accuracy: 0.9935855263157894\n",
      "epoch: 3, batch: 779,                 loss: 0.02190416992622583, training accuracy: 0.99375\n",
      "epoch: 3, batch: 799,                 loss: 0.021834904182687753, training accuracy: 0.993828125\n",
      "epoch: 3, batch: 819,                 loss: 0.02173432596957754, training accuracy: 0.9938262195121951\n",
      "epoch: 3, batch: 839,                 loss: 0.021494768519256642, training accuracy: 0.9938988095238095\n",
      "epoch: 3, batch: 859,                 loss: 0.02209180895026589, training accuracy: 0.9936046511627907\n",
      "epoch: 3, batch: 879,                 loss: 0.02229177194352484, training accuracy: 0.993465909090909\n",
      "epoch: 3, batch: 899,                 loss: 0.021990963479749756, training accuracy: 0.9936111111111111\n",
      "epoch: 3, batch: 919,                 loss: 0.021651891196898244, training accuracy: 0.99375\n",
      "epoch: 3, batch: 939,                 loss: 0.021773097372646048, training accuracy: 0.99375\n",
      "epoch: 3, batch: 959,                 loss: 0.021483650378225624, training accuracy: 0.9938802083333333\n",
      "epoch: 3, batch: 979,                 loss: 0.021692682304882863, training accuracy: 0.99375\n",
      "epoch: 3, batch: 999,                 loss: 0.021661853889469056, training accuracy: 0.99375\n",
      "epoch: 3, batch: 1019,                 loss: 0.02162531962088656, training accuracy: 0.9938112745098039\n",
      "epoch: 3, batch: 1039,                 loss: 0.02150843620877892, training accuracy: 0.9938100961538462\n",
      "epoch: 3, batch: 1059,                 loss: 0.02137076491665728, training accuracy: 0.9938679245283019\n",
      "epoch: 3, batch: 1079,                 loss: 0.02149519390174343, training accuracy: 0.99375\n",
      "epoch: 3, batch: 1099,                 loss: 0.021379411730555478, training accuracy: 0.9938068181818182\n",
      "epoch: 3, batch: 1119,                 loss: 0.02113317124926003, training accuracy: 0.9939174107142857\n",
      "epoch: 3, batch: 1139,                 loss: 0.021142681964607744, training accuracy: 0.9939692982456141\n",
      "epoch: 3, batch: 1159,                 loss: 0.02111067939429255, training accuracy: 0.9939655172413793\n",
      "epoch: 3, batch: 1179,                 loss: 0.021039298498584748, training accuracy: 0.9940148305084746\n",
      "epoch: 3, batch: 1199,                 loss: 0.020960199652957576, training accuracy: 0.9940625\n",
      "epoch: 3, batch: 1219,                 loss: 0.021470753192380607, training accuracy: 0.9939036885245902\n",
      "epoch: 3, batch: 1239,                 loss: 0.02127872927094652, training accuracy: 0.9940020161290323\n",
      "epoch: 3, batch: 1259,                 loss: 0.021464357198823968, training accuracy: 0.9938988095238095\n",
      "epoch: 3, batch: 1279,                 loss: 0.021261306450332994, training accuracy: 0.993994140625\n",
      "epoch: 3, batch: 1299,                 loss: 0.02112224702423331, training accuracy: 0.9940865384615385\n",
      "validation accuracy 0.9915\n",
      "test_accuracy 0.5736\n",
      "Saved weights/resnet18-epoch-2-valid_acc=0.9915-test_acc=0.5736.pt\n",
      "epoch: 4, batch: 19,                 loss: 0.010645565582672134, training accuracy: 0.996875\n",
      "epoch: 4, batch: 39,                 loss: 0.011073826948995702, training accuracy: 0.9953125\n",
      "epoch: 4, batch: 59,                 loss: 0.01135550666464648, training accuracy: 0.9958333333333333\n",
      "epoch: 4, batch: 79,                 loss: 0.009532947955449345, training accuracy: 0.996875\n",
      "epoch: 4, batch: 99,                 loss: 0.009329613969894126, training accuracy: 0.9975\n",
      "epoch: 4, batch: 119,                 loss: 0.009437121979620619, training accuracy: 0.9973958333333334\n",
      "epoch: 4, batch: 139,                 loss: 0.009495951586619153, training accuracy: 0.9973214285714286\n",
      "epoch: 4, batch: 159,                 loss: 0.009438745733496035, training accuracy: 0.99765625\n",
      "epoch: 4, batch: 179,                 loss: 0.010317668521828536, training accuracy: 0.9965277777777778\n",
      "epoch: 4, batch: 199,                 loss: 0.010894479805720038, training accuracy: 0.9965625\n",
      "epoch: 4, batch: 219,                 loss: 0.011262362345058301, training accuracy: 0.9965909090909091\n",
      "epoch: 4, batch: 239,                 loss: 0.011152253760762202, training accuracy: 0.996875\n",
      "epoch: 4, batch: 259,                 loss: 0.011072967631312517, training accuracy: 0.9971153846153846\n",
      "epoch: 4, batch: 279,                 loss: 0.011295748839620501, training accuracy: 0.9970982142857143\n",
      "epoch: 4, batch: 299,                 loss: 0.011424302063921156, training accuracy: 0.9970833333333333\n",
      "epoch: 4, batch: 319,                 loss: 0.011617549426591722, training accuracy: 0.9970703125\n",
      "epoch: 4, batch: 339,                 loss: 0.011364462801686707, training accuracy: 0.9972426470588235\n",
      "epoch: 4, batch: 359,                 loss: 0.011039309314057593, training accuracy: 0.9973958333333334\n",
      "epoch: 4, batch: 379,                 loss: 0.012128435308879585, training accuracy: 0.9972039473684211\n",
      "epoch: 4, batch: 399,                 loss: 0.011831189228105358, training accuracy: 0.99734375\n",
      "epoch: 4, batch: 419,                 loss: 0.011736471523874484, training accuracy: 0.9973214285714286\n",
      "epoch: 4, batch: 439,                 loss: 0.01208566629819953, training accuracy: 0.9971590909090909\n",
      "epoch: 4, batch: 459,                 loss: 0.01198736309382619, training accuracy: 0.9971467391304348\n",
      "epoch: 4, batch: 479,                 loss: 0.012129902924304286, training accuracy: 0.9971354166666667\n",
      "epoch: 4, batch: 499,                 loss: 0.012025250232079997, training accuracy: 0.997\n",
      "epoch: 4, batch: 519,                 loss: 0.01240127832201184, training accuracy: 0.9967548076923077\n",
      "epoch: 4, batch: 539,                 loss: 0.01284906737165767, training accuracy: 0.9965277777777778\n",
      "epoch: 4, batch: 559,                 loss: 0.012624095823516005, training accuracy: 0.9965401785714286\n",
      "epoch: 4, batch: 579,                 loss: 0.01233391263512172, training accuracy: 0.9966594827586207\n",
      "epoch: 4, batch: 599,                 loss: 0.012331511926992486, training accuracy: 0.9965625\n",
      "epoch: 4, batch: 619,                 loss: 0.012418266873423671, training accuracy: 0.9965725806451613\n",
      "epoch: 4, batch: 639,                 loss: 0.012718750047952199, training accuracy: 0.99638671875\n",
      "epoch: 4, batch: 659,                 loss: 0.012730831065070534, training accuracy: 0.9964962121212121\n",
      "epoch: 4, batch: 679,                 loss: 0.013309701762131334, training accuracy: 0.9964154411764706\n",
      "epoch: 4, batch: 699,                 loss: 0.013298556031908706, training accuracy: 0.9963392857142858\n",
      "epoch: 4, batch: 719,                 loss: 0.013359143426916692, training accuracy: 0.9963541666666667\n",
      "epoch: 4, batch: 739,                 loss: 0.013155321078846935, training accuracy: 0.9964527027027027\n",
      "epoch: 4, batch: 759,                 loss: 0.013160624925819176, training accuracy: 0.9963815789473685\n",
      "epoch: 4, batch: 779,                 loss: 0.013158983335895942, training accuracy: 0.9963942307692307\n",
      "epoch: 4, batch: 799,                 loss: 0.013355019287118922, training accuracy: 0.996328125\n",
      "epoch: 4, batch: 819,                 loss: 0.013221315321833372, training accuracy: 0.9964176829268293\n",
      "epoch: 4, batch: 839,                 loss: 0.013363324348964463, training accuracy: 0.9963541666666667\n",
      "epoch: 4, batch: 859,                 loss: 0.01335539413686452, training accuracy: 0.9962936046511628\n",
      "epoch: 4, batch: 879,                 loss: 0.013150672167433765, training accuracy: 0.9963778409090909\n",
      "epoch: 4, batch: 899,                 loss: 0.01294968433264229, training accuracy: 0.9964583333333333\n",
      "epoch: 4, batch: 919,                 loss: 0.013316700335543948, training accuracy: 0.9962635869565217\n",
      "epoch: 4, batch: 939,                 loss: 0.013193791492364092, training accuracy: 0.996343085106383\n",
      "epoch: 4, batch: 959,                 loss: 0.013086394379024568, training accuracy: 0.9964192708333334\n",
      "epoch: 4, batch: 979,                 loss: 0.013000057739673696, training accuracy: 0.9964285714285714\n",
      "epoch: 4, batch: 999,                 loss: 0.012839518090651836, training accuracy: 0.9964375\n",
      "epoch: 4, batch: 1019,                 loss: 0.012660267346712085, training accuracy: 0.9965073529411764\n",
      "epoch: 4, batch: 1039,                 loss: 0.01249189389284136, training accuracy: 0.9965745192307692\n",
      "epoch: 4, batch: 1059,                 loss: 0.012657871657712297, training accuracy: 0.9964622641509434\n",
      "epoch: 4, batch: 1079,                 loss: 0.01266773560025656, training accuracy: 0.9964120370370371\n",
      "epoch: 4, batch: 1099,                 loss: 0.012625725719950754, training accuracy: 0.9964772727272727\n",
      "epoch: 4, batch: 1119,                 loss: 0.012541477870737644, training accuracy: 0.9965401785714286\n",
      "epoch: 4, batch: 1139,                 loss: 0.012500512086721994, training accuracy: 0.9966008771929824\n",
      "epoch: 4, batch: 1159,                 loss: 0.0124425344862363, training accuracy: 0.9966056034482759\n",
      "epoch: 4, batch: 1179,                 loss: 0.012320142531727038, training accuracy: 0.9966631355932203\n",
      "epoch: 4, batch: 1199,                 loss: 0.012340432275013882, training accuracy: 0.9966145833333333\n",
      "epoch: 4, batch: 1219,                 loss: 0.012301139214451112, training accuracy: 0.9966188524590164\n",
      "epoch: 4, batch: 1239,                 loss: 0.012300412529152855, training accuracy: 0.9966229838709677\n",
      "epoch: 4, batch: 1259,                 loss: 0.012218677853294167, training accuracy: 0.9966269841269841\n",
      "epoch: 4, batch: 1279,                 loss: 0.012135019230322541, training accuracy: 0.9966796875\n",
      "epoch: 4, batch: 1299,                 loss: 0.012223067618436358, training accuracy: 0.9966346153846154\n",
      "validation accuracy 0.9881\n",
      "test_accuracy 0.5726\n",
      "Saved weights/resnet18-epoch-3-valid_acc=0.9881-test_acc=0.5726.pt\n",
      "epoch: 5, batch: 19,                 loss: 0.006927237616037018, training accuracy: 1.0\n",
      "epoch: 5, batch: 39,                 loss: 0.006350332021247596, training accuracy: 1.0\n",
      "epoch: 5, batch: 59,                 loss: 0.005428838343747581, training accuracy: 1.0\n",
      "epoch: 5, batch: 79,                 loss: 0.007773224166157888, training accuracy: 0.99921875\n",
      "epoch: 5, batch: 99,                 loss: 0.007329439503373578, training accuracy: 0.999375\n",
      "epoch: 5, batch: 119,                 loss: 0.0071261969996461024, training accuracy: 0.9994791666666667\n",
      "epoch: 5, batch: 139,                 loss: 0.007390519208066897, training accuracy: 0.9991071428571429\n",
      "epoch: 5, batch: 159,                 loss: 0.007303868367125687, training accuracy: 0.99921875\n",
      "epoch: 5, batch: 179,                 loss: 0.009570933931293742, training accuracy: 0.9989583333333333\n",
      "epoch: 5, batch: 199,                 loss: 0.00925810057829949, training accuracy: 0.9990625\n",
      "epoch: 5, batch: 219,                 loss: 0.009449035170440436, training accuracy: 0.9988636363636364\n",
      "epoch: 5, batch: 239,                 loss: 0.010100441050478063, training accuracy: 0.9986979166666666\n",
      "epoch: 5, batch: 259,                 loss: 0.009649194516756464, training accuracy: 0.9987980769230769\n",
      "epoch: 5, batch: 279,                 loss: 0.00924916696084048, training accuracy: 0.9988839285714286\n",
      "epoch: 5, batch: 299,                 loss: 0.008976763508884081, training accuracy: 0.9989583333333333\n",
      "epoch: 5, batch: 319,                 loss: 0.008813381422714883, training accuracy: 0.9990234375\n",
      "epoch: 5, batch: 339,                 loss: 0.009064981430984678, training accuracy: 0.9987132352941176\n",
      "epoch: 5, batch: 359,                 loss: 0.008720394492734663, training accuracy: 0.9987847222222223\n",
      "epoch: 5, batch: 379,                 loss: 0.008711344019071763, training accuracy: 0.9986842105263158\n",
      "epoch: 5, batch: 399,                 loss: 0.00885612324665999, training accuracy: 0.99859375\n",
      "epoch: 5, batch: 419,                 loss: 0.009053256298717489, training accuracy: 0.9985119047619048\n",
      "epoch: 5, batch: 439,                 loss: 0.008844996512065832, training accuracy: 0.9985795454545454\n",
      "epoch: 5, batch: 459,                 loss: 0.009137089022007548, training accuracy: 0.9985054347826087\n",
      "epoch: 5, batch: 479,                 loss: 0.009064681272987703, training accuracy: 0.9984375\n",
      "epoch: 5, batch: 499,                 loss: 0.0090666383265052, training accuracy: 0.998375\n",
      "epoch: 5, batch: 519,                 loss: 0.008956777860741847, training accuracy: 0.9984375\n",
      "epoch: 5, batch: 539,                 loss: 0.008701906785211544, training accuracy: 0.9984953703703704\n",
      "epoch: 5, batch: 559,                 loss: 0.008536037478188518, training accuracy: 0.9985491071428572\n",
      "epoch: 5, batch: 579,                 loss: 0.008435760627366232, training accuracy: 0.9985991379310345\n",
      "epoch: 5, batch: 599,                 loss: 0.008313100175825336, training accuracy: 0.9986458333333333\n",
      "epoch: 5, batch: 619,                 loss: 0.00812369023370857, training accuracy: 0.9986895161290322\n",
      "epoch: 5, batch: 639,                 loss: 0.008363205086789094, training accuracy: 0.9986328125\n",
      "epoch: 5, batch: 659,                 loss: 0.008378527916537485, training accuracy: 0.9985795454545454\n",
      "epoch: 5, batch: 679,                 loss: 0.008264079789018176, training accuracy: 0.9986213235294118\n",
      "epoch: 5, batch: 699,                 loss: 0.008197108770670768, training accuracy: 0.9986607142857142\n",
      "epoch: 5, batch: 719,                 loss: 0.008082974214630667, training accuracy: 0.9986979166666666\n",
      "epoch: 5, batch: 739,                 loss: 0.008023072633777455, training accuracy: 0.9987331081081081\n",
      "epoch: 5, batch: 759,                 loss: 0.008012956161493142, training accuracy: 0.9986842105263158\n",
      "epoch: 5, batch: 779,                 loss: 0.007873649868139555, training accuracy: 0.9987179487179487\n",
      "epoch: 5, batch: 799,                 loss: 0.008051551950629801, training accuracy: 0.998671875\n",
      "epoch: 5, batch: 819,                 loss: 0.008474880109240142, training accuracy: 0.9985518292682927\n",
      "epoch: 5, batch: 839,                 loss: 0.00838269890317904, training accuracy: 0.9985863095238096\n",
      "epoch: 5, batch: 859,                 loss: 0.008378253933949245, training accuracy: 0.9986191860465117\n",
      "epoch: 5, batch: 879,                 loss: 0.008246282541949767, training accuracy: 0.9986505681818182\n",
      "epoch: 5, batch: 899,                 loss: 0.008151761732232343, training accuracy: 0.9986805555555556\n",
      "epoch: 5, batch: 919,                 loss: 0.008064526423961228, training accuracy: 0.9987092391304347\n",
      "epoch: 5, batch: 939,                 loss: 0.008077834296273068, training accuracy: 0.9986702127659575\n",
      "epoch: 5, batch: 959,                 loss: 0.008463617039130138, training accuracy: 0.9984375\n",
      "epoch: 5, batch: 979,                 loss: 0.00868593522734175, training accuracy: 0.9983418367346939\n",
      "epoch: 5, batch: 999,                 loss: 0.008725722867209696, training accuracy: 0.99825\n",
      "epoch: 5, batch: 1019,                 loss: 0.008824004664048141, training accuracy: 0.9981617647058824\n",
      "epoch: 5, batch: 1039,                 loss: 0.00869878308364535, training accuracy: 0.9981971153846154\n",
      "epoch: 5, batch: 1059,                 loss: 0.008708751152372778, training accuracy: 0.9981721698113207\n",
      "epoch: 5, batch: 1079,                 loss: 0.008772683108340801, training accuracy: 0.9980902777777778\n",
      "epoch: 5, batch: 1099,                 loss: 0.00876060071804783, training accuracy: 0.9980681818181818\n",
      "epoch: 5, batch: 1119,                 loss: 0.008721900482188565, training accuracy: 0.9981026785714285\n",
      "epoch: 5, batch: 1139,                 loss: 0.008765469295758522, training accuracy: 0.9980263157894737\n",
      "epoch: 5, batch: 1159,                 loss: 0.008670008732500217, training accuracy: 0.9980603448275862\n",
      "epoch: 5, batch: 1179,                 loss: 0.008579932904165432, training accuracy: 0.9980932203389831\n",
      "epoch: 5, batch: 1199,                 loss: 0.008554013042557927, training accuracy: 0.9980729166666666\n",
      "epoch: 5, batch: 1219,                 loss: 0.008641995702472757, training accuracy: 0.9980532786885246\n",
      "epoch: 5, batch: 1239,                 loss: 0.008573638500644349, training accuracy: 0.9980342741935484\n",
      "epoch: 5, batch: 1259,                 loss: 0.008606889556863785, training accuracy: 0.9979662698412698\n",
      "epoch: 5, batch: 1279,                 loss: 0.008536751683220701, training accuracy: 0.997998046875\n",
      "epoch: 5, batch: 1299,                 loss: 0.008435430594735617, training accuracy: 0.9980288461538461\n",
      "validation accuracy 0.9932\n",
      "test_accuracy 0.5817\n",
      "Saved weights/resnet18-epoch-4-valid_acc=0.9932-test_acc=0.5817.pt\n",
      "epoch: 6, batch: 19,                 loss: 0.00784749763988657, training accuracy: 1.0\n",
      "epoch: 6, batch: 39,                 loss: 0.005813118194055278, training accuracy: 1.0\n",
      "epoch: 6, batch: 59,                 loss: 0.00850987187635231, training accuracy: 0.9989583333333333\n",
      "epoch: 6, batch: 79,                 loss: 0.007285322974712472, training accuracy: 0.99921875\n",
      "epoch: 6, batch: 99,                 loss: 0.008331933829322225, training accuracy: 0.99875\n",
      "epoch: 6, batch: 119,                 loss: 0.00787084332247711, training accuracy: 0.9989583333333333\n",
      "epoch: 6, batch: 139,                 loss: 0.00762547448404283, training accuracy: 0.9986607142857142\n",
      "epoch: 6, batch: 159,                 loss: 0.007431182029995398, training accuracy: 0.998828125\n",
      "epoch: 6, batch: 179,                 loss: 0.006841533187657155, training accuracy: 0.9989583333333333\n",
      "epoch: 6, batch: 199,                 loss: 0.0069513689660379895, training accuracy: 0.99875\n",
      "epoch: 6, batch: 219,                 loss: 0.006491870480518132, training accuracy: 0.9988636363636364\n",
      "epoch: 6, batch: 239,                 loss: 0.0073374904589703265, training accuracy: 0.9984375\n",
      "epoch: 6, batch: 259,                 loss: 0.007178288680678144, training accuracy: 0.9985576923076923\n",
      "epoch: 6, batch: 279,                 loss: 0.007005668916359095, training accuracy: 0.9986607142857142\n",
      "epoch: 6, batch: 299,                 loss: 0.0071742997859352425, training accuracy: 0.9985416666666667\n",
      "epoch: 6, batch: 319,                 loss: 0.007121258222286997, training accuracy: 0.9986328125\n",
      "epoch: 6, batch: 339,                 loss: 0.0074415759723599284, training accuracy: 0.9985294117647059\n",
      "epoch: 6, batch: 359,                 loss: 0.007261611181456828, training accuracy: 0.9986111111111111\n",
      "epoch: 6, batch: 379,                 loss: 0.007031221028668561, training accuracy: 0.9986842105263158\n",
      "epoch: 6, batch: 399,                 loss: 0.006833069708372932, training accuracy: 0.99875\n",
      "epoch: 6, batch: 419,                 loss: 0.0068483894058902345, training accuracy: 0.9986607142857142\n",
      "epoch: 6, batch: 439,                 loss: 0.006918366849574588, training accuracy: 0.9985795454545454\n",
      "epoch: 6, batch: 459,                 loss: 0.006936219204236176, training accuracy: 0.998641304347826\n",
      "epoch: 6, batch: 479,                 loss: 0.006862637095431031, training accuracy: 0.9986979166666666\n",
      "epoch: 6, batch: 499,                 loss: 0.0067588414670026395, training accuracy: 0.99875\n",
      "epoch: 6, batch: 519,                 loss: 0.006718693769009685, training accuracy: 0.9986778846153846\n",
      "epoch: 6, batch: 539,                 loss: 0.00650630624793983, training accuracy: 0.9987268518518518\n",
      "epoch: 6, batch: 559,                 loss: 0.006600182678058835, training accuracy: 0.9986607142857142\n",
      "epoch: 6, batch: 579,                 loss: 0.006900119385606778, training accuracy: 0.9984913793103448\n",
      "epoch: 6, batch: 599,                 loss: 0.006858275478274057, training accuracy: 0.9985416666666667\n",
      "epoch: 6, batch: 619,                 loss: 0.0068695026161402625, training accuracy: 0.9984879032258065\n",
      "epoch: 6, batch: 639,                 loss: 0.006748630515517107, training accuracy: 0.99853515625\n",
      "epoch: 6, batch: 659,                 loss: 0.006859457013938068, training accuracy: 0.9984848484848485\n",
      "epoch: 6, batch: 679,                 loss: 0.006771896383489708, training accuracy: 0.9985294117647059\n",
      "epoch: 6, batch: 699,                 loss: 0.006756761325294585, training accuracy: 0.9984821428571429\n",
      "epoch: 6, batch: 719,                 loss: 0.00684883905347912, training accuracy: 0.9984375\n",
      "epoch: 6, batch: 739,                 loss: 0.00678491206980087, training accuracy: 0.9984797297297298\n",
      "epoch: 6, batch: 759,                 loss: 0.006992579180548905, training accuracy: 0.9984375\n",
      "epoch: 6, batch: 779,                 loss: 0.006942700703373889, training accuracy: 0.998477564102564\n",
      "epoch: 6, batch: 799,                 loss: 0.007134774605710845, training accuracy: 0.9984375\n",
      "epoch: 6, batch: 819,                 loss: 0.00710835349252703, training accuracy: 0.9984756097560976\n",
      "epoch: 6, batch: 839,                 loss: 0.0070405240537227305, training accuracy: 0.9985119047619048\n",
      "epoch: 6, batch: 859,                 loss: 0.006969673271686228, training accuracy: 0.998546511627907\n",
      "epoch: 6, batch: 879,                 loss: 0.006917142811719465, training accuracy: 0.9985795454545454\n",
      "epoch: 6, batch: 899,                 loss: 0.006996302470474297, training accuracy: 0.9986111111111111\n",
      "epoch: 6, batch: 919,                 loss: 0.006995725769957062, training accuracy: 0.9985733695652174\n",
      "epoch: 6, batch: 939,                 loss: 0.006908903531439137, training accuracy: 0.9986037234042553\n",
      "epoch: 6, batch: 959,                 loss: 0.006916302873423774, training accuracy: 0.9986328125\n",
      "epoch: 6, batch: 979,                 loss: 0.007220456828434515, training accuracy: 0.9984693877551021\n",
      "epoch: 6, batch: 999,                 loss: 0.007200405021460028, training accuracy: 0.9985\n",
      "epoch: 6, batch: 1019,                 loss: 0.007123465340512613, training accuracy: 0.9985294117647059\n",
      "epoch: 6, batch: 1039,                 loss: 0.007045017914872285, training accuracy: 0.9985576923076923\n",
      "epoch: 6, batch: 1059,                 loss: 0.0069570616073247465, training accuracy: 0.9985849056603774\n",
      "epoch: 6, batch: 1079,                 loss: 0.0068896957805177576, training accuracy: 0.9986111111111111\n",
      "epoch: 6, batch: 1099,                 loss: 0.006798056050849316, training accuracy: 0.9986363636363637\n",
      "epoch: 6, batch: 1119,                 loss: 0.006711874162517363, training accuracy: 0.9986607142857142\n",
      "epoch: 6, batch: 1139,                 loss: 0.006705082018794328, training accuracy: 0.9986842105263158\n",
      "epoch: 6, batch: 1159,                 loss: 0.006744059754939748, training accuracy: 0.9985991379310345\n",
      "epoch: 6, batch: 1179,                 loss: 0.006669743693579468, training accuracy: 0.9986228813559322\n",
      "epoch: 6, batch: 1199,                 loss: 0.006633493188728607, training accuracy: 0.9986458333333333\n",
      "epoch: 6, batch: 1219,                 loss: 0.006567227885433135, training accuracy: 0.9986680327868852\n",
      "epoch: 6, batch: 1239,                 loss: 0.006564141203119605, training accuracy: 0.9986391129032258\n",
      "epoch: 6, batch: 1259,                 loss: 0.006522187639607832, training accuracy: 0.9986607142857142\n",
      "epoch: 6, batch: 1279,                 loss: 0.006493932690199244, training accuracy: 0.998681640625\n",
      "epoch: 6, batch: 1299,                 loss: 0.006613670422341854, training accuracy: 0.9986057692307693\n",
      "validation accuracy 0.9923\n",
      "test_accuracy 0.5831\n",
      "Saved weights/resnet18-epoch-5-valid_acc=0.9923-test_acc=0.5831.pt\n",
      "Finished Training: resnet18\n",
      "epoch: 1, batch: 19,                 loss: 0.7592333167791366, training accuracy: 0.515625\n",
      "epoch: 1, batch: 39,                 loss: 0.6643537044525146, training accuracy: 0.5984375\n",
      "epoch: 1, batch: 59,                 loss: 0.606552887459596, training accuracy: 0.6479166666666667\n",
      "epoch: 1, batch: 79,                 loss: 0.5509629735723138, training accuracy: 0.70078125\n",
      "epoch: 1, batch: 99,                 loss: 0.4958600330352783, training accuracy: 0.744375\n",
      "epoch: 1, batch: 119,                 loss: 0.4582670307407776, training accuracy: 0.7713541666666667\n",
      "epoch: 1, batch: 139,                 loss: 0.42003824269132956, training accuracy: 0.7959821428571429\n",
      "epoch: 1, batch: 159,                 loss: 0.3910110845696181, training accuracy: 0.814453125\n",
      "epoch: 1, batch: 179,                 loss: 0.3666828491621547, training accuracy: 0.8288194444444444\n",
      "epoch: 1, batch: 199,                 loss: 0.3461116429790854, training accuracy: 0.8409375\n",
      "epoch: 1, batch: 219,                 loss: 0.3302540483799848, training accuracy: 0.8505681818181818\n",
      "epoch: 1, batch: 239,                 loss: 0.3161127655301243, training accuracy: 0.8572916666666667\n",
      "epoch: 1, batch: 259,                 loss: 0.30161647253598156, training accuracy: 0.8646634615384615\n",
      "epoch: 1, batch: 279,                 loss: 0.2867940466584904, training accuracy: 0.8716517857142857\n",
      "epoch: 1, batch: 299,                 loss: 0.27463220424329243, training accuracy: 0.8785416666666667\n",
      "epoch: 1, batch: 319,                 loss: 0.26505490837735124, training accuracy: 0.8837890625\n",
      "epoch: 1, batch: 339,                 loss: 0.2561898141661111, training accuracy: 0.8886029411764705\n",
      "epoch: 1, batch: 359,                 loss: 0.2488183297837774, training accuracy: 0.8925347222222222\n",
      "epoch: 1, batch: 379,                 loss: 0.2404158071026598, training accuracy: 0.896875\n",
      "epoch: 1, batch: 399,                 loss: 0.23532336038071663, training accuracy: 0.899375\n",
      "epoch: 1, batch: 419,                 loss: 0.2288119393600417, training accuracy: 0.903422619047619\n",
      "epoch: 1, batch: 439,                 loss: 0.22390999178275128, training accuracy: 0.9058238636363637\n",
      "epoch: 1, batch: 459,                 loss: 0.2178556510105567, training accuracy: 0.9084239130434782\n",
      "epoch: 1, batch: 479,                 loss: 0.2107926731715755, training accuracy: 0.91171875\n",
      "epoch: 1, batch: 499,                 loss: 0.20715849806182088, training accuracy: 0.91325\n",
      "epoch: 1, batch: 519,                 loss: 0.20319359328311223, training accuracy: 0.9152644230769231\n",
      "epoch: 1, batch: 539,                 loss: 0.19908294351081604, training accuracy: 0.9168981481481482\n",
      "epoch: 1, batch: 559,                 loss: 0.19638687076180109, training accuracy: 0.9183035714285714\n",
      "epoch: 1, batch: 579,                 loss: 0.1922445880666632, training accuracy: 0.9203663793103448\n",
      "epoch: 1, batch: 599,                 loss: 0.18944810283215097, training accuracy: 0.9217708333333333\n",
      "epoch: 1, batch: 619,                 loss: 0.18564107753937284, training accuracy: 0.9235887096774194\n",
      "epoch: 1, batch: 639,                 loss: 0.18264832460263278, training accuracy: 0.925\n",
      "epoch: 1, batch: 659,                 loss: 0.17911793209725257, training accuracy: 0.9262310606060606\n",
      "epoch: 1, batch: 679,                 loss: 0.1760765179991722, training accuracy: 0.9276654411764705\n",
      "epoch: 1, batch: 699,                 loss: 0.17267463729716837, training accuracy: 0.9291964285714286\n",
      "epoch: 1, batch: 719,                 loss: 0.1694775867140076, training accuracy: 0.9307291666666667\n",
      "epoch: 1, batch: 739,                 loss: 0.16668415622898958, training accuracy: 0.9320101351351351\n",
      "epoch: 1, batch: 759,                 loss: 0.16436364279361443, training accuracy: 0.9331414473684211\n",
      "epoch: 1, batch: 779,                 loss: 0.1626310269175193, training accuracy: 0.933974358974359\n",
      "epoch: 1, batch: 799,                 loss: 0.16029891087498982, training accuracy: 0.935078125\n",
      "epoch: 1, batch: 819,                 loss: 0.15809961068614317, training accuracy: 0.9361280487804878\n",
      "epoch: 1, batch: 839,                 loss: 0.15593490697654142, training accuracy: 0.9371279761904762\n",
      "epoch: 1, batch: 859,                 loss: 0.15359089783078797, training accuracy: 0.9380087209302326\n",
      "epoch: 1, batch: 879,                 loss: 0.15113105861713516, training accuracy: 0.9391335227272727\n",
      "epoch: 1, batch: 899,                 loss: 0.149017363426586, training accuracy: 0.9400694444444444\n",
      "epoch: 1, batch: 919,                 loss: 0.14660904848765907, training accuracy: 0.9411684782608696\n",
      "epoch: 1, batch: 939,                 loss: 0.1443348043707219, training accuracy: 0.942154255319149\n",
      "epoch: 1, batch: 959,                 loss: 0.14278714193108802, training accuracy: 0.9429036458333333\n",
      "epoch: 1, batch: 979,                 loss: 0.14075257037623728, training accuracy: 0.94375\n",
      "epoch: 1, batch: 999,                 loss: 0.13858813377469778, training accuracy: 0.944625\n",
      "epoch: 1, batch: 1019,                 loss: 0.13679219282040483, training accuracy: 0.9454044117647059\n",
      "epoch: 1, batch: 1039,                 loss: 0.13534709317430568, training accuracy: 0.94609375\n",
      "epoch: 1, batch: 1059,                 loss: 0.13371267705136594, training accuracy: 0.9468160377358491\n",
      "epoch: 1, batch: 1079,                 loss: 0.1318151918893111, training accuracy: 0.9476851851851852\n",
      "epoch: 1, batch: 1099,                 loss: 0.1308609557983635, training accuracy: 0.9481818181818182\n",
      "epoch: 1, batch: 1119,                 loss: 0.1292739574346342, training accuracy: 0.9489397321428571\n",
      "epoch: 1, batch: 1139,                 loss: 0.12827648405157227, training accuracy: 0.9492872807017544\n",
      "epoch: 1, batch: 1159,                 loss: 0.1274222527891558, training accuracy: 0.9495689655172413\n",
      "epoch: 1, batch: 1179,                 loss: 0.1257891092565842, training accuracy: 0.9503707627118644\n",
      "epoch: 1, batch: 1199,                 loss: 0.12455106925937191, training accuracy: 0.9509895833333334\n",
      "epoch: 1, batch: 1219,                 loss: 0.1232492553801123, training accuracy: 0.9515881147540983\n",
      "epoch: 1, batch: 1239,                 loss: 0.12220574134581481, training accuracy: 0.9520161290322581\n",
      "epoch: 1, batch: 1259,                 loss: 0.12107759741973871, training accuracy: 0.952579365079365\n",
      "epoch: 1, batch: 1279,                 loss: 0.12047206347870087, training accuracy: 0.9529296875\n",
      "epoch: 1, batch: 1299,                 loss: 0.11924091701915202, training accuracy: 0.9535096153846154\n",
      "validation accuracy 0.9868\n",
      "test_accuracy 0.5155\n",
      "Saved weights/resnet34-epoch-0-valid_acc=0.9868-test_acc=0.5155.pt\n",
      "epoch: 2, batch: 19,                 loss: 0.03176870127208531, training accuracy: 0.99375\n",
      "epoch: 2, batch: 39,                 loss: 0.04161451674881391, training accuracy: 0.9890625\n",
      "epoch: 2, batch: 59,                 loss: 0.04179837605139861, training accuracy: 0.9885416666666667\n",
      "epoch: 2, batch: 79,                 loss: 0.0400807385914959, training accuracy: 0.98984375\n",
      "epoch: 2, batch: 99,                 loss: 0.037888155800756065, training accuracy: 0.990625\n",
      "epoch: 2, batch: 119,                 loss: 0.03712234514338585, training accuracy: 0.990625\n",
      "epoch: 2, batch: 139,                 loss: 0.03668290763162076, training accuracy: 0.9901785714285715\n",
      "epoch: 2, batch: 159,                 loss: 0.035244508218602276, training accuracy: 0.990234375\n",
      "epoch: 2, batch: 179,                 loss: 0.03417054055284502, training accuracy: 0.990625\n",
      "epoch: 2, batch: 199,                 loss: 0.032612905119312925, training accuracy: 0.9909375\n",
      "epoch: 2, batch: 219,                 loss: 0.03177106836175715, training accuracy: 0.9911931818181818\n",
      "epoch: 2, batch: 239,                 loss: 0.03176604735005337, training accuracy: 0.9911458333333333\n",
      "epoch: 2, batch: 259,                 loss: 0.030770879128249363, training accuracy: 0.9913461538461539\n",
      "epoch: 2, batch: 279,                 loss: 0.030456472376577687, training accuracy: 0.9910714285714286\n",
      "epoch: 2, batch: 299,                 loss: 0.02971582243257823, training accuracy: 0.99125\n",
      "epoch: 2, batch: 319,                 loss: 0.03177606309000112, training accuracy: 0.990234375\n",
      "epoch: 2, batch: 339,                 loss: 0.032517186073956136, training accuracy: 0.9898897058823529\n",
      "epoch: 2, batch: 359,                 loss: 0.03248261720194326, training accuracy: 0.9902777777777778\n",
      "epoch: 2, batch: 379,                 loss: 0.03321404716974173, training accuracy: 0.9896381578947369\n",
      "epoch: 2, batch: 399,                 loss: 0.03269797815562924, training accuracy: 0.99\n",
      "epoch: 2, batch: 419,                 loss: 0.032008201822117416, training accuracy: 0.9903273809523809\n",
      "epoch: 2, batch: 439,                 loss: 0.03136800762652208, training accuracy: 0.990625\n",
      "epoch: 2, batch: 459,                 loss: 0.030952183617046103, training accuracy: 0.9907608695652174\n",
      "epoch: 2, batch: 479,                 loss: 0.030638960684639945, training accuracy: 0.991015625\n",
      "epoch: 2, batch: 499,                 loss: 0.030684675608528778, training accuracy: 0.990875\n",
      "epoch: 2, batch: 519,                 loss: 0.029840454944776586, training accuracy: 0.9912259615384615\n",
      "epoch: 2, batch: 539,                 loss: 0.03035909282690328, training accuracy: 0.9912037037037037\n",
      "epoch: 2, batch: 559,                 loss: 0.030222533153054038, training accuracy: 0.9912946428571429\n",
      "epoch: 2, batch: 579,                 loss: 0.029629277683802527, training accuracy: 0.9915948275862069\n",
      "epoch: 2, batch: 599,                 loss: 0.029951292258144045, training accuracy: 0.9915625\n",
      "epoch: 2, batch: 619,                 loss: 0.029969287417723887, training accuracy: 0.9915322580645162\n",
      "epoch: 2, batch: 639,                 loss: 0.030513155709195418, training accuracy: 0.99130859375\n",
      "epoch: 2, batch: 659,                 loss: 0.030861405725590884, training accuracy: 0.9911931818181818\n",
      "epoch: 2, batch: 679,                 loss: 0.03072403560680173, training accuracy: 0.9910845588235294\n",
      "epoch: 2, batch: 699,                 loss: 0.031202184359010843, training accuracy: 0.9908035714285715\n",
      "epoch: 2, batch: 719,                 loss: 0.031257580436391035, training accuracy: 0.9907118055555556\n",
      "epoch: 2, batch: 739,                 loss: 0.031757715441022266, training accuracy: 0.9905405405405405\n",
      "epoch: 2, batch: 759,                 loss: 0.031747420489218234, training accuracy: 0.9905427631578947\n",
      "epoch: 2, batch: 779,                 loss: 0.031202244248617297, training accuracy: 0.9907051282051282\n",
      "epoch: 2, batch: 799,                 loss: 0.031079522730287863, training accuracy: 0.990625\n",
      "epoch: 2, batch: 819,                 loss: 0.031122741578913454, training accuracy: 0.9905487804878049\n",
      "epoch: 2, batch: 839,                 loss: 0.031010764185200622, training accuracy: 0.9904761904761905\n",
      "epoch: 2, batch: 859,                 loss: 0.030671893071713533, training accuracy: 0.9906976744186047\n",
      "epoch: 2, batch: 879,                 loss: 0.030386067496014718, training accuracy: 0.9908380681818182\n",
      "epoch: 2, batch: 899,                 loss: 0.030162408742924324, training accuracy: 0.9909722222222223\n",
      "epoch: 2, batch: 919,                 loss: 0.02984803283458029, training accuracy: 0.9910326086956521\n",
      "epoch: 2, batch: 939,                 loss: 0.03005643053094242, training accuracy: 0.9909574468085106\n",
      "epoch: 2, batch: 959,                 loss: 0.029846812394074124, training accuracy: 0.9910807291666667\n",
      "epoch: 2, batch: 979,                 loss: 0.029498432710771544, training accuracy: 0.9911989795918368\n",
      "epoch: 2, batch: 999,                 loss: 0.02941057358530816, training accuracy: 0.9913125\n",
      "epoch: 2, batch: 1019,                 loss: 0.029068104811492104, training accuracy: 0.9914828431372549\n",
      "epoch: 2, batch: 1039,                 loss: 0.028885268649677387, training accuracy: 0.9915865384615384\n",
      "epoch: 2, batch: 1059,                 loss: 0.0286172620047165, training accuracy: 0.991686320754717\n",
      "epoch: 2, batch: 1079,                 loss: 0.02867759616185342, training accuracy: 0.991724537037037\n",
      "epoch: 2, batch: 1099,                 loss: 0.028938722013263033, training accuracy: 0.9915909090909091\n",
      "epoch: 2, batch: 1119,                 loss: 0.02872351064091033, training accuracy: 0.9916852678571428\n",
      "epoch: 2, batch: 1139,                 loss: 0.02924155437708179, training accuracy: 0.9915021929824561\n",
      "epoch: 2, batch: 1159,                 loss: 0.029010103166340208, training accuracy: 0.9915948275862069\n",
      "epoch: 2, batch: 1179,                 loss: 0.02903030011931166, training accuracy: 0.9915783898305085\n",
      "epoch: 2, batch: 1199,                 loss: 0.028975272876462742, training accuracy: 0.9916145833333333\n",
      "epoch: 2, batch: 1219,                 loss: 0.02884434048347862, training accuracy: 0.9916495901639344\n",
      "epoch: 2, batch: 1239,                 loss: 0.028732931017856896, training accuracy: 0.9916834677419355\n",
      "epoch: 2, batch: 1259,                 loss: 0.02859014557177452, training accuracy: 0.991765873015873\n",
      "epoch: 2, batch: 1279,                 loss: 0.028529617194999447, training accuracy: 0.991796875\n",
      "epoch: 2, batch: 1299,                 loss: 0.028498112982443462, training accuracy: 0.991875\n",
      "validation accuracy 0.9911\n",
      "test_accuracy 0.5311\n",
      "Saved weights/resnet34-epoch-1-valid_acc=0.9911-test_acc=0.5311.pt\n",
      "epoch: 3, batch: 19,                 loss: 0.01520607151906006, training accuracy: 0.996875\n",
      "epoch: 3, batch: 39,                 loss: 0.01714046211563982, training accuracy: 0.9984375\n",
      "epoch: 3, batch: 59,                 loss: 0.018334576782460015, training accuracy: 0.9958333333333333\n",
      "epoch: 3, batch: 79,                 loss: 0.01610652986128116, training accuracy: 0.996875\n",
      "epoch: 3, batch: 99,                 loss: 0.018427751815179364, training accuracy: 0.996875\n",
      "epoch: 3, batch: 119,                 loss: 0.029925750788728087, training accuracy: 0.9942708333333333\n",
      "epoch: 3, batch: 139,                 loss: 0.02811686324920239, training accuracy: 0.9946428571428572\n",
      "epoch: 3, batch: 159,                 loss: 0.025983134916896234, training accuracy: 0.9953125\n",
      "epoch: 3, batch: 179,                 loss: 0.024402847747680628, training accuracy: 0.9958333333333333\n",
      "epoch: 3, batch: 199,                 loss: 0.02515212269092444, training accuracy: 0.9953125\n",
      "epoch: 3, batch: 219,                 loss: 0.024696913150943477, training accuracy: 0.9951704545454545\n",
      "epoch: 3, batch: 239,                 loss: 0.023277734231669456, training accuracy: 0.9955729166666667\n",
      "epoch: 3, batch: 259,                 loss: 0.02289934761267012, training accuracy: 0.9956730769230769\n",
      "epoch: 3, batch: 279,                 loss: 0.02388640773382836, training accuracy: 0.9953125\n",
      "epoch: 3, batch: 299,                 loss: 0.022860746771330015, training accuracy: 0.995625\n",
      "epoch: 3, batch: 319,                 loss: 0.023108921364473643, training accuracy: 0.9953125\n",
      "epoch: 3, batch: 339,                 loss: 0.02241411061532905, training accuracy: 0.9955882352941177\n",
      "epoch: 3, batch: 359,                 loss: 0.02166465059708571, training accuracy: 0.9956597222222222\n",
      "epoch: 3, batch: 379,                 loss: 0.02099153427606277, training accuracy: 0.9958881578947368\n",
      "epoch: 3, batch: 399,                 loss: 0.020738175200094702, training accuracy: 0.99578125\n",
      "epoch: 3, batch: 419,                 loss: 0.020980098487260485, training accuracy: 0.9953869047619047\n",
      "epoch: 3, batch: 439,                 loss: 0.020868894064253917, training accuracy: 0.9953125\n",
      "epoch: 3, batch: 459,                 loss: 0.020191570831609527, training accuracy: 0.9955163043478261\n",
      "epoch: 3, batch: 479,                 loss: 0.01963256436077548, training accuracy: 0.995703125\n",
      "epoch: 3, batch: 499,                 loss: 0.019363867801846936, training accuracy: 0.99575\n",
      "epoch: 3, batch: 519,                 loss: 0.018916841396891797, training accuracy: 0.9959134615384615\n",
      "epoch: 3, batch: 539,                 loss: 0.018874232017831807, training accuracy: 0.9958333333333333\n",
      "epoch: 3, batch: 559,                 loss: 0.018729938077116717, training accuracy: 0.9958705357142857\n",
      "epoch: 3, batch: 579,                 loss: 0.0183820310773344, training accuracy: 0.9959051724137931\n",
      "epoch: 3, batch: 599,                 loss: 0.018097606713999993, training accuracy: 0.9960416666666667\n",
      "epoch: 3, batch: 619,                 loss: 0.018490230567535505, training accuracy: 0.995866935483871\n",
      "epoch: 3, batch: 639,                 loss: 0.018078591603807582, training accuracy: 0.99599609375\n",
      "epoch: 3, batch: 659,                 loss: 0.01774792686902043, training accuracy: 0.9961174242424242\n",
      "epoch: 3, batch: 679,                 loss: 0.0181958880946588, training accuracy: 0.9959558823529412\n",
      "epoch: 3, batch: 699,                 loss: 0.018099753436399624, training accuracy: 0.9958928571428571\n",
      "epoch: 3, batch: 719,                 loss: 0.018152829346783823, training accuracy: 0.9959201388888889\n",
      "epoch: 3, batch: 739,                 loss: 0.018145186708440904, training accuracy: 0.9958614864864865\n",
      "epoch: 3, batch: 759,                 loss: 0.018060596786764156, training accuracy: 0.9958881578947368\n",
      "epoch: 3, batch: 779,                 loss: 0.017919109698432762, training accuracy: 0.9959134615384615\n",
      "epoch: 3, batch: 799,                 loss: 0.017977841816973525, training accuracy: 0.9959375\n",
      "epoch: 3, batch: 819,                 loss: 0.01795614598029316, training accuracy: 0.9959603658536585\n",
      "epoch: 3, batch: 839,                 loss: 0.01810972784074866, training accuracy: 0.9958333333333333\n",
      "epoch: 3, batch: 859,                 loss: 0.018600230725065177, training accuracy: 0.9957122093023256\n",
      "epoch: 3, batch: 879,                 loss: 0.018405359463742405, training accuracy: 0.9958096590909091\n",
      "epoch: 3, batch: 899,                 loss: 0.018182409497999794, training accuracy: 0.9958333333333333\n",
      "epoch: 3, batch: 919,                 loss: 0.018134064617966624, training accuracy: 0.9958559782608696\n",
      "epoch: 3, batch: 939,                 loss: 0.017905752995779657, training accuracy: 0.995877659574468\n",
      "epoch: 3, batch: 959,                 loss: 0.017901412721463807, training accuracy: 0.9957682291666666\n",
      "epoch: 3, batch: 979,                 loss: 0.017887888533569284, training accuracy: 0.9957270408163266\n",
      "epoch: 3, batch: 999,                 loss: 0.017692070719029288, training accuracy: 0.99575\n",
      "epoch: 3, batch: 1019,                 loss: 0.018166785410493522, training accuracy: 0.9955882352941177\n",
      "epoch: 3, batch: 1039,                 loss: 0.01795512751257495, training accuracy: 0.9956730769230769\n",
      "epoch: 3, batch: 1059,                 loss: 0.017752925301177145, training accuracy: 0.995754716981132\n",
      "epoch: 3, batch: 1079,                 loss: 0.017598286893917247, training accuracy: 0.9957754629629629\n",
      "epoch: 3, batch: 1099,                 loss: 0.01754541222376495, training accuracy: 0.9956818181818182\n",
      "epoch: 3, batch: 1119,                 loss: 0.017640130716089126, training accuracy: 0.9955915178571428\n",
      "epoch: 3, batch: 1139,                 loss: 0.017439410250772835, training accuracy: 0.9956688596491228\n",
      "epoch: 3, batch: 1159,                 loss: 0.01752597081499046, training accuracy: 0.9956896551724138\n",
      "epoch: 3, batch: 1179,                 loss: 0.017573244449923257, training accuracy: 0.995603813559322\n",
      "epoch: 3, batch: 1199,                 loss: 0.01735731212577472, training accuracy: 0.9956770833333334\n",
      "epoch: 3, batch: 1219,                 loss: 0.01724680817879729, training accuracy: 0.9956967213114755\n",
      "epoch: 3, batch: 1239,                 loss: 0.017098371566070483, training accuracy: 0.9957157258064516\n",
      "epoch: 3, batch: 1259,                 loss: 0.017126392379600834, training accuracy: 0.9956845238095238\n",
      "epoch: 3, batch: 1279,                 loss: 0.016993088247591003, training accuracy: 0.995703125\n",
      "epoch: 3, batch: 1299,                 loss: 0.01682417252490548, training accuracy: 0.9957692307692307\n",
      "validation accuracy 0.9919\n",
      "test_accuracy 0.5366\n",
      "Saved weights/resnet34-epoch-2-valid_acc=0.9919-test_acc=0.5366.pt\n",
      "epoch: 4, batch: 19,                 loss: 0.009869158978108316, training accuracy: 0.996875\n",
      "epoch: 4, batch: 39,                 loss: 0.00768971239667735, training accuracy: 0.9984375\n",
      "epoch: 4, batch: 59,                 loss: 0.005917990315841355, training accuracy: 0.9989583333333333\n",
      "epoch: 4, batch: 79,                 loss: 0.005725086984966765, training accuracy: 0.99921875\n",
      "epoch: 4, batch: 99,                 loss: 0.007623931347916368, training accuracy: 0.998125\n",
      "epoch: 4, batch: 119,                 loss: 0.006711911305076986, training accuracy: 0.9984375\n",
      "epoch: 4, batch: 139,                 loss: 0.006442397144564893, training accuracy: 0.9982142857142857\n",
      "epoch: 4, batch: 159,                 loss: 0.006517638360855926, training accuracy: 0.9984375\n",
      "epoch: 4, batch: 179,                 loss: 0.006251061741851218, training accuracy: 0.9986111111111111\n",
      "epoch: 4, batch: 199,                 loss: 0.006075490516523132, training accuracy: 0.99875\n",
      "epoch: 4, batch: 219,                 loss: 0.005792282895708922, training accuracy: 0.9988636363636364\n",
      "epoch: 4, batch: 239,                 loss: 0.00591107761671689, training accuracy: 0.9986979166666666\n",
      "epoch: 4, batch: 259,                 loss: 0.005646714417917582, training accuracy: 0.9987980769230769\n",
      "epoch: 4, batch: 279,                 loss: 0.006424322223132809, training accuracy: 0.9984375\n",
      "epoch: 4, batch: 299,                 loss: 0.006885314812146438, training accuracy: 0.998125\n",
      "epoch: 4, batch: 319,                 loss: 0.006700304663172574, training accuracy: 0.9982421875\n",
      "epoch: 4, batch: 339,                 loss: 0.006795148606932558, training accuracy: 0.9983455882352941\n",
      "epoch: 4, batch: 359,                 loss: 0.0069704410693601756, training accuracy: 0.9982638888888888\n",
      "epoch: 4, batch: 379,                 loss: 0.00710025062565508, training accuracy: 0.9981907894736842\n",
      "epoch: 4, batch: 399,                 loss: 0.007836741346036433, training accuracy: 0.9978125\n",
      "epoch: 4, batch: 419,                 loss: 0.007770438151575425, training accuracy: 0.9979166666666667\n",
      "epoch: 4, batch: 439,                 loss: 0.007905122029478661, training accuracy: 0.9980113636363637\n",
      "epoch: 4, batch: 459,                 loss: 0.008298556308601173, training accuracy: 0.9979619565217391\n",
      "epoch: 4, batch: 479,                 loss: 0.008183064825061592, training accuracy: 0.998046875\n",
      "epoch: 4, batch: 499,                 loss: 0.008216665126266889, training accuracy: 0.998\n",
      "epoch: 4, batch: 519,                 loss: 0.008426615666002573, training accuracy: 0.9979567307692307\n",
      "epoch: 4, batch: 539,                 loss: 0.008584893101888829, training accuracy: 0.9979166666666667\n",
      "epoch: 4, batch: 559,                 loss: 0.008562771375155924, training accuracy: 0.9979910714285715\n",
      "epoch: 4, batch: 579,                 loss: 0.00861204782232907, training accuracy: 0.9980603448275862\n",
      "epoch: 4, batch: 599,                 loss: 0.008652231538386937, training accuracy: 0.9980208333333334\n",
      "epoch: 4, batch: 619,                 loss: 0.008515732953814985, training accuracy: 0.9980846774193548\n",
      "epoch: 4, batch: 639,                 loss: 0.008411975000808525, training accuracy: 0.99814453125\n",
      "epoch: 4, batch: 659,                 loss: 0.00871041731632872, training accuracy: 0.9980113636363637\n",
      "epoch: 4, batch: 679,                 loss: 0.008698006744902266, training accuracy: 0.9979779411764705\n",
      "epoch: 4, batch: 699,                 loss: 0.008666140118730254, training accuracy: 0.9979464285714286\n",
      "epoch: 4, batch: 719,                 loss: 0.008536116671651446, training accuracy: 0.9980034722222222\n",
      "epoch: 4, batch: 739,                 loss: 0.008410763472548334, training accuracy: 0.9980574324324324\n",
      "epoch: 4, batch: 759,                 loss: 0.008381439112341276, training accuracy: 0.9980263157894737\n",
      "epoch: 4, batch: 779,                 loss: 0.008249199716150402, training accuracy: 0.9980769230769231\n",
      "epoch: 4, batch: 799,                 loss: 0.008165208526479546, training accuracy: 0.998125\n",
      "epoch: 4, batch: 819,                 loss: 0.008277938174007165, training accuracy: 0.9980945121951219\n",
      "epoch: 4, batch: 839,                 loss: 0.00817771441472273, training accuracy: 0.9981398809523809\n",
      "epoch: 4, batch: 859,                 loss: 0.008038875418931765, training accuracy: 0.9981831395348837\n",
      "epoch: 4, batch: 879,                 loss: 0.008455810956035169, training accuracy: 0.9980823863636363\n",
      "epoch: 4, batch: 899,                 loss: 0.008389952223256437, training accuracy: 0.998125\n",
      "epoch: 4, batch: 919,                 loss: 0.008358873958312198, training accuracy: 0.9980978260869565\n",
      "epoch: 4, batch: 939,                 loss: 0.0082224750780176, training accuracy: 0.9981382978723404\n",
      "epoch: 4, batch: 959,                 loss: 0.00811997139411081, training accuracy: 0.9981770833333333\n",
      "epoch: 4, batch: 979,                 loss: 0.008201580878901913, training accuracy: 0.9980867346938775\n",
      "epoch: 4, batch: 999,                 loss: 0.008455984873726265, training accuracy: 0.998\n",
      "epoch: 4, batch: 1019,                 loss: 0.008446842711818331, training accuracy: 0.9980392156862745\n",
      "epoch: 4, batch: 1039,                 loss: 0.008410686498581735, training accuracy: 0.9980168269230769\n",
      "epoch: 4, batch: 1059,                 loss: 0.008313140442061133, training accuracy: 0.9980542452830189\n",
      "epoch: 4, batch: 1079,                 loss: 0.00824061189605682, training accuracy: 0.9980902777777778\n",
      "epoch: 4, batch: 1099,                 loss: 0.008141593726838686, training accuracy: 0.998125\n",
      "epoch: 4, batch: 1119,                 loss: 0.008365510736595232, training accuracy: 0.9981026785714285\n",
      "epoch: 4, batch: 1139,                 loss: 0.008291622221734367, training accuracy: 0.9981359649122807\n",
      "epoch: 4, batch: 1159,                 loss: 0.008725132545253566, training accuracy: 0.9980603448275862\n",
      "epoch: 4, batch: 1179,                 loss: 0.008909390398332754, training accuracy: 0.9980402542372881\n",
      "epoch: 4, batch: 1199,                 loss: 0.008811147044568013, training accuracy: 0.9980729166666666\n",
      "epoch: 4, batch: 1219,                 loss: 0.008741081169411372, training accuracy: 0.9981045081967214\n",
      "epoch: 4, batch: 1239,                 loss: 0.008669930739063515, training accuracy: 0.9981350806451613\n",
      "epoch: 4, batch: 1259,                 loss: 0.008623008734855196, training accuracy: 0.9981646825396825\n",
      "epoch: 4, batch: 1279,                 loss: 0.008560838379139568, training accuracy: 0.998193359375\n",
      "epoch: 4, batch: 1299,                 loss: 0.008506327655430562, training accuracy: 0.9982211538461538\n",
      "validation accuracy 0.9936\n",
      "test_accuracy 0.5423\n",
      "Saved weights/resnet34-epoch-3-valid_acc=0.9936-test_acc=0.5423.pt\n",
      "epoch: 5, batch: 19,                 loss: 0.0023843094415497033, training accuracy: 1.0\n",
      "epoch: 5, batch: 39,                 loss: 0.004796488818828948, training accuracy: 0.9984375\n",
      "epoch: 5, batch: 59,                 loss: 0.003998553723067744, training accuracy: 0.9989583333333333\n",
      "epoch: 5, batch: 79,                 loss: 0.003645342446725408, training accuracy: 0.99921875\n",
      "epoch: 5, batch: 99,                 loss: 0.0038496923378261274, training accuracy: 0.999375\n",
      "epoch: 5, batch: 119,                 loss: 0.004296533683494393, training accuracy: 0.9994791666666667\n",
      "epoch: 5, batch: 139,                 loss: 0.004032327184540918, training accuracy: 0.9995535714285714\n",
      "epoch: 5, batch: 159,                 loss: 0.004125930110058107, training accuracy: 0.999609375\n",
      "epoch: 5, batch: 179,                 loss: 0.007781887964908188, training accuracy: 0.9986111111111111\n",
      "epoch: 5, batch: 199,                 loss: 0.007292453244590433, training accuracy: 0.99875\n",
      "epoch: 5, batch: 219,                 loss: 0.007875150472682436, training accuracy: 0.9985795454545454\n",
      "epoch: 5, batch: 239,                 loss: 0.007763066055364713, training accuracy: 0.9986979166666666\n",
      "epoch: 5, batch: 259,                 loss: 0.007449766379096008, training accuracy: 0.9987980769230769\n",
      "epoch: 5, batch: 279,                 loss: 0.007409564082523242, training accuracy: 0.9986607142857142\n",
      "epoch: 5, batch: 299,                 loss: 0.007077640681042491, training accuracy: 0.99875\n",
      "epoch: 5, batch: 319,                 loss: 0.006893304527784494, training accuracy: 0.998828125\n",
      "epoch: 5, batch: 339,                 loss: 0.007027714526510167, training accuracy: 0.9987132352941176\n",
      "epoch: 5, batch: 359,                 loss: 0.006783095217219347, training accuracy: 0.9987847222222223\n",
      "epoch: 5, batch: 379,                 loss: 0.006719572940001901, training accuracy: 0.9988486842105263\n",
      "epoch: 5, batch: 399,                 loss: 0.0065710898940596965, training accuracy: 0.99890625\n",
      "epoch: 5, batch: 419,                 loss: 0.00666343476727239, training accuracy: 0.9988095238095238\n",
      "epoch: 5, batch: 439,                 loss: 0.006471404268185407, training accuracy: 0.9988636363636364\n",
      "epoch: 5, batch: 459,                 loss: 0.00672895451200969, training accuracy: 0.9987771739130434\n",
      "epoch: 5, batch: 479,                 loss: 0.0066984716719465116, training accuracy: 0.998828125\n",
      "epoch: 5, batch: 499,                 loss: 0.006574696934985695, training accuracy: 0.998875\n",
      "epoch: 5, batch: 519,                 loss: 0.006513765257589582, training accuracy: 0.9989182692307692\n",
      "epoch: 5, batch: 539,                 loss: 0.006582211605698965, training accuracy: 0.9988425925925926\n",
      "epoch: 5, batch: 559,                 loss: 0.006542354633633555, training accuracy: 0.9987723214285714\n",
      "epoch: 5, batch: 579,                 loss: 0.006400522440426043, training accuracy: 0.9988146551724137\n",
      "epoch: 5, batch: 599,                 loss: 0.006391706858072818, training accuracy: 0.99875\n",
      "epoch: 5, batch: 619,                 loss: 0.0065953673103414925, training accuracy: 0.9985887096774193\n",
      "epoch: 5, batch: 639,                 loss: 0.007323115285862514, training accuracy: 0.99814453125\n",
      "epoch: 5, batch: 659,                 loss: 0.007358863939236581, training accuracy: 0.9980113636363637\n",
      "epoch: 5, batch: 679,                 loss: 0.007824300058093607, training accuracy: 0.9977941176470588\n",
      "epoch: 5, batch: 699,                 loss: 0.007704739911465108, training accuracy: 0.9978571428571429\n",
      "epoch: 5, batch: 719,                 loss: 0.007626054149780733, training accuracy: 0.9979166666666667\n",
      "epoch: 5, batch: 739,                 loss: 0.007683573631456474, training accuracy: 0.9978885135135135\n",
      "epoch: 5, batch: 759,                 loss: 0.007587621730444401, training accuracy: 0.9978618421052632\n",
      "epoch: 5, batch: 779,                 loss: 0.007503693270868658, training accuracy: 0.9979166666666667\n",
      "epoch: 5, batch: 799,                 loss: 0.007377466165235091, training accuracy: 0.99796875\n",
      "epoch: 5, batch: 819,                 loss: 0.0073160772844325615, training accuracy: 0.9979420731707317\n",
      "epoch: 5, batch: 839,                 loss: 0.007626158793573268, training accuracy: 0.9978422619047619\n",
      "epoch: 5, batch: 859,                 loss: 0.007610909175533844, training accuracy: 0.9978197674418605\n",
      "epoch: 5, batch: 879,                 loss: 0.0075544563857957575, training accuracy: 0.9977982954545455\n",
      "epoch: 5, batch: 899,                 loss: 0.007440542146553829, training accuracy: 0.9978472222222222\n",
      "epoch: 5, batch: 919,                 loss: 0.007693394005653555, training accuracy: 0.9978260869565218\n",
      "epoch: 5, batch: 939,                 loss: 0.007739686080551225, training accuracy: 0.9978058510638298\n",
      "epoch: 5, batch: 959,                 loss: 0.007661180248487653, training accuracy: 0.9978515625\n",
      "epoch: 5, batch: 979,                 loss: 0.007541124678272707, training accuracy: 0.9978954081632653\n",
      "epoch: 5, batch: 999,                 loss: 0.00791288484839606, training accuracy: 0.9978125\n",
      "epoch: 5, batch: 1019,                 loss: 0.007900714010340345, training accuracy: 0.9977941176470588\n",
      "epoch: 5, batch: 1039,                 loss: 0.0077976257380494365, training accuracy: 0.9978365384615384\n",
      "epoch: 5, batch: 1059,                 loss: 0.007705972899484035, training accuracy: 0.997877358490566\n",
      "epoch: 5, batch: 1079,                 loss: 0.007732002854700787, training accuracy: 0.9978587962962963\n",
      "epoch: 5, batch: 1099,                 loss: 0.007672644658080323, training accuracy: 0.9978409090909091\n",
      "epoch: 5, batch: 1119,                 loss: 0.0076430798953879275, training accuracy: 0.9978236607142857\n",
      "epoch: 5, batch: 1139,                 loss: 0.0076837778009991, training accuracy: 0.9977521929824561\n",
      "epoch: 5, batch: 1159,                 loss: 0.007733354670425139, training accuracy: 0.9977370689655173\n",
      "epoch: 5, batch: 1179,                 loss: 0.007958211036748254, training accuracy: 0.9976694915254237\n",
      "epoch: 5, batch: 1199,                 loss: 0.007900010020603077, training accuracy: 0.9977083333333333\n",
      "epoch: 5, batch: 1219,                 loss: 0.007867531694512868, training accuracy: 0.9976946721311475\n",
      "epoch: 5, batch: 1239,                 loss: 0.00783272082257862, training accuracy: 0.9977318548387096\n",
      "epoch: 5, batch: 1259,                 loss: 0.007867786550126593, training accuracy: 0.997718253968254\n",
      "epoch: 5, batch: 1279,                 loss: 0.007788722718191821, training accuracy: 0.99775390625\n",
      "epoch: 5, batch: 1299,                 loss: 0.007971131489343511, training accuracy: 0.9976923076923077\n",
      "validation accuracy 0.9932\n",
      "test_accuracy 0.5298\n",
      "Saved weights/resnet34-epoch-4-valid_acc=0.9932-test_acc=0.5298.pt\n",
      "epoch: 6, batch: 19,                 loss: 0.002769717064802535, training accuracy: 1.0\n",
      "epoch: 6, batch: 39,                 loss: 0.00451445854632766, training accuracy: 1.0\n",
      "epoch: 6, batch: 59,                 loss: 0.008165494420488055, training accuracy: 0.9989583333333333\n",
      "epoch: 6, batch: 79,                 loss: 0.007286692421257612, training accuracy: 0.9984375\n",
      "epoch: 6, batch: 99,                 loss: 0.006237902070279233, training accuracy: 0.99875\n",
      "epoch: 6, batch: 119,                 loss: 0.006033257140613083, training accuracy: 0.9989583333333333\n",
      "epoch: 6, batch: 139,                 loss: 0.005472959248956093, training accuracy: 0.9991071428571429\n",
      "epoch: 6, batch: 159,                 loss: 0.005066006079869112, training accuracy: 0.99921875\n",
      "epoch: 6, batch: 179,                 loss: 0.005794664366920996, training accuracy: 0.9989583333333333\n",
      "epoch: 6, batch: 199,                 loss: 0.0053826709564600604, training accuracy: 0.9990625\n",
      "epoch: 6, batch: 219,                 loss: 0.005346284363556399, training accuracy: 0.9991477272727273\n",
      "epoch: 6, batch: 239,                 loss: 0.00530544764969818, training accuracy: 0.99921875\n",
      "epoch: 6, batch: 259,                 loss: 0.005041555434525855, training accuracy: 0.9992788461538461\n",
      "epoch: 6, batch: 279,                 loss: 0.0050304929522618684, training accuracy: 0.9991071428571429\n",
      "epoch: 6, batch: 299,                 loss: 0.004849664644425502, training accuracy: 0.9991666666666666\n",
      "epoch: 6, batch: 319,                 loss: 0.004723334601703755, training accuracy: 0.99921875\n",
      "epoch: 6, batch: 339,                 loss: 0.0045181730581509115, training accuracy: 0.9992647058823529\n",
      "epoch: 6, batch: 359,                 loss: 0.004396830055581328, training accuracy: 0.9993055555555556\n",
      "epoch: 6, batch: 379,                 loss: 0.005121673076600449, training accuracy: 0.9990131578947369\n",
      "epoch: 6, batch: 399,                 loss: 0.005444231783330906, training accuracy: 0.99890625\n",
      "epoch: 6, batch: 419,                 loss: 0.005791402343727116, training accuracy: 0.9988095238095238\n",
      "epoch: 6, batch: 439,                 loss: 0.00561084034558338, training accuracy: 0.9988636363636364\n",
      "epoch: 6, batch: 459,                 loss: 0.005609368265805128, training accuracy: 0.9989130434782608\n",
      "epoch: 6, batch: 479,                 loss: 0.005470624374872083, training accuracy: 0.9989583333333333\n",
      "epoch: 6, batch: 499,                 loss: 0.005405397018854273, training accuracy: 0.999\n",
      "epoch: 6, batch: 519,                 loss: 0.005690867542552251, training accuracy: 0.9989182692307692\n",
      "epoch: 6, batch: 539,                 loss: 0.005770360497640299, training accuracy: 0.9988425925925926\n",
      "epoch: 6, batch: 559,                 loss: 0.005683619519394207, training accuracy: 0.9988839285714286\n",
      "epoch: 6, batch: 579,                 loss: 0.00559634607589346, training accuracy: 0.9989224137931034\n",
      "epoch: 6, batch: 599,                 loss: 0.005535822653522094, training accuracy: 0.9989583333333333\n",
      "epoch: 6, batch: 619,                 loss: 0.005641458978812631, training accuracy: 0.9987903225806452\n",
      "epoch: 6, batch: 639,                 loss: 0.005515305714516217, training accuracy: 0.998828125\n",
      "epoch: 6, batch: 659,                 loss: 0.005465856936202864, training accuracy: 0.9988636363636364\n",
      "epoch: 6, batch: 679,                 loss: 0.005412090550560285, training accuracy: 0.9988970588235294\n",
      "epoch: 6, batch: 699,                 loss: 0.0055127188275218945, training accuracy: 0.9988392857142857\n",
      "epoch: 6, batch: 719,                 loss: 0.005573968266455469, training accuracy: 0.9987847222222223\n",
      "epoch: 6, batch: 739,                 loss: 0.005461710188211401, training accuracy: 0.9988175675675676\n",
      "epoch: 6, batch: 759,                 loss: 0.005905845555638447, training accuracy: 0.9986842105263158\n",
      "epoch: 6, batch: 779,                 loss: 0.005914664608616687, training accuracy: 0.9986378205128205\n",
      "epoch: 6, batch: 799,                 loss: 0.006108989556723827, training accuracy: 0.99859375\n",
      "epoch: 6, batch: 819,                 loss: 0.006025213473114447, training accuracy: 0.9986280487804878\n",
      "epoch: 6, batch: 839,                 loss: 0.006092613032454946, training accuracy: 0.9985119047619048\n",
      "epoch: 6, batch: 859,                 loss: 0.006183367643977765, training accuracy: 0.9984011627906977\n",
      "epoch: 6, batch: 879,                 loss: 0.006269155054492744, training accuracy: 0.9983664772727273\n",
      "epoch: 6, batch: 899,                 loss: 0.0062015479236045695, training accuracy: 0.9984027777777778\n",
      "epoch: 6, batch: 919,                 loss: 0.006158049443120431, training accuracy: 0.9983695652173913\n",
      "epoch: 6, batch: 939,                 loss: 0.0063547298935597435, training accuracy: 0.9982712765957447\n",
      "epoch: 6, batch: 959,                 loss: 0.006270704969422999, training accuracy: 0.9983072916666667\n",
      "epoch: 6, batch: 979,                 loss: 0.006330859591074915, training accuracy: 0.9982142857142857\n",
      "epoch: 6, batch: 999,                 loss: 0.0062752976469928395, training accuracy: 0.99825\n",
      "epoch: 6, batch: 1019,                 loss: 0.006187619543697128, training accuracy: 0.9982843137254902\n",
      "epoch: 6, batch: 1039,                 loss: 0.006105223536584302, training accuracy: 0.9983173076923076\n",
      "epoch: 6, batch: 1059,                 loss: 0.006019476920372877, training accuracy: 0.9983490566037736\n",
      "epoch: 6, batch: 1079,                 loss: 0.005934431703334903, training accuracy: 0.9983796296296297\n",
      "epoch: 6, batch: 1099,                 loss: 0.0059183767774745565, training accuracy: 0.9984090909090909\n",
      "epoch: 6, batch: 1119,                 loss: 0.0058471498495237025, training accuracy: 0.9984375\n",
      "epoch: 6, batch: 1139,                 loss: 0.006221091093175346, training accuracy: 0.9983004385964912\n",
      "epoch: 6, batch: 1159,                 loss: 0.006190250335215563, training accuracy: 0.9983297413793103\n",
      "epoch: 6, batch: 1179,                 loss: 0.006201673706737446, training accuracy: 0.9983580508474577\n",
      "epoch: 6, batch: 1199,                 loss: 0.006159309016426657, training accuracy: 0.9983854166666667\n",
      "epoch: 6, batch: 1219,                 loss: 0.006121027708465336, training accuracy: 0.9984118852459016\n",
      "epoch: 6, batch: 1239,                 loss: 0.0060547745555654285, training accuracy: 0.9984375\n",
      "epoch: 6, batch: 1259,                 loss: 0.006024821629179069, training accuracy: 0.9984623015873015\n",
      "epoch: 6, batch: 1279,                 loss: 0.005954864264526805, training accuracy: 0.998486328125\n",
      "epoch: 6, batch: 1299,                 loss: 0.005889562321972335, training accuracy: 0.9985096153846154\n",
      "validation accuracy 0.9957\n",
      "test_accuracy 0.5403\n",
      "Saved weights/resnet34-epoch-5-valid_acc=0.9957-test_acc=0.5403.pt\n",
      "Finished Training: resnet34\n",
      "epoch: 1, batch: 19,                 loss: 0.6545679926872253, training accuracy: 0.59375\n",
      "epoch: 1, batch: 39,                 loss: 0.5875716589391231, training accuracy: 0.7109375\n",
      "epoch: 1, batch: 59,                 loss: 0.5278129244844119, training accuracy: 0.7677083333333333\n",
      "epoch: 1, batch: 79,                 loss: 0.4721170239150524, training accuracy: 0.80625\n",
      "epoch: 1, batch: 99,                 loss: 0.4302856485545635, training accuracy: 0.83\n",
      "epoch: 1, batch: 119,                 loss: 0.39280580009023347, training accuracy: 0.8489583333333334\n",
      "epoch: 1, batch: 139,                 loss: 0.3680404889264277, training accuracy: 0.859375\n",
      "epoch: 1, batch: 159,                 loss: 0.3449621892068535, training accuracy: 0.87109375\n",
      "epoch: 1, batch: 179,                 loss: 0.3218157406275471, training accuracy: 0.8805555555555555\n",
      "epoch: 1, batch: 199,                 loss: 0.3039946273714304, training accuracy: 0.8878125\n",
      "epoch: 1, batch: 219,                 loss: 0.2874741792678833, training accuracy: 0.8946022727272728\n",
      "epoch: 1, batch: 239,                 loss: 0.2705176843640705, training accuracy: 0.90234375\n",
      "epoch: 1, batch: 259,                 loss: 0.2595873645865, training accuracy: 0.9069711538461539\n",
      "epoch: 1, batch: 279,                 loss: 0.2490193528389292, training accuracy: 0.9109375\n",
      "epoch: 1, batch: 299,                 loss: 0.23811109395697713, training accuracy: 0.9152083333333333\n",
      "epoch: 1, batch: 319,                 loss: 0.22711906852782704, training accuracy: 0.9197265625\n",
      "epoch: 1, batch: 339,                 loss: 0.21927379663376248, training accuracy: 0.9226102941176471\n",
      "epoch: 1, batch: 359,                 loss: 0.21259137235788836, training accuracy: 0.9255208333333333\n",
      "epoch: 1, batch: 379,                 loss: 0.2071704095254015, training accuracy: 0.9271381578947369\n",
      "epoch: 1, batch: 399,                 loss: 0.20186856183689086, training accuracy: 0.92921875\n",
      "epoch: 1, batch: 419,                 loss: 0.19757857130663026, training accuracy: 0.9306547619047619\n",
      "epoch: 1, batch: 439,                 loss: 0.19373001889114014, training accuracy: 0.9323863636363636\n",
      "epoch: 1, batch: 459,                 loss: 0.18948415907342797, training accuracy: 0.9338315217391304\n",
      "epoch: 1, batch: 479,                 loss: 0.1844918648363091, training accuracy: 0.9358072916666667\n",
      "epoch: 1, batch: 499,                 loss: 0.18022841185890137, training accuracy: 0.937125\n",
      "epoch: 1, batch: 519,                 loss: 0.17660929407888593, training accuracy: 0.9384615384615385\n",
      "epoch: 1, batch: 539,                 loss: 0.17312833244601886, training accuracy: 0.939699074074074\n",
      "epoch: 1, batch: 559,                 loss: 0.16951802001234942, training accuracy: 0.9410714285714286\n",
      "epoch: 1, batch: 579,                 loss: 0.1654098335782002, training accuracy: 0.9424568965517242\n",
      "epoch: 1, batch: 599,                 loss: 0.16275687752602, training accuracy: 0.9435416666666666\n",
      "epoch: 1, batch: 619,                 loss: 0.1593566002669714, training accuracy: 0.944758064516129\n",
      "epoch: 1, batch: 639,                 loss: 0.15668682326504496, training accuracy: 0.9455078125\n",
      "epoch: 1, batch: 659,                 loss: 0.15328713896627905, training accuracy: 0.946780303030303\n",
      "epoch: 1, batch: 679,                 loss: 0.1513103065039853, training accuracy: 0.947702205882353\n",
      "epoch: 1, batch: 699,                 loss: 0.1485478672671265, training accuracy: 0.94875\n",
      "epoch: 1, batch: 719,                 loss: 0.1461363939186817, training accuracy: 0.9498263888888889\n",
      "epoch: 1, batch: 739,                 loss: 0.1440788939538588, training accuracy: 0.9505912162162162\n",
      "epoch: 1, batch: 759,                 loss: 0.14159935319820713, training accuracy: 0.9513980263157895\n",
      "epoch: 1, batch: 779,                 loss: 0.1397110048042706, training accuracy: 0.9519230769230769\n",
      "epoch: 1, batch: 799,                 loss: 0.13817980746389366, training accuracy: 0.95234375\n",
      "epoch: 1, batch: 819,                 loss: 0.13656034510946127, training accuracy: 0.9529725609756098\n",
      "epoch: 1, batch: 839,                 loss: 0.13417676115308755, training accuracy: 0.9537946428571429\n",
      "epoch: 1, batch: 859,                 loss: 0.13402357300862583, training accuracy: 0.9539244186046512\n",
      "epoch: 1, batch: 879,                 loss: 0.13228179971126586, training accuracy: 0.9544744318181818\n",
      "epoch: 1, batch: 899,                 loss: 0.1301694955661272, training accuracy: 0.9552083333333333\n",
      "epoch: 1, batch: 919,                 loss: 0.1287670170731397, training accuracy: 0.9557065217391304\n",
      "epoch: 1, batch: 939,                 loss: 0.12720850411099086, training accuracy: 0.9561835106382979\n",
      "epoch: 1, batch: 959,                 loss: 0.1258782748419132, training accuracy: 0.956640625\n",
      "epoch: 1, batch: 979,                 loss: 0.12449002992171718, training accuracy: 0.9570790816326531\n",
      "epoch: 1, batch: 999,                 loss: 0.12262235872307792, training accuracy: 0.957875\n",
      "epoch: 1, batch: 1019,                 loss: 0.12086382273255902, training accuracy: 0.9585784313725491\n",
      "epoch: 1, batch: 1039,                 loss: 0.11952861979818688, training accuracy: 0.9590745192307693\n",
      "epoch: 1, batch: 1059,                 loss: 0.11843087045554915, training accuracy: 0.9594339622641509\n",
      "epoch: 1, batch: 1079,                 loss: 0.11707780908241316, training accuracy: 0.9598958333333333\n",
      "epoch: 1, batch: 1099,                 loss: 0.116172053639523, training accuracy: 0.9602272727272727\n",
      "epoch: 1, batch: 1119,                 loss: 0.11489324070945649, training accuracy: 0.9607142857142857\n",
      "epoch: 1, batch: 1139,                 loss: 0.11452536559908798, training accuracy: 0.9610197368421053\n",
      "epoch: 1, batch: 1159,                 loss: 0.1130941635154284, training accuracy: 0.961584051724138\n",
      "epoch: 1, batch: 1179,                 loss: 0.11177778904862955, training accuracy: 0.9620762711864407\n",
      "epoch: 1, batch: 1199,                 loss: 0.1106809196768639, training accuracy: 0.9625520833333333\n",
      "epoch: 1, batch: 1219,                 loss: 0.10937575470450044, training accuracy: 0.9629098360655738\n",
      "epoch: 1, batch: 1239,                 loss: 0.10841122540953238, training accuracy: 0.9632560483870968\n",
      "epoch: 1, batch: 1259,                 loss: 0.10721917713304893, training accuracy: 0.963640873015873\n",
      "epoch: 1, batch: 1279,                 loss: 0.10593644971868343, training accuracy: 0.96416015625\n",
      "epoch: 1, batch: 1299,                 loss: 0.10463435003050388, training accuracy: 0.9646634615384615\n",
      "validation accuracy 0.9864\n",
      "test_accuracy 0.5804\n",
      "Saved weights/resnet50-epoch-0-valid_acc=0.9864-test_acc=0.5804.pt\n",
      "epoch: 2, batch: 19,                 loss: 0.028106081997975707, training accuracy: 0.990625\n",
      "epoch: 2, batch: 39,                 loss: 0.026150297187268735, training accuracy: 0.9921875\n",
      "epoch: 2, batch: 59,                 loss: 0.024165829992853105, training accuracy: 0.99375\n",
      "epoch: 2, batch: 79,                 loss: 0.023436044016852974, training accuracy: 0.99375\n",
      "epoch: 2, batch: 99,                 loss: 0.022237886283546685, training accuracy: 0.99375\n",
      "epoch: 2, batch: 119,                 loss: 0.023408218925275528, training accuracy: 0.9932291666666667\n",
      "epoch: 2, batch: 139,                 loss: 0.02449163448930319, training accuracy: 0.9924107142857143\n",
      "epoch: 2, batch: 159,                 loss: 0.025996574673627038, training accuracy: 0.9921875\n",
      "epoch: 2, batch: 179,                 loss: 0.026087789423763753, training accuracy: 0.9920138888888889\n",
      "epoch: 2, batch: 199,                 loss: 0.025722278220346197, training accuracy: 0.9925\n",
      "epoch: 2, batch: 219,                 loss: 0.025550184918525204, training accuracy: 0.9926136363636363\n",
      "epoch: 2, batch: 239,                 loss: 0.02530439208203461, training accuracy: 0.9924479166666667\n",
      "epoch: 2, batch: 259,                 loss: 0.024761858781298194, training accuracy: 0.9925480769230769\n",
      "epoch: 2, batch: 279,                 loss: 0.025578122330729716, training accuracy: 0.9921875\n",
      "epoch: 2, batch: 299,                 loss: 0.027348089268586288, training accuracy: 0.9910416666666667\n",
      "epoch: 2, batch: 319,                 loss: 0.027644381806749153, training accuracy: 0.991015625\n",
      "epoch: 2, batch: 339,                 loss: 0.026629794962183737, training accuracy: 0.9915441176470589\n",
      "epoch: 2, batch: 359,                 loss: 0.02630862039513886, training accuracy: 0.9916666666666667\n",
      "epoch: 2, batch: 379,                 loss: 0.026216977228729153, training accuracy: 0.9916118421052632\n",
      "epoch: 2, batch: 399,                 loss: 0.025563016712549142, training accuracy: 0.99203125\n",
      "epoch: 2, batch: 419,                 loss: 0.025879880833062564, training accuracy: 0.9919642857142857\n",
      "epoch: 2, batch: 439,                 loss: 0.02615972091814249, training accuracy: 0.9919034090909091\n",
      "epoch: 2, batch: 459,                 loss: 0.02593066758506567, training accuracy: 0.9919836956521739\n",
      "epoch: 2, batch: 479,                 loss: 0.025168956867128146, training accuracy: 0.9923177083333333\n",
      "epoch: 2, batch: 499,                 loss: 0.025008533040061592, training accuracy: 0.992375\n",
      "epoch: 2, batch: 519,                 loss: 0.02510908782312002, training accuracy: 0.9921875\n",
      "epoch: 2, batch: 539,                 loss: 0.024997728926353848, training accuracy: 0.9922453703703704\n",
      "epoch: 2, batch: 559,                 loss: 0.025028432980096632, training accuracy: 0.9924107142857143\n",
      "epoch: 2, batch: 579,                 loss: 0.02467825889310414, training accuracy: 0.9925646551724138\n",
      "epoch: 2, batch: 599,                 loss: 0.02447900128628438, training accuracy: 0.9926041666666666\n",
      "epoch: 2, batch: 619,                 loss: 0.024903309652431597, training accuracy: 0.9923387096774193\n",
      "epoch: 2, batch: 639,                 loss: 0.024522538114979398, training accuracy: 0.99248046875\n",
      "epoch: 2, batch: 659,                 loss: 0.02438129823386782, training accuracy: 0.9924242424242424\n",
      "epoch: 2, batch: 679,                 loss: 0.02398513579665793, training accuracy: 0.9924632352941176\n",
      "epoch: 2, batch: 699,                 loss: 0.0248022016064663, training accuracy: 0.9922321428571429\n",
      "epoch: 2, batch: 719,                 loss: 0.02446014774355313, training accuracy: 0.9923611111111111\n",
      "epoch: 2, batch: 739,                 loss: 0.024828869181785833, training accuracy: 0.9922297297297298\n",
      "epoch: 2, batch: 759,                 loss: 0.025240153098773015, training accuracy: 0.9922697368421053\n",
      "epoch: 2, batch: 779,                 loss: 0.025010390551342892, training accuracy: 0.9923878205128205\n",
      "epoch: 2, batch: 799,                 loss: 0.025308390059362865, training accuracy: 0.992109375\n",
      "epoch: 2, batch: 819,                 loss: 0.024929137470728786, training accuracy: 0.9922256097560975\n",
      "epoch: 2, batch: 839,                 loss: 0.02477111037601606, training accuracy: 0.9922619047619048\n",
      "epoch: 2, batch: 859,                 loss: 0.024774928806555394, training accuracy: 0.992296511627907\n",
      "epoch: 2, batch: 879,                 loss: 0.024821728504453362, training accuracy: 0.9922585227272728\n",
      "epoch: 2, batch: 899,                 loss: 0.02499921305855322, training accuracy: 0.9922916666666667\n",
      "epoch: 2, batch: 919,                 loss: 0.024838597278373883, training accuracy: 0.9923913043478261\n",
      "epoch: 2, batch: 939,                 loss: 0.02472213018844102, training accuracy: 0.9924202127659575\n",
      "epoch: 2, batch: 959,                 loss: 0.024601642757625088, training accuracy: 0.9923828125\n",
      "epoch: 2, batch: 979,                 loss: 0.0248762174706659, training accuracy: 0.9923469387755102\n",
      "epoch: 2, batch: 999,                 loss: 0.024740723266848362, training accuracy: 0.9924375\n",
      "epoch: 2, batch: 1019,                 loss: 0.024952756669874503, training accuracy: 0.9924019607843138\n",
      "epoch: 2, batch: 1039,                 loss: 0.02511313784142168, training accuracy: 0.9923076923076923\n",
      "epoch: 2, batch: 1059,                 loss: 0.025021553609107253, training accuracy: 0.9923349056603774\n",
      "epoch: 2, batch: 1079,                 loss: 0.025782523851376027, training accuracy: 0.9920717592592593\n",
      "epoch: 2, batch: 1099,                 loss: 0.025502202169525184, training accuracy: 0.9921590909090909\n",
      "epoch: 2, batch: 1119,                 loss: 0.025401356386906368, training accuracy: 0.9922433035714285\n",
      "epoch: 2, batch: 1139,                 loss: 0.025612028813492015, training accuracy: 0.9922149122807018\n",
      "epoch: 2, batch: 1159,                 loss: 0.026316711980877604, training accuracy: 0.9920258620689655\n",
      "epoch: 2, batch: 1179,                 loss: 0.02626183923497654, training accuracy: 0.9920550847457628\n",
      "epoch: 2, batch: 1199,                 loss: 0.02597290685031718, training accuracy: 0.9921875\n",
      "epoch: 2, batch: 1219,                 loss: 0.02589604948765644, training accuracy: 0.9922131147540983\n",
      "epoch: 2, batch: 1239,                 loss: 0.02610016899294175, training accuracy: 0.9920866935483871\n",
      "epoch: 2, batch: 1259,                 loss: 0.025830286537345114, training accuracy: 0.9922123015873016\n",
      "epoch: 2, batch: 1279,                 loss: 0.025859405051869545, training accuracy: 0.992236328125\n",
      "epoch: 2, batch: 1299,                 loss: 0.02577937491094837, training accuracy: 0.9922115384615384\n",
      "validation accuracy 0.986\n",
      "test_accuracy 0.5977\n",
      "Saved weights/resnet50-epoch-1-valid_acc=0.986-test_acc=0.5977.pt\n",
      "epoch: 3, batch: 19,                 loss: 0.011709805025020614, training accuracy: 0.996875\n",
      "epoch: 3, batch: 39,                 loss: 0.027842710961704143, training accuracy: 0.9890625\n",
      "epoch: 3, batch: 59,                 loss: 0.022697462872990095, training accuracy: 0.9927083333333333\n",
      "epoch: 3, batch: 79,                 loss: 0.021269314183155075, training accuracy: 0.99375\n",
      "epoch: 3, batch: 99,                 loss: 0.02088970101904124, training accuracy: 0.99375\n",
      "epoch: 3, batch: 119,                 loss: 0.01958777051331708, training accuracy: 0.9942708333333333\n",
      "epoch: 3, batch: 139,                 loss: 0.01840815316411733, training accuracy: 0.9946428571428572\n",
      "epoch: 3, batch: 159,                 loss: 0.01800796963107132, training accuracy: 0.994921875\n",
      "epoch: 3, batch: 179,                 loss: 0.0181696556201334, training accuracy: 0.9947916666666666\n",
      "epoch: 3, batch: 199,                 loss: 0.017795384269265923, training accuracy: 0.995\n",
      "epoch: 3, batch: 219,                 loss: 0.01724391561027997, training accuracy: 0.9951704545454545\n",
      "epoch: 3, batch: 239,                 loss: 0.016467329825051516, training accuracy: 0.9955729166666667\n",
      "epoch: 3, batch: 259,                 loss: 0.015964303747526942, training accuracy: 0.9959134615384615\n",
      "epoch: 3, batch: 279,                 loss: 0.015504778271133546, training accuracy: 0.9959821428571428\n",
      "epoch: 3, batch: 299,                 loss: 0.015749717645812778, training accuracy: 0.9958333333333333\n",
      "epoch: 3, batch: 319,                 loss: 0.015577738706269884, training accuracy: 0.9958984375\n",
      "epoch: 3, batch: 339,                 loss: 0.015584072960294126, training accuracy: 0.9955882352941177\n",
      "epoch: 3, batch: 359,                 loss: 0.015032545592112001, training accuracy: 0.9956597222222222\n",
      "epoch: 3, batch: 379,                 loss: 0.01552218142391403, training accuracy: 0.9957236842105263\n",
      "epoch: 3, batch: 399,                 loss: 0.015200763043103506, training accuracy: 0.99578125\n",
      "epoch: 3, batch: 419,                 loss: 0.014685063311065148, training accuracy: 0.9959821428571428\n",
      "epoch: 3, batch: 439,                 loss: 0.014509447513079398, training accuracy: 0.9961647727272728\n",
      "epoch: 3, batch: 459,                 loss: 0.014085571002468223, training accuracy: 0.9963315217391304\n",
      "epoch: 3, batch: 479,                 loss: 0.013770419730280991, training accuracy: 0.996484375\n",
      "epoch: 3, batch: 499,                 loss: 0.013837308540125378, training accuracy: 0.996375\n",
      "epoch: 3, batch: 519,                 loss: 0.014533454481324252, training accuracy: 0.9961538461538462\n",
      "epoch: 3, batch: 539,                 loss: 0.014537074418277134, training accuracy: 0.9960648148148148\n",
      "epoch: 3, batch: 559,                 loss: 0.014623570064577507, training accuracy: 0.99609375\n",
      "epoch: 3, batch: 579,                 loss: 0.014723568791644005, training accuracy: 0.9960129310344827\n",
      "epoch: 3, batch: 599,                 loss: 0.014454572210573436, training accuracy: 0.9961458333333333\n",
      "epoch: 3, batch: 619,                 loss: 0.014259412506644073, training accuracy: 0.9961693548387097\n",
      "epoch: 3, batch: 639,                 loss: 0.014287419727133965, training accuracy: 0.99609375\n",
      "epoch: 3, batch: 659,                 loss: 0.014099587785753874, training accuracy: 0.9961174242424242\n",
      "epoch: 3, batch: 679,                 loss: 0.014569114573019118, training accuracy: 0.9957720588235294\n",
      "epoch: 3, batch: 699,                 loss: 0.014770938136747905, training accuracy: 0.995625\n",
      "epoch: 3, batch: 719,                 loss: 0.015032437636141873, training accuracy: 0.9956597222222222\n",
      "epoch: 3, batch: 739,                 loss: 0.014936662664026575, training accuracy: 0.9956925675675675\n",
      "epoch: 3, batch: 759,                 loss: 0.014978300032702176, training accuracy: 0.9956414473684211\n",
      "epoch: 3, batch: 779,                 loss: 0.014839038289993858, training accuracy: 0.9957532051282051\n",
      "epoch: 3, batch: 799,                 loss: 0.014893955103761982, training accuracy: 0.99578125\n",
      "epoch: 3, batch: 819,                 loss: 0.014743483592273395, training accuracy: 0.9958079268292683\n",
      "epoch: 3, batch: 839,                 loss: 0.014575754771483065, training accuracy: 0.9958333333333333\n",
      "epoch: 3, batch: 859,                 loss: 0.014736464025715344, training accuracy: 0.9958575581395349\n",
      "epoch: 3, batch: 879,                 loss: 0.014557219718567053, training accuracy: 0.9959517045454546\n",
      "epoch: 3, batch: 899,                 loss: 0.014339751529882455, training accuracy: 0.9960416666666667\n",
      "epoch: 3, batch: 919,                 loss: 0.014290567725180628, training accuracy: 0.9961277173913043\n",
      "epoch: 3, batch: 939,                 loss: 0.014251505685078495, training accuracy: 0.9961436170212766\n",
      "epoch: 3, batch: 959,                 loss: 0.014487543106952216, training accuracy: 0.9960286458333333\n",
      "epoch: 3, batch: 979,                 loss: 0.014567325545275317, training accuracy: 0.9960459183673469\n",
      "epoch: 3, batch: 999,                 loss: 0.014582978678867221, training accuracy: 0.9960625\n",
      "epoch: 3, batch: 1019,                 loss: 0.01480582735750039, training accuracy: 0.9959558823529412\n",
      "epoch: 3, batch: 1039,                 loss: 0.01509740357600654, training accuracy: 0.9958533653846153\n",
      "epoch: 3, batch: 1059,                 loss: 0.015319330583629638, training accuracy: 0.9956957547169811\n",
      "epoch: 3, batch: 1079,                 loss: 0.015338910479988921, training accuracy: 0.9957175925925926\n",
      "epoch: 3, batch: 1099,                 loss: 0.015493957156802273, training accuracy: 0.9956818181818182\n",
      "epoch: 3, batch: 1119,                 loss: 0.01554227295075959, training accuracy: 0.9956473214285714\n",
      "epoch: 3, batch: 1139,                 loss: 0.015607159812179017, training accuracy: 0.9956140350877193\n",
      "epoch: 3, batch: 1159,                 loss: 0.015672967529149148, training accuracy: 0.995635775862069\n",
      "epoch: 3, batch: 1179,                 loss: 0.015529956026801886, training accuracy: 0.995656779661017\n",
      "epoch: 3, batch: 1199,                 loss: 0.015438379325011435, training accuracy: 0.9956770833333334\n",
      "epoch: 3, batch: 1219,                 loss: 0.015287628587021408, training accuracy: 0.9957479508196722\n",
      "epoch: 3, batch: 1239,                 loss: 0.015247923723819118, training accuracy: 0.995766129032258\n",
      "epoch: 3, batch: 1259,                 loss: 0.015216709728678873, training accuracy: 0.995734126984127\n",
      "epoch: 3, batch: 1279,                 loss: 0.01572191595257664, training accuracy: 0.9955078125\n",
      "epoch: 3, batch: 1299,                 loss: 0.015587972851644736, training accuracy: 0.995576923076923\n",
      "validation accuracy 0.9915\n",
      "test_accuracy 0.5966\n",
      "Saved weights/resnet50-epoch-2-valid_acc=0.9915-test_acc=0.5966.pt\n",
      "epoch: 4, batch: 19,                 loss: 0.015988131146878005, training accuracy: 0.99375\n",
      "epoch: 4, batch: 39,                 loss: 0.011211099178763107, training accuracy: 0.9953125\n",
      "epoch: 4, batch: 59,                 loss: 0.009018009045394137, training accuracy: 0.996875\n",
      "epoch: 4, batch: 79,                 loss: 0.010712134649656946, training accuracy: 0.99609375\n",
      "epoch: 4, batch: 99,                 loss: 0.014032025613705628, training accuracy: 0.99625\n",
      "epoch: 4, batch: 119,                 loss: 0.014036777937144506, training accuracy: 0.9963541666666667\n",
      "epoch: 4, batch: 139,                 loss: 0.014619291448616423, training accuracy: 0.9964285714285714\n",
      "epoch: 4, batch: 159,                 loss: 0.013678759594040458, training accuracy: 0.996875\n",
      "epoch: 4, batch: 179,                 loss: 0.01350232178099557, training accuracy: 0.996875\n",
      "epoch: 4, batch: 199,                 loss: 0.012541982933471444, training accuracy: 0.9971875\n",
      "epoch: 4, batch: 219,                 loss: 0.011800672600723126, training accuracy: 0.9974431818181818\n",
      "epoch: 4, batch: 239,                 loss: 0.011787814724812051, training accuracy: 0.9973958333333334\n",
      "epoch: 4, batch: 259,                 loss: 0.01117150783964182, training accuracy: 0.9975961538461539\n",
      "epoch: 4, batch: 279,                 loss: 0.010834486988564354, training accuracy: 0.9977678571428571\n",
      "epoch: 4, batch: 299,                 loss: 0.010297144334181212, training accuracy: 0.9979166666666667\n",
      "epoch: 4, batch: 319,                 loss: 0.010197348639849224, training accuracy: 0.9978515625\n",
      "epoch: 4, batch: 339,                 loss: 0.009911446825101259, training accuracy: 0.9979779411764705\n",
      "epoch: 4, batch: 359,                 loss: 0.00954365224129611, training accuracy: 0.9980902777777778\n",
      "epoch: 4, batch: 379,                 loss: 0.009400816589799146, training accuracy: 0.9980263157894737\n",
      "epoch: 4, batch: 399,                 loss: 0.009340844215184916, training accuracy: 0.998125\n",
      "epoch: 4, batch: 419,                 loss: 0.009126551038172606, training accuracy: 0.9982142857142857\n",
      "epoch: 4, batch: 439,                 loss: 0.009095332317321498, training accuracy: 0.9980113636363637\n",
      "epoch: 4, batch: 459,                 loss: 0.008883899898248036, training accuracy: 0.9980978260869565\n",
      "epoch: 4, batch: 479,                 loss: 0.00883434715039281, training accuracy: 0.998046875\n",
      "epoch: 4, batch: 499,                 loss: 0.008795197144907434, training accuracy: 0.998\n",
      "epoch: 4, batch: 519,                 loss: 0.008628911327608735, training accuracy: 0.9980769230769231\n",
      "epoch: 4, batch: 539,                 loss: 0.00895894023614582, training accuracy: 0.9980324074074074\n",
      "epoch: 4, batch: 559,                 loss: 0.00908364164892451, training accuracy: 0.9979910714285715\n",
      "epoch: 4, batch: 579,                 loss: 0.008908534966858811, training accuracy: 0.9980603448275862\n",
      "epoch: 4, batch: 599,                 loss: 0.008685116711615896, training accuracy: 0.998125\n",
      "epoch: 4, batch: 619,                 loss: 0.008732241472405863, training accuracy: 0.9979838709677419\n",
      "epoch: 4, batch: 639,                 loss: 0.008541257822798798, training accuracy: 0.998046875\n",
      "epoch: 4, batch: 659,                 loss: 0.008409861564921977, training accuracy: 0.9981060606060606\n",
      "epoch: 4, batch: 679,                 loss: 0.008424707743816887, training accuracy: 0.9981617647058824\n",
      "epoch: 4, batch: 699,                 loss: 0.008453508318094204, training accuracy: 0.998125\n",
      "epoch: 4, batch: 719,                 loss: 0.00836915936197329, training accuracy: 0.9981770833333333\n",
      "epoch: 4, batch: 739,                 loss: 0.00820694776858373, training accuracy: 0.9982263513513514\n",
      "epoch: 4, batch: 759,                 loss: 0.008085488530502373, training accuracy: 0.9982730263157895\n",
      "epoch: 4, batch: 779,                 loss: 0.007970262911560265, training accuracy: 0.9983173076923076\n",
      "epoch: 4, batch: 799,                 loss: 0.007970565810246626, training accuracy: 0.99828125\n",
      "epoch: 4, batch: 819,                 loss: 0.00791884421689646, training accuracy: 0.9983231707317073\n",
      "epoch: 4, batch: 839,                 loss: 0.008013375462732732, training accuracy: 0.9982142857142857\n",
      "epoch: 4, batch: 859,                 loss: 0.007874833489666682, training accuracy: 0.9982558139534884\n",
      "epoch: 4, batch: 879,                 loss: 0.007807757401744973, training accuracy: 0.9982954545454545\n",
      "epoch: 4, batch: 899,                 loss: 0.007675344033147364, training accuracy: 0.9983333333333333\n",
      "epoch: 4, batch: 919,                 loss: 0.007567839899796957, training accuracy: 0.9983695652173913\n",
      "epoch: 4, batch: 939,                 loss: 0.008010150136087373, training accuracy: 0.9982712765957447\n",
      "epoch: 4, batch: 959,                 loss: 0.008016020347880234, training accuracy: 0.9981770833333333\n",
      "epoch: 4, batch: 979,                 loss: 0.007901521012966869, training accuracy: 0.9982142857142857\n",
      "epoch: 4, batch: 999,                 loss: 0.007935380404131137, training accuracy: 0.998125\n",
      "epoch: 4, batch: 1019,                 loss: 0.007894727295420392, training accuracy: 0.9981617647058824\n",
      "epoch: 4, batch: 1039,                 loss: 0.007817138623193807, training accuracy: 0.9981971153846154\n",
      "epoch: 4, batch: 1059,                 loss: 0.007733187654106724, training accuracy: 0.9982311320754716\n",
      "epoch: 4, batch: 1079,                 loss: 0.00766788293976451, training accuracy: 0.9982638888888888\n",
      "epoch: 4, batch: 1099,                 loss: 0.007664101059000876, training accuracy: 0.9982954545454545\n",
      "epoch: 4, batch: 1119,                 loss: 0.007759053780721712, training accuracy: 0.9982700892857143\n",
      "epoch: 4, batch: 1139,                 loss: 0.007733624263805962, training accuracy: 0.9982456140350877\n",
      "epoch: 4, batch: 1159,                 loss: 0.007635780240186783, training accuracy: 0.9982758620689656\n",
      "epoch: 4, batch: 1179,                 loss: 0.007598155227791167, training accuracy: 0.9983050847457627\n",
      "epoch: 4, batch: 1199,                 loss: 0.007495268982493144, training accuracy: 0.9983333333333333\n",
      "epoch: 4, batch: 1219,                 loss: 0.007444901345595889, training accuracy: 0.9983606557377049\n",
      "epoch: 4, batch: 1239,                 loss: 0.007369745331814028, training accuracy: 0.9983870967741936\n",
      "epoch: 4, batch: 1259,                 loss: 0.007361217814052777, training accuracy: 0.9983630952380952\n",
      "epoch: 4, batch: 1279,                 loss: 0.007301343253084269, training accuracy: 0.998388671875\n",
      "epoch: 4, batch: 1299,                 loss: 0.007625050746842484, training accuracy: 0.9983173076923076\n",
      "validation accuracy 0.9919\n",
      "test_accuracy 0.6062\n",
      "Saved weights/resnet50-epoch-3-valid_acc=0.9919-test_acc=0.6062.pt\n",
      "epoch: 5, batch: 19,                 loss: 0.0039056323395925572, training accuracy: 0.996875\n",
      "epoch: 5, batch: 39,                 loss: 0.008024141473288181, training accuracy: 0.996875\n",
      "epoch: 5, batch: 59,                 loss: 0.005927027300640475, training accuracy: 0.9979166666666667\n",
      "epoch: 5, batch: 79,                 loss: 0.00643922347771877, training accuracy: 0.99765625\n",
      "epoch: 5, batch: 99,                 loss: 0.010304318861162755, training accuracy: 0.99625\n",
      "epoch: 5, batch: 119,                 loss: 0.010868936943249233, training accuracy: 0.9963541666666667\n",
      "epoch: 5, batch: 139,                 loss: 0.009710938894256418, training accuracy: 0.996875\n",
      "epoch: 5, batch: 159,                 loss: 0.011178705963720859, training accuracy: 0.99609375\n",
      "epoch: 5, batch: 179,                 loss: 0.012407512607913103, training accuracy: 0.9958333333333333\n",
      "epoch: 5, batch: 199,                 loss: 0.013298709027149016, training accuracy: 0.995625\n",
      "epoch: 5, batch: 219,                 loss: 0.012578798316826578, training accuracy: 0.9960227272727272\n",
      "epoch: 5, batch: 239,                 loss: 0.011671994926291517, training accuracy: 0.9963541666666667\n",
      "epoch: 5, batch: 259,                 loss: 0.011632917842115812, training accuracy: 0.9963942307692307\n",
      "epoch: 5, batch: 279,                 loss: 0.012022918220256022, training accuracy: 0.9964285714285714\n",
      "epoch: 5, batch: 299,                 loss: 0.01274373545020353, training accuracy: 0.9964583333333333\n",
      "epoch: 5, batch: 319,                 loss: 0.012192454917658324, training accuracy: 0.9966796875\n",
      "epoch: 5, batch: 339,                 loss: 0.011876065115297131, training accuracy: 0.9966911764705882\n",
      "epoch: 5, batch: 359,                 loss: 0.011850857391254976, training accuracy: 0.9967013888888889\n",
      "epoch: 5, batch: 379,                 loss: 0.01131645383705434, training accuracy: 0.996875\n",
      "epoch: 5, batch: 399,                 loss: 0.011983471780986292, training accuracy: 0.996875\n",
      "epoch: 5, batch: 419,                 loss: 0.011710810893800088, training accuracy: 0.996875\n",
      "epoch: 5, batch: 439,                 loss: 0.011335618772930253, training accuracy: 0.9970170454545455\n",
      "epoch: 5, batch: 459,                 loss: 0.011001223654317943, training accuracy: 0.9970108695652173\n",
      "epoch: 5, batch: 479,                 loss: 0.011573725684593228, training accuracy: 0.996875\n",
      "epoch: 5, batch: 499,                 loss: 0.011345817094814265, training accuracy: 0.997\n",
      "epoch: 5, batch: 519,                 loss: 0.011306839755679202, training accuracy: 0.9969951923076923\n",
      "epoch: 5, batch: 539,                 loss: 0.010966481254042634, training accuracy: 0.9971064814814815\n",
      "epoch: 5, batch: 559,                 loss: 0.010689393982751686, training accuracy: 0.9972098214285714\n",
      "epoch: 5, batch: 579,                 loss: 0.01098034272257917, training accuracy: 0.9970905172413793\n",
      "epoch: 5, batch: 599,                 loss: 0.010830780315809535, training accuracy: 0.9971875\n",
      "epoch: 5, batch: 619,                 loss: 0.01102227699962133, training accuracy: 0.9970766129032258\n",
      "epoch: 5, batch: 639,                 loss: 0.010903142934444077, training accuracy: 0.9970703125\n",
      "epoch: 5, batch: 659,                 loss: 0.010836828377156934, training accuracy: 0.997064393939394\n",
      "epoch: 5, batch: 679,                 loss: 0.01095542268772346, training accuracy: 0.9969669117647059\n",
      "epoch: 5, batch: 699,                 loss: 0.01083316181239622, training accuracy: 0.9969642857142857\n",
      "epoch: 5, batch: 719,                 loss: 0.010608961162688502, training accuracy: 0.9970486111111111\n",
      "epoch: 5, batch: 739,                 loss: 0.010558235115073526, training accuracy: 0.997043918918919\n",
      "epoch: 5, batch: 759,                 loss: 0.011092976562347184, training accuracy: 0.9970394736842105\n",
      "epoch: 5, batch: 779,                 loss: 0.010970033134818107, training accuracy: 0.9971153846153846\n",
      "epoch: 5, batch: 799,                 loss: 0.0109659612260657, training accuracy: 0.9971875\n",
      "epoch: 5, batch: 819,                 loss: 0.010878565130760983, training accuracy: 0.9972560975609757\n",
      "epoch: 5, batch: 839,                 loss: 0.011303552839568251, training accuracy: 0.997172619047619\n",
      "epoch: 5, batch: 859,                 loss: 0.011112167437200103, training accuracy: 0.9972383720930232\n",
      "epoch: 5, batch: 879,                 loss: 0.011175735873935496, training accuracy: 0.9971590909090909\n",
      "epoch: 5, batch: 899,                 loss: 0.01103591350756081, training accuracy: 0.9971527777777778\n",
      "epoch: 5, batch: 919,                 loss: 0.011302756726834796, training accuracy: 0.9970788043478261\n",
      "epoch: 5, batch: 939,                 loss: 0.011221807962949165, training accuracy: 0.9971409574468085\n",
      "epoch: 5, batch: 959,                 loss: 0.011166099940661903, training accuracy: 0.9971354166666667\n",
      "epoch: 5, batch: 979,                 loss: 0.011108960438168095, training accuracy: 0.9971938775510204\n",
      "epoch: 5, batch: 999,                 loss: 0.011092937804874964, training accuracy: 0.9971875\n",
      "epoch: 5, batch: 1019,                 loss: 0.011292215092073414, training accuracy: 0.9971200980392156\n",
      "epoch: 5, batch: 1039,                 loss: 0.01115104794861019, training accuracy: 0.9971754807692308\n",
      "epoch: 5, batch: 1059,                 loss: 0.011154679304871814, training accuracy: 0.9971108490566037\n",
      "epoch: 5, batch: 1079,                 loss: 0.011127296020492429, training accuracy: 0.9970486111111111\n",
      "epoch: 5, batch: 1099,                 loss: 0.011137670870309441, training accuracy: 0.9970454545454546\n",
      "epoch: 5, batch: 1119,                 loss: 0.011333979261403978, training accuracy: 0.9969308035714286\n",
      "epoch: 5, batch: 1139,                 loss: 0.01116384419637095, training accuracy: 0.996984649122807\n",
      "epoch: 5, batch: 1159,                 loss: 0.011075205634978344, training accuracy: 0.9970366379310345\n",
      "epoch: 5, batch: 1179,                 loss: 0.011223421779856326, training accuracy: 0.9969809322033898\n",
      "epoch: 5, batch: 1199,                 loss: 0.01106378463187866, training accuracy: 0.99703125\n",
      "epoch: 5, batch: 1219,                 loss: 0.010943747436201684, training accuracy: 0.9970799180327868\n",
      "epoch: 5, batch: 1239,                 loss: 0.010882878234746561, training accuracy: 0.9970766129032258\n",
      "epoch: 5, batch: 1259,                 loss: 0.010740447298257282, training accuracy: 0.9971230158730159\n",
      "epoch: 5, batch: 1279,                 loss: 0.01067143062037985, training accuracy: 0.997119140625\n",
      "epoch: 5, batch: 1299,                 loss: 0.01056300291757977, training accuracy: 0.9971634615384616\n",
      "validation accuracy 0.9906\n",
      "test_accuracy 0.6069\n",
      "Saved weights/resnet50-epoch-4-valid_acc=0.9906-test_acc=0.6069.pt\n",
      "epoch: 6, batch: 19,                 loss: 0.0022645317891146987, training accuracy: 1.0\n",
      "epoch: 6, batch: 39,                 loss: 0.0033292717758740763, training accuracy: 0.9984375\n",
      "epoch: 6, batch: 59,                 loss: 0.00269694899955842, training accuracy: 0.9989583333333333\n",
      "epoch: 6, batch: 79,                 loss: 0.0025146710717308452, training accuracy: 0.99921875\n",
      "epoch: 6, batch: 99,                 loss: 0.0031938859698129817, training accuracy: 0.999375\n",
      "epoch: 6, batch: 119,                 loss: 0.007068540119507816, training accuracy: 0.9979166666666667\n",
      "epoch: 6, batch: 139,                 loss: 0.006241959032299097, training accuracy: 0.9982142857142857\n",
      "epoch: 6, batch: 159,                 loss: 0.0056379263854069, training accuracy: 0.9984375\n",
      "epoch: 6, batch: 179,                 loss: 0.005166890974376454, training accuracy: 0.9986111111111111\n",
      "epoch: 6, batch: 199,                 loss: 0.004772332594220643, training accuracy: 0.99875\n",
      "epoch: 6, batch: 219,                 loss: 0.00449856272005656, training accuracy: 0.9988636363636364\n",
      "epoch: 6, batch: 239,                 loss: 0.005182813514935939, training accuracy: 0.9986979166666666\n",
      "epoch: 6, batch: 259,                 loss: 0.0050375119579257445, training accuracy: 0.9987980769230769\n",
      "epoch: 6, batch: 279,                 loss: 0.005637137291965441, training accuracy: 0.9984375\n",
      "epoch: 6, batch: 299,                 loss: 0.005682350361409286, training accuracy: 0.9983333333333333\n",
      "epoch: 6, batch: 319,                 loss: 0.005514124401906883, training accuracy: 0.9984375\n",
      "epoch: 6, batch: 339,                 loss: 0.005408667410751257, training accuracy: 0.9985294117647059\n",
      "epoch: 6, batch: 359,                 loss: 0.005403928943350265, training accuracy: 0.9984375\n",
      "epoch: 6, batch: 379,                 loss: 0.005230378487191813, training accuracy: 0.9985197368421053\n",
      "epoch: 6, batch: 399,                 loss: 0.005001071545593732, training accuracy: 0.99859375\n",
      "epoch: 6, batch: 419,                 loss: 0.004867555242578549, training accuracy: 0.9986607142857142\n",
      "epoch: 6, batch: 439,                 loss: 0.0051489885944895585, training accuracy: 0.9985795454545454\n",
      "epoch: 6, batch: 459,                 loss: 0.005082081676585443, training accuracy: 0.998641304347826\n",
      "epoch: 6, batch: 479,                 loss: 0.005436943164613695, training accuracy: 0.9985677083333333\n",
      "epoch: 6, batch: 499,                 loss: 0.00529857227440516, training accuracy: 0.998625\n",
      "epoch: 6, batch: 519,                 loss: 0.006014665058976859, training accuracy: 0.9985576923076923\n",
      "epoch: 6, batch: 539,                 loss: 0.005925281040402263, training accuracy: 0.9986111111111111\n",
      "epoch: 6, batch: 559,                 loss: 0.005980159686168917, training accuracy: 0.9985491071428572\n",
      "epoch: 6, batch: 579,                 loss: 0.00638843349677637, training accuracy: 0.9983836206896551\n",
      "epoch: 6, batch: 599,                 loss: 0.006422368972695646, training accuracy: 0.9983333333333333\n",
      "epoch: 6, batch: 619,                 loss: 0.006399822453820361, training accuracy: 0.9982862903225806\n",
      "epoch: 6, batch: 639,                 loss: 0.006523484632714372, training accuracy: 0.9982421875\n",
      "epoch: 6, batch: 659,                 loss: 0.006893291251826943, training accuracy: 0.9981060606060606\n",
      "epoch: 6, batch: 679,                 loss: 0.0068079811043978275, training accuracy: 0.9981617647058824\n",
      "epoch: 6, batch: 699,                 loss: 0.006676884509745702, training accuracy: 0.9982142857142857\n",
      "epoch: 6, batch: 719,                 loss: 0.006529673824611059, training accuracy: 0.9982638888888888\n",
      "epoch: 6, batch: 739,                 loss: 0.006411681750231199, training accuracy: 0.9983108108108109\n",
      "epoch: 6, batch: 759,                 loss: 0.006435584488941746, training accuracy: 0.9982730263157895\n",
      "epoch: 6, batch: 779,                 loss: 0.006316734236884842, training accuracy: 0.9983173076923076\n",
      "epoch: 6, batch: 799,                 loss: 0.006192176501517679, training accuracy: 0.998359375\n",
      "epoch: 6, batch: 819,                 loss: 0.006096863745418576, training accuracy: 0.9983993902439025\n",
      "epoch: 6, batch: 839,                 loss: 0.006137121495114462, training accuracy: 0.9983630952380952\n",
      "epoch: 6, batch: 859,                 loss: 0.006054216537822233, training accuracy: 0.9984011627906977\n",
      "epoch: 6, batch: 879,                 loss: 0.005978544256884727, training accuracy: 0.9984375\n",
      "epoch: 6, batch: 899,                 loss: 0.006066207217760772, training accuracy: 0.9984027777777778\n",
      "epoch: 6, batch: 919,                 loss: 0.005962072964694412, training accuracy: 0.9984375\n",
      "epoch: 6, batch: 939,                 loss: 0.006045141782004143, training accuracy: 0.9984042553191489\n",
      "epoch: 6, batch: 959,                 loss: 0.005972319664958074, training accuracy: 0.9984375\n",
      "epoch: 6, batch: 979,                 loss: 0.005906353848131031, training accuracy: 0.9984693877551021\n",
      "epoch: 6, batch: 999,                 loss: 0.005841378848534078, training accuracy: 0.9985\n",
      "epoch: 6, batch: 1019,                 loss: 0.005905289373770881, training accuracy: 0.9984681372549019\n",
      "epoch: 6, batch: 1039,                 loss: 0.005880291620479301, training accuracy: 0.9984375\n",
      "epoch: 6, batch: 1059,                 loss: 0.005914464416773111, training accuracy: 0.9984080188679245\n",
      "epoch: 6, batch: 1079,                 loss: 0.005984102693050604, training accuracy: 0.9983796296296297\n",
      "epoch: 6, batch: 1099,                 loss: 0.0059044274421268545, training accuracy: 0.9984090909090909\n",
      "epoch: 6, batch: 1119,                 loss: 0.006231489796398039, training accuracy: 0.9981584821428572\n",
      "epoch: 6, batch: 1139,                 loss: 0.006155396501357277, training accuracy: 0.9981907894736842\n",
      "epoch: 6, batch: 1159,                 loss: 0.006140558099995642, training accuracy: 0.9982219827586207\n",
      "epoch: 6, batch: 1179,                 loss: 0.006093821863667749, training accuracy: 0.9982521186440678\n",
      "epoch: 6, batch: 1199,                 loss: 0.006238925887064397, training accuracy: 0.9982291666666666\n",
      "epoch: 6, batch: 1219,                 loss: 0.006222918588716058, training accuracy: 0.9982581967213114\n",
      "epoch: 6, batch: 1239,                 loss: 0.006136277769620656, training accuracy: 0.9982862903225806\n",
      "epoch: 6, batch: 1259,                 loss: 0.006085982390083252, training accuracy: 0.9983134920634921\n",
      "epoch: 6, batch: 1279,                 loss: 0.0060559232163257095, training accuracy: 0.99833984375\n",
      "epoch: 6, batch: 1299,                 loss: 0.006112823381985296, training accuracy: 0.9983173076923076\n",
      "validation accuracy 0.9932\n",
      "test_accuracy 0.5987\n",
      "Saved weights/resnet50-epoch-5-valid_acc=0.9932-test_acc=0.5987.pt\n",
      "Finished Training: resnet50\n",
      "epoch: 1, batch: 19,                 loss: 0.623428612947464, training accuracy: 0.675\n",
      "epoch: 1, batch: 39,                 loss: 0.5616109274327755, training accuracy: 0.7640625\n",
      "epoch: 1, batch: 59,                 loss: 0.49524156053860985, training accuracy: 0.8166666666666667\n",
      "epoch: 1, batch: 79,                 loss: 0.44326360020786526, training accuracy: 0.84609375\n",
      "epoch: 1, batch: 99,                 loss: 0.4018473602831364, training accuracy: 0.865\n",
      "epoch: 1, batch: 119,                 loss: 0.3642776805907488, training accuracy: 0.8786458333333333\n",
      "epoch: 1, batch: 139,                 loss: 0.33909865841269493, training accuracy: 0.8866071428571428\n",
      "epoch: 1, batch: 159,                 loss: 0.31290198653005064, training accuracy: 0.896484375\n",
      "epoch: 1, batch: 179,                 loss: 0.2947278439998627, training accuracy: 0.9027777777777778\n",
      "epoch: 1, batch: 199,                 loss: 0.2767111025005579, training accuracy: 0.91\n",
      "epoch: 1, batch: 219,                 loss: 0.26440089322965254, training accuracy: 0.9133522727272727\n",
      "epoch: 1, batch: 239,                 loss: 0.2518478540626044, training accuracy: 0.9177083333333333\n",
      "epoch: 1, batch: 259,                 loss: 0.2396608154504345, training accuracy: 0.9221153846153847\n",
      "epoch: 1, batch: 279,                 loss: 0.22866234287752638, training accuracy: 0.9258928571428572\n",
      "epoch: 1, batch: 299,                 loss: 0.22086444011578957, training accuracy: 0.92875\n",
      "epoch: 1, batch: 319,                 loss: 0.21220509896229486, training accuracy: 0.93203125\n",
      "epoch: 1, batch: 339,                 loss: 0.20549740518224152, training accuracy: 0.934375\n",
      "epoch: 1, batch: 359,                 loss: 0.19998856311301805, training accuracy: 0.9366319444444444\n",
      "epoch: 1, batch: 379,                 loss: 0.19257565170869623, training accuracy: 0.9389802631578947\n",
      "epoch: 1, batch: 399,                 loss: 0.18614000762347133, training accuracy: 0.94109375\n",
      "epoch: 1, batch: 419,                 loss: 0.1812172636877568, training accuracy: 0.9428571428571428\n",
      "epoch: 1, batch: 439,                 loss: 0.17662557388063183, training accuracy: 0.9443181818181818\n",
      "epoch: 1, batch: 459,                 loss: 0.1724136769913299, training accuracy: 0.9456521739130435\n",
      "epoch: 1, batch: 479,                 loss: 0.16725587101924855, training accuracy: 0.9471354166666667\n",
      "epoch: 1, batch: 499,                 loss: 0.16274442742578685, training accuracy: 0.948375\n",
      "epoch: 1, batch: 519,                 loss: 0.16032656180815627, training accuracy: 0.9489182692307693\n",
      "epoch: 1, batch: 539,                 loss: 0.15714371496535562, training accuracy: 0.9501157407407408\n",
      "epoch: 1, batch: 559,                 loss: 0.1531328651455364, training accuracy: 0.9514508928571429\n",
      "epoch: 1, batch: 579,                 loss: 0.149812135039347, training accuracy: 0.9525862068965517\n",
      "epoch: 1, batch: 599,                 loss: 0.1460587271147718, training accuracy: 0.9536458333333333\n",
      "epoch: 1, batch: 619,                 loss: 0.1431412354817674, training accuracy: 0.9545362903225807\n",
      "epoch: 1, batch: 639,                 loss: 0.14166908329498257, training accuracy: 0.95498046875\n",
      "epoch: 1, batch: 659,                 loss: 0.13927595290835157, training accuracy: 0.9557765151515152\n",
      "epoch: 1, batch: 679,                 loss: 0.13659815193660668, training accuracy: 0.9565257352941177\n",
      "epoch: 1, batch: 699,                 loss: 0.1341887639316597, training accuracy: 0.9572321428571429\n",
      "epoch: 1, batch: 719,                 loss: 0.13172184140874177, training accuracy: 0.9579861111111111\n",
      "epoch: 1, batch: 739,                 loss: 0.13006021431836023, training accuracy: 0.9584459459459459\n",
      "epoch: 1, batch: 759,                 loss: 0.12762546736477434, training accuracy: 0.959375\n",
      "epoch: 1, batch: 779,                 loss: 0.12495101570056226, training accuracy: 0.9602564102564103\n",
      "epoch: 1, batch: 799,                 loss: 0.12272881356824655, training accuracy: 0.96109375\n",
      "epoch: 1, batch: 819,                 loss: 0.12079951574730619, training accuracy: 0.9616615853658537\n",
      "epoch: 1, batch: 839,                 loss: 0.11856627161226546, training accuracy: 0.9623511904761904\n",
      "epoch: 1, batch: 859,                 loss: 0.11730677331364606, training accuracy: 0.9627906976744186\n",
      "epoch: 1, batch: 879,                 loss: 0.11556656219737223, training accuracy: 0.9633522727272728\n",
      "epoch: 1, batch: 899,                 loss: 0.11388231759192421, training accuracy: 0.9638194444444445\n",
      "epoch: 1, batch: 919,                 loss: 0.11242461575767147, training accuracy: 0.9644021739130435\n",
      "epoch: 1, batch: 939,                 loss: 0.11055439367513865, training accuracy: 0.9650265957446809\n",
      "epoch: 1, batch: 959,                 loss: 0.10926300500917326, training accuracy: 0.9655598958333333\n",
      "epoch: 1, batch: 979,                 loss: 0.10794941319428308, training accuracy: 0.9660076530612245\n",
      "epoch: 1, batch: 999,                 loss: 0.10705644119763746, training accuracy: 0.966375\n",
      "epoch: 1, batch: 1019,                 loss: 0.10607548369478215, training accuracy: 0.9667279411764705\n",
      "epoch: 1, batch: 1039,                 loss: 0.10441075928974897, training accuracy: 0.9673076923076923\n",
      "epoch: 1, batch: 1059,                 loss: 0.10458389415300258, training accuracy: 0.9672759433962265\n",
      "epoch: 1, batch: 1079,                 loss: 0.10361755560066, training accuracy: 0.9677083333333333\n",
      "epoch: 1, batch: 1099,                 loss: 0.10227659236258742, training accuracy: 0.9682386363636364\n",
      "epoch: 1, batch: 1119,                 loss: 0.10129460836927007, training accuracy: 0.9684709821428571\n",
      "epoch: 1, batch: 1139,                 loss: 0.10025492605116022, training accuracy: 0.9689144736842106\n",
      "epoch: 1, batch: 1159,                 loss: 0.0987790915308167, training accuracy: 0.969396551724138\n",
      "epoch: 1, batch: 1179,                 loss: 0.09782400700240002, training accuracy: 0.9697033898305085\n",
      "epoch: 1, batch: 1199,                 loss: 0.09675337657681667, training accuracy: 0.9700520833333334\n",
      "epoch: 1, batch: 1219,                 loss: 0.09563994480212998, training accuracy: 0.9704405737704918\n",
      "epoch: 1, batch: 1239,                 loss: 0.09464710930478759, training accuracy: 0.9706653225806452\n",
      "epoch: 1, batch: 1259,                 loss: 0.0942999652095346, training accuracy: 0.970734126984127\n",
      "epoch: 1, batch: 1279,                 loss: 0.09323651971426443, training accuracy: 0.97109375\n",
      "epoch: 1, batch: 1299,                 loss: 0.09204773993786568, training accuracy: 0.9714903846153846\n",
      "validation accuracy 0.9906\n",
      "test_accuracy 0.6064\n",
      "Saved weights/resnet101-epoch-0-valid_acc=0.9906-test_acc=0.6064.pt\n",
      "epoch: 2, batch: 19,                 loss: 0.06918446780182422, training accuracy: 0.98125\n",
      "epoch: 2, batch: 39,                 loss: 0.04760202376637608, training accuracy: 0.9875\n",
      "epoch: 2, batch: 59,                 loss: 0.04153843025754516, training accuracy: 0.9885416666666667\n",
      "epoch: 2, batch: 79,                 loss: 0.037725686826161106, training accuracy: 0.9890625\n",
      "epoch: 2, batch: 99,                 loss: 0.034287573422770945, training accuracy: 0.99\n",
      "epoch: 2, batch: 119,                 loss: 0.03116366546601057, training accuracy: 0.9911458333333333\n",
      "epoch: 2, batch: 139,                 loss: 0.029378426734391335, training accuracy: 0.9915178571428571\n",
      "epoch: 2, batch: 159,                 loss: 0.026807294834725326, training accuracy: 0.992578125\n",
      "epoch: 2, batch: 179,                 loss: 0.025347758690542024, training accuracy: 0.9930555555555556\n",
      "epoch: 2, batch: 199,                 loss: 0.02542283220042009, training accuracy: 0.9928125\n",
      "epoch: 2, batch: 219,                 loss: 0.024814447534101253, training accuracy: 0.9931818181818182\n",
      "epoch: 2, batch: 239,                 loss: 0.02394939026950548, training accuracy: 0.9934895833333334\n",
      "epoch: 2, batch: 259,                 loss: 0.02425071708858013, training accuracy: 0.9932692307692308\n",
      "epoch: 2, batch: 279,                 loss: 0.024799398228891992, training accuracy: 0.9930803571428571\n",
      "epoch: 2, batch: 299,                 loss: 0.02470720906353866, training accuracy: 0.9933333333333333\n",
      "epoch: 2, batch: 319,                 loss: 0.02484963008464547, training accuracy: 0.993359375\n",
      "epoch: 2, batch: 339,                 loss: 0.024909836670164675, training accuracy: 0.9931985294117647\n",
      "epoch: 2, batch: 359,                 loss: 0.025082968089393236, training accuracy: 0.9928819444444444\n",
      "epoch: 2, batch: 379,                 loss: 0.025386892524425334, training accuracy: 0.9925986842105263\n",
      "epoch: 2, batch: 399,                 loss: 0.024757144832983614, training accuracy: 0.9928125\n",
      "epoch: 2, batch: 419,                 loss: 0.024212890240596606, training accuracy: 0.9930059523809524\n",
      "epoch: 2, batch: 439,                 loss: 0.02353467050733426, training accuracy: 0.9933238636363636\n",
      "epoch: 2, batch: 459,                 loss: 0.023148658780796128, training accuracy: 0.9934782608695653\n",
      "epoch: 2, batch: 479,                 loss: 0.023169080872806565, training accuracy: 0.9934895833333334\n",
      "epoch: 2, batch: 499,                 loss: 0.022735999795142563, training accuracy: 0.99375\n",
      "epoch: 2, batch: 519,                 loss: 0.022677223650568453, training accuracy: 0.99375\n",
      "epoch: 2, batch: 539,                 loss: 0.022171036080086467, training accuracy: 0.9939814814814815\n",
      "epoch: 2, batch: 559,                 loss: 0.021809851160131594, training accuracy: 0.9940848214285715\n",
      "epoch: 2, batch: 579,                 loss: 0.022499911088279673, training accuracy: 0.9938577586206897\n",
      "epoch: 2, batch: 599,                 loss: 0.022012476232290887, training accuracy: 0.9940625\n",
      "epoch: 2, batch: 619,                 loss: 0.021886350474350395, training accuracy: 0.9941532258064516\n",
      "epoch: 2, batch: 639,                 loss: 0.021406196154293865, training accuracy: 0.9943359375\n",
      "epoch: 2, batch: 659,                 loss: 0.021108111694444563, training accuracy: 0.9944128787878788\n",
      "epoch: 2, batch: 679,                 loss: 0.020979926730454762, training accuracy: 0.9943014705882353\n",
      "epoch: 2, batch: 699,                 loss: 0.02071276932796796, training accuracy: 0.994375\n",
      "epoch: 2, batch: 719,                 loss: 0.021011226762816984, training accuracy: 0.9942708333333333\n",
      "epoch: 2, batch: 739,                 loss: 0.02092833821441525, training accuracy: 0.9943412162162162\n",
      "epoch: 2, batch: 759,                 loss: 0.020942999675600347, training accuracy: 0.9943256578947368\n",
      "epoch: 2, batch: 779,                 loss: 0.02130729687006141, training accuracy: 0.9940705128205128\n",
      "epoch: 2, batch: 799,                 loss: 0.021451437222931417, training accuracy: 0.993984375\n",
      "epoch: 2, batch: 819,                 loss: 0.021800346690494136, training accuracy: 0.9939786585365854\n",
      "epoch: 2, batch: 839,                 loss: 0.0219133366508426, training accuracy: 0.9938988095238095\n",
      "epoch: 2, batch: 859,                 loss: 0.021529913721078205, training accuracy: 0.9940406976744186\n",
      "epoch: 2, batch: 879,                 loss: 0.021394654607932103, training accuracy: 0.9940340909090909\n",
      "epoch: 2, batch: 899,                 loss: 0.021420477793435568, training accuracy: 0.9940277777777777\n",
      "epoch: 2, batch: 919,                 loss: 0.021188128975020093, training accuracy: 0.9941576086956522\n",
      "epoch: 2, batch: 939,                 loss: 0.021064906848094207, training accuracy: 0.9942154255319149\n",
      "epoch: 2, batch: 959,                 loss: 0.021140066820468442, training accuracy: 0.9942057291666667\n",
      "epoch: 2, batch: 979,                 loss: 0.02141657486042407, training accuracy: 0.9941326530612244\n",
      "epoch: 2, batch: 999,                 loss: 0.0213228691695258, training accuracy: 0.994125\n",
      "epoch: 2, batch: 1019,                 loss: 0.021146393436527647, training accuracy: 0.9941789215686274\n",
      "epoch: 2, batch: 1039,                 loss: 0.021331054951252343, training accuracy: 0.9940504807692307\n",
      "epoch: 2, batch: 1059,                 loss: 0.02190297825595821, training accuracy: 0.99375\n",
      "epoch: 2, batch: 1079,                 loss: 0.021825414576515968, training accuracy: 0.99375\n",
      "epoch: 2, batch: 1099,                 loss: 0.02180344964150043, training accuracy: 0.9936363636363637\n",
      "epoch: 2, batch: 1119,                 loss: 0.02204408684467905, training accuracy: 0.9935825892857143\n",
      "epoch: 2, batch: 1139,                 loss: 0.02215733378599684, training accuracy: 0.9935855263157894\n",
      "epoch: 2, batch: 1159,                 loss: 0.022249570598169472, training accuracy: 0.993426724137931\n",
      "epoch: 2, batch: 1179,                 loss: 0.0221064054335653, training accuracy: 0.9934322033898305\n",
      "epoch: 2, batch: 1199,                 loss: 0.02230368080951545, training accuracy: 0.99328125\n",
      "epoch: 2, batch: 1219,                 loss: 0.0223649392231295, training accuracy: 0.9932377049180328\n",
      "epoch: 2, batch: 1239,                 loss: 0.02239147546375358, training accuracy: 0.9932963709677419\n",
      "epoch: 2, batch: 1259,                 loss: 0.02214515179498232, training accuracy: 0.9934027777777777\n",
      "epoch: 2, batch: 1279,                 loss: 0.021990641521961153, training accuracy: 0.99345703125\n",
      "epoch: 2, batch: 1299,                 loss: 0.02175210049044556, training accuracy: 0.9935576923076923\n",
      "validation accuracy 0.9906\n",
      "test_accuracy 0.619\n",
      "Saved weights/resnet101-epoch-1-valid_acc=0.9906-test_acc=0.619.pt\n",
      "epoch: 3, batch: 19,                 loss: 0.01013652302499395, training accuracy: 1.0\n",
      "epoch: 3, batch: 39,                 loss: 0.010186903808789793, training accuracy: 0.9984375\n",
      "epoch: 3, batch: 59,                 loss: 0.0151770577863014, training accuracy: 0.9979166666666667\n",
      "epoch: 3, batch: 79,                 loss: 0.013349498196475906, training accuracy: 0.9984375\n",
      "epoch: 3, batch: 99,                 loss: 0.01290583771711681, training accuracy: 0.998125\n",
      "epoch: 3, batch: 119,                 loss: 0.01498898716866582, training accuracy: 0.9979166666666667\n",
      "epoch: 3, batch: 139,                 loss: 0.013535929371054018, training accuracy: 0.9982142857142857\n",
      "epoch: 3, batch: 159,                 loss: 0.013764755703596166, training accuracy: 0.998046875\n",
      "epoch: 3, batch: 179,                 loss: 0.01411529576645181, training accuracy: 0.9979166666666667\n",
      "epoch: 3, batch: 199,                 loss: 0.0151048178516794, training accuracy: 0.996875\n",
      "epoch: 3, batch: 219,                 loss: 0.014591617961625822, training accuracy: 0.996875\n",
      "epoch: 3, batch: 239,                 loss: 0.014470926911114172, training accuracy: 0.9966145833333333\n",
      "epoch: 3, batch: 259,                 loss: 0.014656522594025143, training accuracy: 0.9963942307692307\n",
      "epoch: 3, batch: 279,                 loss: 0.014244327605618829, training accuracy: 0.9964285714285714\n",
      "epoch: 3, batch: 299,                 loss: 0.01354702140786685, training accuracy: 0.9966666666666667\n",
      "epoch: 3, batch: 319,                 loss: 0.013478989885697956, training accuracy: 0.9966796875\n",
      "epoch: 3, batch: 339,                 loss: 0.013108027811326525, training accuracy: 0.9966911764705882\n",
      "epoch: 3, batch: 359,                 loss: 0.012594628430249739, training accuracy: 0.996875\n",
      "epoch: 3, batch: 379,                 loss: 0.012115512843975969, training accuracy: 0.9970394736842105\n",
      "epoch: 3, batch: 399,                 loss: 0.011979686236009002, training accuracy: 0.99703125\n",
      "epoch: 3, batch: 419,                 loss: 0.011871963353700093, training accuracy: 0.9970238095238095\n",
      "epoch: 3, batch: 439,                 loss: 0.013020372419586321, training accuracy: 0.996875\n",
      "epoch: 3, batch: 459,                 loss: 0.013171993917026354, training accuracy: 0.9967391304347826\n",
      "epoch: 3, batch: 479,                 loss: 0.013169885293852228, training accuracy: 0.9967447916666666\n",
      "epoch: 3, batch: 499,                 loss: 0.012902819763170556, training accuracy: 0.996875\n",
      "epoch: 3, batch: 519,                 loss: 0.012635500295772754, training accuracy: 0.9969951923076923\n",
      "epoch: 3, batch: 539,                 loss: 0.012687506370949213, training accuracy: 0.9967592592592592\n",
      "epoch: 3, batch: 559,                 loss: 0.012776118889451026, training accuracy: 0.9967633928571429\n",
      "epoch: 3, batch: 579,                 loss: 0.012795167198858289, training accuracy: 0.9967672413793104\n",
      "epoch: 3, batch: 599,                 loss: 0.013279257824760861, training accuracy: 0.9965625\n",
      "epoch: 3, batch: 619,                 loss: 0.013143631877122267, training accuracy: 0.9966733870967742\n",
      "epoch: 3, batch: 639,                 loss: 0.012964413680765573, training accuracy: 0.99677734375\n",
      "epoch: 3, batch: 659,                 loss: 0.012810923895272991, training accuracy: 0.996875\n",
      "epoch: 3, batch: 679,                 loss: 0.012507210831801572, training accuracy: 0.9969669117647059\n",
      "epoch: 3, batch: 699,                 loss: 0.01221529309122291, training accuracy: 0.9970535714285714\n",
      "epoch: 3, batch: 719,                 loss: 0.012017038675387287, training accuracy: 0.9971354166666667\n",
      "epoch: 3, batch: 739,                 loss: 0.011886043469555286, training accuracy: 0.9971283783783784\n",
      "epoch: 3, batch: 759,                 loss: 0.012123574092899951, training accuracy: 0.9971217105263158\n",
      "epoch: 3, batch: 779,                 loss: 0.011917212481150786, training accuracy: 0.9971955128205128\n",
      "epoch: 3, batch: 799,                 loss: 0.011842102294576762, training accuracy: 0.9971875\n",
      "epoch: 3, batch: 819,                 loss: 0.011781434317029979, training accuracy: 0.9971798780487805\n",
      "epoch: 3, batch: 839,                 loss: 0.011983197676454439, training accuracy: 0.9970982142857143\n",
      "epoch: 3, batch: 859,                 loss: 0.011978902701433303, training accuracy: 0.9970203488372092\n",
      "epoch: 3, batch: 879,                 loss: 0.011765095006194316, training accuracy: 0.9970880681818182\n",
      "epoch: 3, batch: 899,                 loss: 0.011806110060586232, training accuracy: 0.9970833333333333\n",
      "epoch: 3, batch: 919,                 loss: 0.011596476576833874, training accuracy: 0.9971467391304348\n",
      "epoch: 3, batch: 939,                 loss: 0.01165612560020081, training accuracy: 0.9970744680851064\n",
      "epoch: 3, batch: 959,                 loss: 0.011650592576521982, training accuracy: 0.9971354166666667\n",
      "epoch: 3, batch: 979,                 loss: 0.011554998864285524, training accuracy: 0.9971938775510204\n",
      "epoch: 3, batch: 999,                 loss: 0.011349816397036193, training accuracy: 0.99725\n",
      "epoch: 3, batch: 1019,                 loss: 0.011285775487354556, training accuracy: 0.9972426470588235\n",
      "epoch: 3, batch: 1039,                 loss: 0.011142245106804274, training accuracy: 0.9972956730769231\n",
      "epoch: 3, batch: 1059,                 loss: 0.011001099927931857, training accuracy: 0.9973466981132075\n",
      "epoch: 3, batch: 1079,                 loss: 0.011311766295532127, training accuracy: 0.9972800925925925\n",
      "epoch: 3, batch: 1099,                 loss: 0.011250048740634653, training accuracy: 0.9972727272727273\n",
      "epoch: 3, batch: 1119,                 loss: 0.011203612260162896, training accuracy: 0.997265625\n",
      "epoch: 3, batch: 1139,                 loss: 0.011147488412608621, training accuracy: 0.9972587719298246\n",
      "epoch: 3, batch: 1159,                 loss: 0.011098252024912027, training accuracy: 0.9973060344827587\n",
      "epoch: 3, batch: 1179,                 loss: 0.010942508979361125, training accuracy: 0.9973516949152542\n",
      "epoch: 3, batch: 1199,                 loss: 0.010807364186427245, training accuracy: 0.9973958333333334\n",
      "epoch: 3, batch: 1219,                 loss: 0.010837831748883264, training accuracy: 0.9973872950819672\n",
      "epoch: 3, batch: 1239,                 loss: 0.010802226377235193, training accuracy: 0.997328629032258\n",
      "epoch: 3, batch: 1259,                 loss: 0.01124262468199179, training accuracy: 0.9972222222222222\n",
      "epoch: 3, batch: 1279,                 loss: 0.011187236423870673, training accuracy: 0.997216796875\n",
      "epoch: 3, batch: 1299,                 loss: 0.011161140224218028, training accuracy: 0.9972115384615384\n",
      "validation accuracy 0.9923\n",
      "test_accuracy 0.6129\n",
      "Saved weights/resnet101-epoch-2-valid_acc=0.9923-test_acc=0.6129.pt\n",
      "epoch: 4, batch: 19,                 loss: 0.011008305945142637, training accuracy: 0.99375\n",
      "epoch: 4, batch: 39,                 loss: 0.006820640369551256, training accuracy: 0.996875\n",
      "epoch: 4, batch: 59,                 loss: 0.01154194173286669, training accuracy: 0.9958333333333333\n",
      "epoch: 4, batch: 79,                 loss: 0.009033079238724895, training accuracy: 0.996875\n",
      "epoch: 4, batch: 99,                 loss: 0.007829331870889291, training accuracy: 0.9975\n",
      "epoch: 4, batch: 119,                 loss: 0.007259210049960529, training accuracy: 0.9979166666666667\n",
      "epoch: 4, batch: 139,                 loss: 0.006559967079998127, training accuracy: 0.9982142857142857\n",
      "epoch: 4, batch: 159,                 loss: 0.008463949842007424, training accuracy: 0.998046875\n",
      "epoch: 4, batch: 179,                 loss: 0.007875448064765402, training accuracy: 0.9982638888888888\n",
      "epoch: 4, batch: 199,                 loss: 0.007566674751724349, training accuracy: 0.9984375\n",
      "epoch: 4, batch: 219,                 loss: 0.007150156151460992, training accuracy: 0.9985795454545454\n",
      "epoch: 4, batch: 239,                 loss: 0.006745798595390321, training accuracy: 0.9986979166666666\n",
      "epoch: 4, batch: 259,                 loss: 0.006353080858724962, training accuracy: 0.9987980769230769\n",
      "epoch: 4, batch: 279,                 loss: 0.006498923007321926, training accuracy: 0.9988839285714286\n",
      "epoch: 4, batch: 299,                 loss: 0.006352093345728159, training accuracy: 0.9989583333333333\n",
      "epoch: 4, batch: 319,                 loss: 0.006172672109505584, training accuracy: 0.9990234375\n",
      "epoch: 4, batch: 339,                 loss: 0.0061634575206399485, training accuracy: 0.9988970588235294\n",
      "epoch: 4, batch: 359,                 loss: 0.006021043155447437, training accuracy: 0.9989583333333333\n",
      "epoch: 4, batch: 379,                 loss: 0.005976443520615392, training accuracy: 0.9990131578947369\n",
      "epoch: 4, batch: 399,                 loss: 0.0057814247227361195, training accuracy: 0.9990625\n",
      "epoch: 4, batch: 419,                 loss: 0.006297852134628643, training accuracy: 0.9988095238095238\n",
      "epoch: 4, batch: 439,                 loss: 0.006311757422107885, training accuracy: 0.998721590909091\n",
      "epoch: 4, batch: 459,                 loss: 0.006152636652468177, training accuracy: 0.9987771739130434\n",
      "epoch: 4, batch: 479,                 loss: 0.005951963854355805, training accuracy: 0.998828125\n",
      "epoch: 4, batch: 499,                 loss: 0.005836700575397117, training accuracy: 0.998875\n",
      "epoch: 4, batch: 519,                 loss: 0.005726808544820345, training accuracy: 0.9989182692307692\n",
      "epoch: 4, batch: 539,                 loss: 0.005591617476360018, training accuracy: 0.9989583333333333\n",
      "epoch: 4, batch: 559,                 loss: 0.00545391394041092, training accuracy: 0.9989955357142857\n",
      "epoch: 4, batch: 579,                 loss: 0.00536585498297866, training accuracy: 0.9990301724137931\n",
      "epoch: 4, batch: 599,                 loss: 0.005305798826484533, training accuracy: 0.9990625\n",
      "epoch: 4, batch: 619,                 loss: 0.005198480779290549, training accuracy: 0.9990927419354839\n",
      "epoch: 4, batch: 639,                 loss: 0.005181707690951498, training accuracy: 0.9990234375\n",
      "epoch: 4, batch: 659,                 loss: 0.0050905206686421125, training accuracy: 0.9990530303030303\n",
      "epoch: 4, batch: 679,                 loss: 0.005021986556643884, training accuracy: 0.9990808823529411\n",
      "epoch: 4, batch: 699,                 loss: 0.005081885062401333, training accuracy: 0.9990178571428572\n",
      "epoch: 4, batch: 719,                 loss: 0.005355622571823915, training accuracy: 0.9988715277777778\n",
      "epoch: 4, batch: 739,                 loss: 0.0053296141981361966, training accuracy: 0.998902027027027\n",
      "epoch: 4, batch: 759,                 loss: 0.0053987900215744095, training accuracy: 0.9988486842105263\n",
      "epoch: 4, batch: 779,                 loss: 0.005305404390422225, training accuracy: 0.9988782051282051\n",
      "epoch: 4, batch: 799,                 loss: 0.005314226611853883, training accuracy: 0.99890625\n",
      "epoch: 4, batch: 819,                 loss: 0.00526354652234082, training accuracy: 0.9989329268292683\n",
      "epoch: 4, batch: 839,                 loss: 0.005206286951934523, training accuracy: 0.9989583333333333\n",
      "epoch: 4, batch: 859,                 loss: 0.00549397279115341, training accuracy: 0.9989098837209303\n",
      "epoch: 4, batch: 879,                 loss: 0.005887772841784185, training accuracy: 0.9988636363636364\n",
      "epoch: 4, batch: 899,                 loss: 0.005825716139523946, training accuracy: 0.9988888888888889\n",
      "epoch: 4, batch: 919,                 loss: 0.005788009251370132, training accuracy: 0.9989130434782608\n",
      "epoch: 4, batch: 939,                 loss: 0.006038101677040686, training accuracy: 0.9988031914893617\n",
      "epoch: 4, batch: 959,                 loss: 0.006085644972540649, training accuracy: 0.9987630208333333\n",
      "epoch: 4, batch: 979,                 loss: 0.006077670725069914, training accuracy: 0.9987882653061224\n",
      "epoch: 4, batch: 999,                 loss: 0.0061834128975242495, training accuracy: 0.99875\n",
      "epoch: 4, batch: 1019,                 loss: 0.006385170272530077, training accuracy: 0.9985906862745098\n",
      "epoch: 4, batch: 1039,                 loss: 0.006297806771943634, training accuracy: 0.9986177884615385\n",
      "epoch: 4, batch: 1059,                 loss: 0.006342280861535297, training accuracy: 0.9985849056603774\n",
      "epoch: 4, batch: 1079,                 loss: 0.006268028773673804, training accuracy: 0.9986111111111111\n",
      "epoch: 4, batch: 1099,                 loss: 0.006235114836262338, training accuracy: 0.9985795454545454\n",
      "epoch: 4, batch: 1119,                 loss: 0.006291212482918646, training accuracy: 0.9984933035714286\n",
      "epoch: 4, batch: 1139,                 loss: 0.006485587187330167, training accuracy: 0.9984649122807018\n",
      "epoch: 4, batch: 1159,                 loss: 0.006474194153401939, training accuracy: 0.9984375\n",
      "epoch: 4, batch: 1179,                 loss: 0.006400140847423029, training accuracy: 0.9984639830508475\n",
      "epoch: 4, batch: 1199,                 loss: 0.006348533322313112, training accuracy: 0.9984895833333334\n",
      "epoch: 4, batch: 1219,                 loss: 0.006306361082682938, training accuracy: 0.9985143442622951\n",
      "epoch: 4, batch: 1239,                 loss: 0.006236967751271638, training accuracy: 0.9985383064516129\n",
      "epoch: 4, batch: 1259,                 loss: 0.006158118747494189, training accuracy: 0.9985615079365079\n",
      "epoch: 4, batch: 1279,                 loss: 0.006402140521657884, training accuracy: 0.9984375\n",
      "epoch: 4, batch: 1299,                 loss: 0.006456836777948551, training accuracy: 0.9984134615384616\n",
      "validation accuracy 0.9923\n",
      "test_accuracy 0.6122\n",
      "Saved weights/resnet101-epoch-3-valid_acc=0.9923-test_acc=0.6122.pt\n",
      "epoch: 5, batch: 19,                 loss: 0.0021629123781167436, training accuracy: 1.0\n",
      "epoch: 5, batch: 39,                 loss: 0.0025723936880240215, training accuracy: 1.0\n",
      "epoch: 5, batch: 59,                 loss: 0.002248186297462477, training accuracy: 1.0\n",
      "epoch: 5, batch: 79,                 loss: 0.002358599090075586, training accuracy: 1.0\n",
      "epoch: 5, batch: 99,                 loss: 0.004322021258121822, training accuracy: 0.999375\n",
      "epoch: 5, batch: 119,                 loss: 0.0037788671086066944, training accuracy: 0.9994791666666667\n",
      "epoch: 5, batch: 139,                 loss: 0.0036182107158570682, training accuracy: 0.9995535714285714\n",
      "epoch: 5, batch: 159,                 loss: 0.003417708766846772, training accuracy: 0.999609375\n",
      "epoch: 5, batch: 179,                 loss: 0.004962813503031308, training accuracy: 0.9989583333333333\n",
      "epoch: 5, batch: 199,                 loss: 0.0054230046088196105, training accuracy: 0.99875\n",
      "epoch: 5, batch: 219,                 loss: 0.00510038854769267, training accuracy: 0.9988636363636364\n",
      "epoch: 5, batch: 239,                 loss: 0.004763584325610281, training accuracy: 0.9989583333333333\n",
      "epoch: 5, batch: 259,                 loss: 0.00479431159678475, training accuracy: 0.9987980769230769\n",
      "epoch: 5, batch: 279,                 loss: 0.005313257913309956, training accuracy: 0.9986607142857142\n",
      "epoch: 5, batch: 299,                 loss: 0.005044113053760763, training accuracy: 0.99875\n",
      "epoch: 5, batch: 319,                 loss: 0.004851302298652627, training accuracy: 0.998828125\n",
      "epoch: 5, batch: 339,                 loss: 0.005252449637854999, training accuracy: 0.9987132352941176\n",
      "epoch: 5, batch: 359,                 loss: 0.005136884249744374, training accuracy: 0.9987847222222223\n",
      "epoch: 5, batch: 379,                 loss: 0.004978203032825197, training accuracy: 0.9988486842105263\n",
      "epoch: 5, batch: 399,                 loss: 0.005100191789751989, training accuracy: 0.99875\n",
      "epoch: 5, batch: 419,                 loss: 0.004949280769228824, training accuracy: 0.9988095238095238\n",
      "epoch: 5, batch: 439,                 loss: 0.004866318644648841, training accuracy: 0.9988636363636364\n",
      "epoch: 5, batch: 459,                 loss: 0.005443329300412544, training accuracy: 0.9987771739130434\n",
      "epoch: 5, batch: 479,                 loss: 0.0053462186635442775, training accuracy: 0.998828125\n",
      "epoch: 5, batch: 499,                 loss: 0.0056623161516035905, training accuracy: 0.99875\n",
      "epoch: 5, batch: 519,                 loss: 0.005587763232016677, training accuracy: 0.9987980769230769\n",
      "epoch: 5, batch: 539,                 loss: 0.005593940916016301, training accuracy: 0.9987268518518518\n",
      "epoch: 5, batch: 559,                 loss: 0.005675274064872481, training accuracy: 0.9986607142857142\n",
      "epoch: 5, batch: 579,                 loss: 0.005574047564782789, training accuracy: 0.9987068965517242\n",
      "epoch: 5, batch: 599,                 loss: 0.005505173243679261, training accuracy: 0.99875\n",
      "epoch: 5, batch: 619,                 loss: 0.005559500808733226, training accuracy: 0.9986895161290322\n",
      "epoch: 5, batch: 639,                 loss: 0.005460651986209086, training accuracy: 0.99873046875\n",
      "epoch: 5, batch: 659,                 loss: 0.00538436117973161, training accuracy: 0.9987689393939394\n",
      "epoch: 5, batch: 679,                 loss: 0.005283551493074115, training accuracy: 0.9988051470588235\n",
      "epoch: 5, batch: 699,                 loss: 0.005171339899388841, training accuracy: 0.9988392857142857\n",
      "epoch: 5, batch: 719,                 loss: 0.005078179271185946, training accuracy: 0.9988715277777778\n",
      "epoch: 5, batch: 739,                 loss: 0.004986916247356488, training accuracy: 0.998902027027027\n",
      "epoch: 5, batch: 759,                 loss: 0.00488628536863153, training accuracy: 0.9989309210526316\n",
      "epoch: 5, batch: 779,                 loss: 0.004778816050542772, training accuracy: 0.9989583333333333\n",
      "epoch: 5, batch: 799,                 loss: 0.004683334542514786, training accuracy: 0.998984375\n",
      "epoch: 5, batch: 819,                 loss: 0.004595591207801523, training accuracy: 0.9990091463414634\n",
      "epoch: 5, batch: 839,                 loss: 0.004680754423619268, training accuracy: 0.9989583333333333\n",
      "epoch: 5, batch: 859,                 loss: 0.0047350715167890165, training accuracy: 0.9988372093023256\n",
      "epoch: 5, batch: 879,                 loss: 0.004891644969335506, training accuracy: 0.9987926136363636\n",
      "epoch: 5, batch: 899,                 loss: 0.004912114837700049, training accuracy: 0.99875\n",
      "epoch: 5, batch: 919,                 loss: 0.004855811623620748, training accuracy: 0.9987771739130434\n",
      "epoch: 5, batch: 939,                 loss: 0.0048167634879451296, training accuracy: 0.9988031914893617\n",
      "epoch: 5, batch: 959,                 loss: 0.00494011256922325, training accuracy: 0.9986979166666666\n",
      "epoch: 5, batch: 979,                 loss: 0.00490008868852913, training accuracy: 0.9987244897959183\n",
      "epoch: 5, batch: 999,                 loss: 0.004979869671835331, training accuracy: 0.9986875\n",
      "epoch: 5, batch: 1019,                 loss: 0.00498831984022057, training accuracy: 0.9987132352941176\n",
      "epoch: 5, batch: 1039,                 loss: 0.00499857605338128, training accuracy: 0.9986778846153846\n",
      "epoch: 5, batch: 1059,                 loss: 0.005265020053693146, training accuracy: 0.9985259433962265\n",
      "epoch: 5, batch: 1079,                 loss: 0.0052070029248878, training accuracy: 0.9985532407407407\n",
      "epoch: 5, batch: 1099,                 loss: 0.005321135664932875, training accuracy: 0.998465909090909\n",
      "epoch: 5, batch: 1119,                 loss: 0.005789527976464472, training accuracy: 0.9983258928571429\n",
      "epoch: 5, batch: 1139,                 loss: 0.005903216111249078, training accuracy: 0.9982456140350877\n",
      "epoch: 5, batch: 1159,                 loss: 0.0059676280246941165, training accuracy: 0.9982219827586207\n",
      "epoch: 5, batch: 1179,                 loss: 0.005995853275780357, training accuracy: 0.9981991525423729\n",
      "epoch: 5, batch: 1199,                 loss: 0.005986747025623723, training accuracy: 0.9982291666666666\n",
      "epoch: 5, batch: 1219,                 loss: 0.006213527080363434, training accuracy: 0.9982069672131147\n",
      "epoch: 5, batch: 1239,                 loss: 0.006263116793519247, training accuracy: 0.9981854838709677\n",
      "epoch: 5, batch: 1259,                 loss: 0.006284026783454003, training accuracy: 0.9982142857142857\n",
      "epoch: 5, batch: 1279,                 loss: 0.006361281395322748, training accuracy: 0.99814453125\n",
      "epoch: 5, batch: 1299,                 loss: 0.006326062373857265, training accuracy: 0.9981730769230769\n",
      "validation accuracy 0.9936\n",
      "test_accuracy 0.6241\n",
      "Saved weights/resnet101-epoch-4-valid_acc=0.9936-test_acc=0.6241.pt\n",
      "epoch: 6, batch: 19,                 loss: 0.002673235204201774, training accuracy: 1.0\n",
      "epoch: 6, batch: 39,                 loss: 0.0018780080161377554, training accuracy: 1.0\n",
      "epoch: 6, batch: 59,                 loss: 0.0020281107380772786, training accuracy: 1.0\n",
      "epoch: 6, batch: 79,                 loss: 0.0023011779929220212, training accuracy: 1.0\n",
      "epoch: 6, batch: 99,                 loss: 0.0024456631474458843, training accuracy: 1.0\n",
      "epoch: 6, batch: 119,                 loss: 0.0031666712807539928, training accuracy: 0.9994791666666667\n",
      "epoch: 6, batch: 139,                 loss: 0.002991354089889293, training accuracy: 0.9995535714285714\n",
      "epoch: 6, batch: 159,                 loss: 0.002786207016606568, training accuracy: 0.999609375\n",
      "epoch: 6, batch: 179,                 loss: 0.0029080336626066128, training accuracy: 0.9993055555555556\n",
      "epoch: 6, batch: 199,                 loss: 0.002786686301806185, training accuracy: 0.999375\n",
      "epoch: 6, batch: 219,                 loss: 0.00378463475353783, training accuracy: 0.9991477272727273\n",
      "epoch: 6, batch: 239,                 loss: 0.003751796111494817, training accuracy: 0.99921875\n",
      "epoch: 6, batch: 259,                 loss: 0.003689652922184905, training accuracy: 0.9992788461538461\n",
      "epoch: 6, batch: 279,                 loss: 0.003920490021352765, training accuracy: 0.9988839285714286\n",
      "epoch: 6, batch: 299,                 loss: 0.0037381964219578854, training accuracy: 0.9989583333333333\n",
      "epoch: 6, batch: 319,                 loss: 0.0036364958686590397, training accuracy: 0.9990234375\n",
      "epoch: 6, batch: 339,                 loss: 0.003581454606875709, training accuracy: 0.9990808823529411\n",
      "epoch: 6, batch: 359,                 loss: 0.0035587232890166988, training accuracy: 0.9991319444444444\n",
      "epoch: 6, batch: 379,                 loss: 0.0035228097323086235, training accuracy: 0.9991776315789473\n",
      "epoch: 6, batch: 399,                 loss: 0.0034848883480299263, training accuracy: 0.9990625\n",
      "epoch: 6, batch: 419,                 loss: 0.0034929041111484236, training accuracy: 0.9991071428571429\n",
      "epoch: 6, batch: 439,                 loss: 0.00487755702276693, training accuracy: 0.9988636363636364\n",
      "epoch: 6, batch: 459,                 loss: 0.0053897919409791935, training accuracy: 0.998641304347826\n",
      "epoch: 6, batch: 479,                 loss: 0.005664513421622056, training accuracy: 0.9984375\n",
      "epoch: 6, batch: 499,                 loss: 0.006776236492121825, training accuracy: 0.998125\n",
      "epoch: 6, batch: 519,                 loss: 0.007214935195140872, training accuracy: 0.9980769230769231\n",
      "epoch: 6, batch: 539,                 loss: 0.007090469528743092, training accuracy: 0.9981481481481481\n",
      "epoch: 6, batch: 559,                 loss: 0.007196830140388296, training accuracy: 0.9979910714285715\n",
      "epoch: 6, batch: 579,                 loss: 0.007016310889719471, training accuracy: 0.9980603448275862\n",
      "epoch: 6, batch: 599,                 loss: 0.006890138219581179, training accuracy: 0.998125\n",
      "epoch: 6, batch: 619,                 loss: 0.006960288814039931, training accuracy: 0.9980846774193548\n",
      "epoch: 6, batch: 639,                 loss: 0.006855063242710457, training accuracy: 0.99814453125\n",
      "epoch: 6, batch: 659,                 loss: 0.007028041515039865, training accuracy: 0.9980113636363637\n",
      "epoch: 6, batch: 679,                 loss: 0.0068905641116597345, training accuracy: 0.9980698529411764\n",
      "epoch: 6, batch: 699,                 loss: 0.006783964676807435, training accuracy: 0.998125\n",
      "epoch: 6, batch: 719,                 loss: 0.006975839007787322, training accuracy: 0.9980034722222222\n",
      "epoch: 6, batch: 739,                 loss: 0.006869831846219116, training accuracy: 0.9980574324324324\n",
      "epoch: 6, batch: 759,                 loss: 0.007077560943741302, training accuracy: 0.9979440789473685\n",
      "epoch: 6, batch: 779,                 loss: 0.006947008239531454, training accuracy: 0.9979967948717948\n",
      "epoch: 6, batch: 799,                 loss: 0.0069814455550658745, training accuracy: 0.99796875\n",
      "epoch: 6, batch: 819,                 loss: 0.006871539575655422, training accuracy: 0.9980182926829269\n",
      "epoch: 6, batch: 839,                 loss: 0.006996814396829688, training accuracy: 0.9979910714285715\n",
      "epoch: 6, batch: 859,                 loss: 0.006883321483575517, training accuracy: 0.9980377906976744\n",
      "epoch: 6, batch: 879,                 loss: 0.006786338587186368, training accuracy: 0.9980823863636363\n",
      "epoch: 6, batch: 899,                 loss: 0.006936920971331549, training accuracy: 0.9979861111111111\n",
      "epoch: 6, batch: 919,                 loss: 0.007499979214378033, training accuracy: 0.9978940217391304\n",
      "epoch: 6, batch: 939,                 loss: 0.0073819357587939175, training accuracy: 0.997938829787234\n",
      "epoch: 6, batch: 959,                 loss: 0.00732725408575637, training accuracy: 0.9979817708333333\n",
      "epoch: 6, batch: 979,                 loss: 0.007212283366933829, training accuracy: 0.9980229591836735\n",
      "epoch: 6, batch: 999,                 loss: 0.007109264742568485, training accuracy: 0.9980625\n",
      "epoch: 6, batch: 1019,                 loss: 0.0070063064177149645, training accuracy: 0.9981004901960784\n",
      "epoch: 6, batch: 1039,                 loss: 0.007074847652865384, training accuracy: 0.9980769230769231\n",
      "epoch: 6, batch: 1059,                 loss: 0.007045908322848022, training accuracy: 0.9980542452830189\n",
      "epoch: 6, batch: 1079,                 loss: 0.0069334861858604, training accuracy: 0.9980902777777778\n",
      "epoch: 6, batch: 1099,                 loss: 0.006826255609002229, training accuracy: 0.998125\n",
      "epoch: 6, batch: 1119,                 loss: 0.006719339640013849, training accuracy: 0.9981584821428572\n",
      "epoch: 6, batch: 1139,                 loss: 0.00663522158282783, training accuracy: 0.9981907894736842\n",
      "epoch: 6, batch: 1159,                 loss: 0.006532341766793753, training accuracy: 0.9982219827586207\n",
      "epoch: 6, batch: 1179,                 loss: 0.006483466240637951, training accuracy: 0.9982521186440678\n",
      "epoch: 6, batch: 1199,                 loss: 0.006387702645943136, training accuracy: 0.99828125\n",
      "epoch: 6, batch: 1219,                 loss: 0.006519894318223466, training accuracy: 0.9982069672131147\n",
      "epoch: 6, batch: 1239,                 loss: 0.006447403639618466, training accuracy: 0.9982358870967742\n",
      "epoch: 6, batch: 1259,                 loss: 0.006411924468871831, training accuracy: 0.9982142857142857\n",
      "epoch: 6, batch: 1279,                 loss: 0.006348419785811643, training accuracy: 0.9982421875\n",
      "epoch: 6, batch: 1299,                 loss: 0.006270650560184619, training accuracy: 0.9982692307692308\n",
      "validation accuracy 0.9932\n",
      "test_accuracy 0.6106\n",
      "Saved weights/resnet101-epoch-5-valid_acc=0.9932-test_acc=0.6106.pt\n",
      "Finished Training: resnet101\n",
      "epoch: 1, batch: 19,                 loss: 0.6840187788009644, training accuracy: 0.546875\n",
      "epoch: 1, batch: 39,                 loss: 0.6512618273496628, training accuracy: 0.625\n",
      "epoch: 1, batch: 59,                 loss: 0.614131024479866, training accuracy: 0.6895833333333333\n",
      "epoch: 1, batch: 79,                 loss: 0.5867847818881273, training accuracy: 0.7234375\n",
      "epoch: 1, batch: 99,                 loss: 0.5597643154859543, training accuracy: 0.750625\n",
      "epoch: 1, batch: 119,                 loss: 0.536987604945898, training accuracy: 0.7734375\n",
      "epoch: 1, batch: 139,                 loss: 0.5152476370334625, training accuracy: 0.7919642857142857\n",
      "epoch: 1, batch: 159,                 loss: 0.49590664617717267, training accuracy: 0.80703125\n",
      "epoch: 1, batch: 179,                 loss: 0.4758736710581515, training accuracy: 0.821875\n",
      "epoch: 1, batch: 199,                 loss: 0.4576127204298973, training accuracy: 0.834375\n",
      "epoch: 1, batch: 219,                 loss: 0.4411946060982617, training accuracy: 0.8443181818181819\n",
      "epoch: 1, batch: 239,                 loss: 0.4258084979529182, training accuracy: 0.8520833333333333\n",
      "epoch: 1, batch: 259,                 loss: 0.4135829337514364, training accuracy: 0.8584134615384615\n",
      "epoch: 1, batch: 279,                 loss: 0.39991037127162726, training accuracy: 0.8636160714285714\n",
      "epoch: 1, batch: 299,                 loss: 0.38915869042277335, training accuracy: 0.868125\n",
      "epoch: 1, batch: 319,                 loss: 0.3783792115515098, training accuracy: 0.8716796875\n",
      "epoch: 1, batch: 339,                 loss: 0.366578811998753, training accuracy: 0.8764705882352941\n",
      "epoch: 1, batch: 359,                 loss: 0.3563957331495153, training accuracy: 0.88125\n",
      "epoch: 1, batch: 379,                 loss: 0.34660352346928497, training accuracy: 0.8850328947368421\n",
      "epoch: 1, batch: 399,                 loss: 0.33755910797044636, training accuracy: 0.88875\n",
      "epoch: 1, batch: 419,                 loss: 0.3275979712339384, training accuracy: 0.893452380952381\n",
      "epoch: 1, batch: 439,                 loss: 0.3197288701226088, training accuracy: 0.8964488636363637\n",
      "epoch: 1, batch: 459,                 loss: 0.3128178082730459, training accuracy: 0.8983695652173913\n",
      "epoch: 1, batch: 479,                 loss: 0.30623903738645214, training accuracy: 0.9006510416666667\n",
      "epoch: 1, batch: 499,                 loss: 0.29997337935119867, training accuracy: 0.903\n",
      "epoch: 1, batch: 519,                 loss: 0.29310636571966686, training accuracy: 0.9058894230769231\n",
      "epoch: 1, batch: 539,                 loss: 0.2881258265425762, training accuracy: 0.9078703703703703\n",
      "epoch: 1, batch: 559,                 loss: 0.28220426077688376, training accuracy: 0.9100446428571428\n",
      "epoch: 1, batch: 579,                 loss: 0.276829517619877, training accuracy: 0.9114224137931034\n",
      "epoch: 1, batch: 599,                 loss: 0.27098501605913045, training accuracy: 0.9135416666666667\n",
      "epoch: 1, batch: 619,                 loss: 0.26703672194552996, training accuracy: 0.9150201612903226\n",
      "epoch: 1, batch: 639,                 loss: 0.2609871575899888, training accuracy: 0.9171875\n",
      "epoch: 1, batch: 659,                 loss: 0.2563752091800173, training accuracy: 0.918844696969697\n",
      "epoch: 1, batch: 679,                 loss: 0.2524292600450709, training accuracy: 0.9199448529411764\n",
      "epoch: 1, batch: 699,                 loss: 0.2478877163625189, training accuracy: 0.9217857142857143\n",
      "epoch: 1, batch: 719,                 loss: 0.24417483773496415, training accuracy: 0.9229166666666667\n",
      "epoch: 1, batch: 739,                 loss: 0.2402227602798391, training accuracy: 0.9244087837837838\n",
      "epoch: 1, batch: 759,                 loss: 0.23657513352993287, training accuracy: 0.9256578947368421\n",
      "epoch: 1, batch: 779,                 loss: 0.23369334246246862, training accuracy: 0.9264423076923077\n",
      "epoch: 1, batch: 799,                 loss: 0.23022110834717752, training accuracy: 0.927734375\n",
      "epoch: 1, batch: 819,                 loss: 0.22714418360236577, training accuracy: 0.9284298780487805\n",
      "epoch: 1, batch: 839,                 loss: 0.22463735642488158, training accuracy: 0.9293154761904762\n",
      "epoch: 1, batch: 859,                 loss: 0.2211452820208357, training accuracy: 0.9305232558139535\n",
      "epoch: 1, batch: 879,                 loss: 0.2179670886813917, training accuracy: 0.9315340909090909\n",
      "epoch: 1, batch: 899,                 loss: 0.21543136858691772, training accuracy: 0.9322916666666666\n",
      "epoch: 1, batch: 919,                 loss: 0.21236915329228276, training accuracy: 0.9330842391304348\n",
      "epoch: 1, batch: 939,                 loss: 0.20918403437083705, training accuracy: 0.9341755319148937\n",
      "epoch: 1, batch: 959,                 loss: 0.2064227949847312, training accuracy: 0.93515625\n",
      "epoch: 1, batch: 979,                 loss: 0.20404497211304853, training accuracy: 0.9360331632653062\n",
      "epoch: 1, batch: 999,                 loss: 0.20118959976918996, training accuracy: 0.9370625\n",
      "epoch: 1, batch: 1019,                 loss: 0.19961323400813283, training accuracy: 0.9373161764705882\n",
      "epoch: 1, batch: 1039,                 loss: 0.19738208453636616, training accuracy: 0.93828125\n",
      "epoch: 1, batch: 1059,                 loss: 0.19518641716677626, training accuracy: 0.9387971698113208\n",
      "epoch: 1, batch: 1079,                 loss: 0.19301643058554166, training accuracy: 0.9395254629629629\n",
      "epoch: 1, batch: 1099,                 loss: 0.19035920926623723, training accuracy: 0.9404545454545454\n",
      "epoch: 1, batch: 1119,                 loss: 0.1891943670460023, training accuracy: 0.9408482142857143\n",
      "epoch: 1, batch: 1139,                 loss: 0.18695325297140108, training accuracy: 0.9416666666666667\n",
      "epoch: 1, batch: 1159,                 loss: 0.18471524812811022, training accuracy: 0.9424568965517242\n",
      "epoch: 1, batch: 1179,                 loss: 0.18273163581014437, training accuracy: 0.9430614406779662\n",
      "epoch: 1, batch: 1199,                 loss: 0.18128227160622676, training accuracy: 0.9435416666666666\n",
      "epoch: 1, batch: 1219,                 loss: 0.17938321174168195, training accuracy: 0.9441598360655737\n",
      "epoch: 1, batch: 1239,                 loss: 0.17752509394720678, training accuracy: 0.9448084677419355\n",
      "epoch: 1, batch: 1259,                 loss: 0.17574050698488478, training accuracy: 0.9452876984126984\n",
      "epoch: 1, batch: 1279,                 loss: 0.17391479869402246, training accuracy: 0.945849609375\n",
      "epoch: 1, batch: 1299,                 loss: 0.17194055267609656, training accuracy: 0.9465384615384616\n",
      "validation accuracy 0.9766\n",
      "test_accuracy 0.5587\n",
      "Saved weights/densenet121-epoch-0-valid_acc=0.9766-test_acc=0.5587.pt\n",
      "epoch: 2, batch: 19,                 loss: 0.069404968759045, training accuracy: 0.975\n",
      "epoch: 2, batch: 39,                 loss: 0.05041355825960636, training accuracy: 0.9875\n",
      "epoch: 2, batch: 59,                 loss: 0.04947797041386366, training accuracy: 0.9875\n",
      "epoch: 2, batch: 79,                 loss: 0.05315033997176215, training accuracy: 0.9859375\n",
      "epoch: 2, batch: 99,                 loss: 0.05552854568697512, training accuracy: 0.984375\n",
      "epoch: 2, batch: 119,                 loss: 0.055963957829711336, training accuracy: 0.9833333333333333\n",
      "epoch: 2, batch: 139,                 loss: 0.054521352571568316, training accuracy: 0.9839285714285714\n",
      "epoch: 2, batch: 159,                 loss: 0.053007945365970956, training accuracy: 0.98515625\n",
      "epoch: 2, batch: 179,                 loss: 0.05206038448959589, training accuracy: 0.9854166666666667\n",
      "epoch: 2, batch: 199,                 loss: 0.055649727615527805, training accuracy: 0.985\n",
      "epoch: 2, batch: 219,                 loss: 0.05764010093513538, training accuracy: 0.9840909090909091\n",
      "epoch: 2, batch: 239,                 loss: 0.057102238553731394, training accuracy: 0.9838541666666667\n",
      "epoch: 2, batch: 259,                 loss: 0.05621266843070491, training accuracy: 0.984375\n",
      "epoch: 2, batch: 279,                 loss: 0.054385201295372096, training accuracy: 0.9850446428571429\n",
      "epoch: 2, batch: 299,                 loss: 0.05414089520927519, training accuracy: 0.9852083333333334\n",
      "epoch: 2, batch: 319,                 loss: 0.05381905552203534, training accuracy: 0.9853515625\n",
      "epoch: 2, batch: 339,                 loss: 0.054281512339709, training accuracy: 0.9849264705882353\n",
      "epoch: 2, batch: 359,                 loss: 0.05470694140919174, training accuracy: 0.9847222222222223\n",
      "epoch: 2, batch: 379,                 loss: 0.05428978472972583, training accuracy: 0.984703947368421\n",
      "epoch: 2, batch: 399,                 loss: 0.053981662552105264, training accuracy: 0.985\n",
      "epoch: 2, batch: 419,                 loss: 0.05315826567710333, training accuracy: 0.9854166666666667\n",
      "epoch: 2, batch: 439,                 loss: 0.05403075428700752, training accuracy: 0.9849431818181819\n",
      "epoch: 2, batch: 459,                 loss: 0.053178010203713634, training accuracy: 0.9853260869565217\n",
      "epoch: 2, batch: 479,                 loss: 0.053373012525844386, training accuracy: 0.98515625\n",
      "epoch: 2, batch: 499,                 loss: 0.05431414569821209, training accuracy: 0.984375\n",
      "epoch: 2, batch: 519,                 loss: 0.05365688831079751, training accuracy: 0.9848557692307692\n",
      "epoch: 2, batch: 539,                 loss: 0.05410426883371892, training accuracy: 0.9844907407407407\n",
      "epoch: 2, batch: 559,                 loss: 0.05417875703923138, training accuracy: 0.9844866071428572\n",
      "epoch: 2, batch: 579,                 loss: 0.05346250367382991, training accuracy: 0.9844827586206897\n",
      "epoch: 2, batch: 599,                 loss: 0.05349397803501536, training accuracy: 0.9844791666666667\n",
      "epoch: 2, batch: 619,                 loss: 0.05292439899302178, training accuracy: 0.9845766129032258\n",
      "epoch: 2, batch: 639,                 loss: 0.05228378530446207, training accuracy: 0.984765625\n",
      "epoch: 2, batch: 659,                 loss: 0.05171405519570478, training accuracy: 0.9849431818181819\n",
      "epoch: 2, batch: 679,                 loss: 0.05156121982042404, training accuracy: 0.9849264705882353\n",
      "epoch: 2, batch: 699,                 loss: 0.05124874700193426, training accuracy: 0.985\n",
      "epoch: 2, batch: 719,                 loss: 0.051863563426175256, training accuracy: 0.9847222222222223\n",
      "epoch: 2, batch: 739,                 loss: 0.051216287636575666, training accuracy: 0.9848817567567567\n",
      "epoch: 2, batch: 759,                 loss: 0.05057555647493389, training accuracy: 0.9851151315789474\n",
      "epoch: 2, batch: 779,                 loss: 0.050902031414592874, training accuracy: 0.985176282051282\n",
      "epoch: 2, batch: 799,                 loss: 0.05060247337387409, training accuracy: 0.985390625\n",
      "epoch: 2, batch: 819,                 loss: 0.05071585045604989, training accuracy: 0.9851371951219512\n",
      "epoch: 2, batch: 839,                 loss: 0.05046855794443261, training accuracy: 0.9852678571428571\n",
      "epoch: 2, batch: 859,                 loss: 0.050282936875145276, training accuracy: 0.9853197674418605\n",
      "epoch: 2, batch: 879,                 loss: 0.049687714456707575, training accuracy: 0.9855823863636364\n",
      "epoch: 2, batch: 899,                 loss: 0.049420772408031756, training accuracy: 0.985625\n",
      "epoch: 2, batch: 919,                 loss: 0.04971312936192945, training accuracy: 0.9854619565217392\n",
      "epoch: 2, batch: 939,                 loss: 0.04919950476788143, training accuracy: 0.9857047872340425\n",
      "epoch: 2, batch: 959,                 loss: 0.04904291138712627, training accuracy: 0.9858072916666667\n",
      "epoch: 2, batch: 979,                 loss: 0.04862603055721871, training accuracy: 0.9860331632653061\n",
      "epoch: 2, batch: 999,                 loss: 0.04847199073759839, training accuracy: 0.9860625\n",
      "epoch: 2, batch: 1019,                 loss: 0.0480937214741739, training accuracy: 0.9861519607843138\n",
      "epoch: 2, batch: 1039,                 loss: 0.047713985700214, training accuracy: 0.9862379807692307\n",
      "epoch: 2, batch: 1059,                 loss: 0.04750851689846659, training accuracy: 0.9862617924528302\n",
      "epoch: 2, batch: 1079,                 loss: 0.04741373724019569, training accuracy: 0.9863425925925926\n",
      "epoch: 2, batch: 1099,                 loss: 0.047579621976156804, training accuracy: 0.98625\n",
      "epoch: 2, batch: 1119,                 loss: 0.04755415030854887, training accuracy: 0.9862723214285715\n",
      "epoch: 2, batch: 1139,                 loss: 0.04701355101761261, training accuracy: 0.9865131578947368\n",
      "epoch: 2, batch: 1159,                 loss: 0.04676349999479436, training accuracy: 0.9865840517241379\n",
      "epoch: 2, batch: 1179,                 loss: 0.046786947381067076, training accuracy: 0.9864936440677966\n",
      "epoch: 2, batch: 1199,                 loss: 0.046637598538848885, training accuracy: 0.9865625\n",
      "epoch: 2, batch: 1219,                 loss: 0.046767579552290016, training accuracy: 0.9864754098360655\n",
      "epoch: 2, batch: 1239,                 loss: 0.046463052164613, training accuracy: 0.9866431451612904\n",
      "epoch: 2, batch: 1259,                 loss: 0.0461950035056188, training accuracy: 0.9867559523809524\n",
      "epoch: 2, batch: 1279,                 loss: 0.04615151237703685, training accuracy: 0.98681640625\n",
      "epoch: 2, batch: 1299,                 loss: 0.045648722844198346, training accuracy: 0.9870192307692308\n",
      "validation accuracy 0.9902\n",
      "test_accuracy 0.5729\n",
      "Saved weights/densenet121-epoch-1-valid_acc=0.9902-test_acc=0.5729.pt\n",
      "epoch: 3, batch: 19,                 loss: 0.033988586906343696, training accuracy: 0.990625\n",
      "epoch: 3, batch: 39,                 loss: 0.03379972316324711, training accuracy: 0.9921875\n",
      "epoch: 3, batch: 59,                 loss: 0.02878261755298202, training accuracy: 0.9947916666666666\n",
      "epoch: 3, batch: 79,                 loss: 0.025692626214004123, training accuracy: 0.99609375\n",
      "epoch: 3, batch: 99,                 loss: 0.02597048582741991, training accuracy: 0.99625\n",
      "epoch: 3, batch: 119,                 loss: 0.026406670643094307, training accuracy: 0.9958333333333333\n",
      "epoch: 3, batch: 139,                 loss: 0.02823602392704093, training accuracy: 0.9946428571428572\n",
      "epoch: 3, batch: 159,                 loss: 0.02801430815452477, training accuracy: 0.99453125\n",
      "epoch: 3, batch: 179,                 loss: 0.028556236997246742, training accuracy: 0.9940972222222222\n",
      "epoch: 3, batch: 199,                 loss: 0.029085270997602494, training accuracy: 0.993125\n",
      "epoch: 3, batch: 219,                 loss: 0.02869582179700956, training accuracy: 0.9931818181818182\n",
      "epoch: 3, batch: 239,                 loss: 0.02741935690670895, training accuracy: 0.9932291666666667\n",
      "epoch: 3, batch: 259,                 loss: 0.027831035238117554, training accuracy: 0.9923076923076923\n",
      "epoch: 3, batch: 279,                 loss: 0.02704101186578295, training accuracy: 0.9926339285714286\n",
      "epoch: 3, batch: 299,                 loss: 0.026593560910938927, training accuracy: 0.9929166666666667\n",
      "epoch: 3, batch: 319,                 loss: 0.02664230785376276, training accuracy: 0.9927734375\n",
      "epoch: 3, batch: 339,                 loss: 0.027012747979503784, training accuracy: 0.9928308823529411\n",
      "epoch: 3, batch: 359,                 loss: 0.026854817551146777, training accuracy: 0.9928819444444444\n",
      "epoch: 3, batch: 379,                 loss: 0.026502136127582114, training accuracy: 0.9925986842105263\n",
      "epoch: 3, batch: 399,                 loss: 0.02659111012064386, training accuracy: 0.9925\n",
      "epoch: 3, batch: 419,                 loss: 0.028282069052857836, training accuracy: 0.9918154761904762\n",
      "epoch: 3, batch: 439,                 loss: 0.028533854049270634, training accuracy: 0.9919034090909091\n",
      "epoch: 3, batch: 459,                 loss: 0.028087780149349862, training accuracy: 0.9919836956521739\n",
      "epoch: 3, batch: 479,                 loss: 0.02845645791142791, training accuracy: 0.991796875\n",
      "epoch: 3, batch: 499,                 loss: 0.02824894121149555, training accuracy: 0.992\n",
      "epoch: 3, batch: 519,                 loss: 0.028957562824227633, training accuracy: 0.9915865384615384\n",
      "epoch: 3, batch: 539,                 loss: 0.02894684244680253, training accuracy: 0.9917824074074074\n",
      "epoch: 3, batch: 559,                 loss: 0.02844313917989244, training accuracy: 0.9919642857142857\n",
      "epoch: 3, batch: 579,                 loss: 0.02892265608413787, training accuracy: 0.9915948275862069\n",
      "epoch: 3, batch: 599,                 loss: 0.02860272706563895, training accuracy: 0.9917708333333334\n",
      "epoch: 3, batch: 619,                 loss: 0.02815473166805121, training accuracy: 0.9920362903225807\n",
      "epoch: 3, batch: 639,                 loss: 0.027887615821964574, training accuracy: 0.9921875\n",
      "epoch: 3, batch: 659,                 loss: 0.027508423198014498, training accuracy: 0.9923295454545454\n",
      "epoch: 3, batch: 679,                 loss: 0.027192735643235637, training accuracy: 0.9924632352941176\n",
      "epoch: 3, batch: 699,                 loss: 0.027064803341137512, training accuracy: 0.9925892857142857\n",
      "epoch: 3, batch: 719,                 loss: 0.026980777533026412, training accuracy: 0.9926215277777778\n",
      "epoch: 3, batch: 739,                 loss: 0.026818724385638898, training accuracy: 0.992652027027027\n",
      "epoch: 3, batch: 759,                 loss: 0.026535320855787418, training accuracy: 0.9926809210526316\n",
      "epoch: 3, batch: 779,                 loss: 0.026593964034989953, training accuracy: 0.9927083333333333\n",
      "epoch: 3, batch: 799,                 loss: 0.026511055734881665, training accuracy: 0.992734375\n",
      "epoch: 3, batch: 819,                 loss: 0.026150092796320322, training accuracy: 0.9928353658536585\n",
      "epoch: 3, batch: 839,                 loss: 0.02602264657256282, training accuracy: 0.9927827380952381\n",
      "epoch: 3, batch: 859,                 loss: 0.025587841395158753, training accuracy: 0.9929505813953489\n",
      "epoch: 3, batch: 879,                 loss: 0.025388693548103965, training accuracy: 0.9930397727272727\n",
      "epoch: 3, batch: 899,                 loss: 0.025377329733326202, training accuracy: 0.9929861111111111\n",
      "epoch: 3, batch: 919,                 loss: 0.025703308149493988, training accuracy: 0.9927989130434782\n",
      "epoch: 3, batch: 939,                 loss: 0.025596555191627207, training accuracy: 0.9928856382978724\n",
      "epoch: 3, batch: 959,                 loss: 0.025820714482930877, training accuracy: 0.9927734375\n",
      "epoch: 3, batch: 979,                 loss: 0.025996397360113964, training accuracy: 0.9926658163265306\n",
      "epoch: 3, batch: 999,                 loss: 0.02584268919448368, training accuracy: 0.99275\n",
      "epoch: 3, batch: 1019,                 loss: 0.0255508555864057, training accuracy: 0.9928921568627451\n",
      "epoch: 3, batch: 1039,                 loss: 0.025655465448261777, training accuracy: 0.9928485576923077\n",
      "epoch: 3, batch: 1059,                 loss: 0.0256647725289749, training accuracy: 0.9928655660377359\n",
      "epoch: 3, batch: 1079,                 loss: 0.02546160713267185, training accuracy: 0.9929398148148149\n",
      "epoch: 3, batch: 1099,                 loss: 0.025201184930470348, training accuracy: 0.9930681818181818\n",
      "epoch: 3, batch: 1119,                 loss: 0.02487346067802199, training accuracy: 0.9931919642857143\n",
      "epoch: 3, batch: 1139,                 loss: 0.02513714225874936, training accuracy: 0.9930372807017543\n",
      "epoch: 3, batch: 1159,                 loss: 0.02524114944600773, training accuracy: 0.9929418103448275\n",
      "epoch: 3, batch: 1179,                 loss: 0.025059811733327646, training accuracy: 0.9930084745762712\n",
      "epoch: 3, batch: 1199,                 loss: 0.02502852475028097, training accuracy: 0.99296875\n",
      "epoch: 3, batch: 1219,                 loss: 0.02485121084676796, training accuracy: 0.9930327868852459\n",
      "epoch: 3, batch: 1239,                 loss: 0.02475124095677353, training accuracy: 0.9930443548387097\n",
      "epoch: 3, batch: 1259,                 loss: 0.024564514748127538, training accuracy: 0.9931051587301587\n",
      "epoch: 3, batch: 1279,                 loss: 0.02452681038166702, training accuracy: 0.9931640625\n",
      "epoch: 3, batch: 1299,                 loss: 0.024521774015693852, training accuracy: 0.9930769230769231\n",
      "validation accuracy 0.983\n",
      "test_accuracy 0.579\n",
      "Saved weights/densenet121-epoch-2-valid_acc=0.983-test_acc=0.579.pt\n",
      "epoch: 4, batch: 19,                 loss: 0.013537297281436622, training accuracy: 0.996875\n",
      "epoch: 4, batch: 39,                 loss: 0.01382753657817375, training accuracy: 0.996875\n",
      "epoch: 4, batch: 59,                 loss: 0.013202254115215813, training accuracy: 0.9979166666666667\n",
      "epoch: 4, batch: 79,                 loss: 0.012689851106551941, training accuracy: 0.99765625\n",
      "epoch: 4, batch: 99,                 loss: 0.011980955376056954, training accuracy: 0.998125\n",
      "epoch: 4, batch: 119,                 loss: 0.011871762795878264, training accuracy: 0.9979166666666667\n",
      "epoch: 4, batch: 139,                 loss: 0.011344968014496512, training accuracy: 0.9982142857142857\n",
      "epoch: 4, batch: 159,                 loss: 0.011588119751104386, training accuracy: 0.9984375\n",
      "epoch: 4, batch: 179,                 loss: 0.012551787281538256, training accuracy: 0.9979166666666667\n",
      "epoch: 4, batch: 199,                 loss: 0.013195763164549134, training accuracy: 0.9975\n",
      "epoch: 4, batch: 219,                 loss: 0.012876120978564193, training accuracy: 0.9977272727272727\n",
      "epoch: 4, batch: 239,                 loss: 0.012419713170190031, training accuracy: 0.9979166666666667\n",
      "epoch: 4, batch: 259,                 loss: 0.01206485946985105, training accuracy: 0.9980769230769231\n",
      "epoch: 4, batch: 279,                 loss: 0.012000093461080854, training accuracy: 0.9982142857142857\n",
      "epoch: 4, batch: 299,                 loss: 0.012032278360178074, training accuracy: 0.9983333333333333\n",
      "epoch: 4, batch: 319,                 loss: 0.012736051710817264, training accuracy: 0.9978515625\n",
      "epoch: 4, batch: 339,                 loss: 0.012403893309152302, training accuracy: 0.9979779411764705\n",
      "epoch: 4, batch: 359,                 loss: 0.012052347296654867, training accuracy: 0.9980902777777778\n",
      "epoch: 4, batch: 379,                 loss: 0.011796023036463578, training accuracy: 0.9981907894736842\n",
      "epoch: 4, batch: 399,                 loss: 0.011573714303958696, training accuracy: 0.99828125\n",
      "epoch: 4, batch: 419,                 loss: 0.012204452399497053, training accuracy: 0.9979166666666667\n",
      "epoch: 4, batch: 439,                 loss: 0.012665595530151305, training accuracy: 0.9973011363636364\n",
      "epoch: 4, batch: 459,                 loss: 0.013014867113214796, training accuracy: 0.9970108695652173\n",
      "epoch: 4, batch: 479,                 loss: 0.012877408249672347, training accuracy: 0.9971354166666667\n",
      "epoch: 4, batch: 499,                 loss: 0.012632702865172178, training accuracy: 0.99725\n",
      "epoch: 4, batch: 519,                 loss: 0.01292798012862197, training accuracy: 0.9971153846153846\n",
      "epoch: 4, batch: 539,                 loss: 0.01262342189762017, training accuracy: 0.9972222222222222\n",
      "epoch: 4, batch: 559,                 loss: 0.013052819165126753, training accuracy: 0.9970982142857143\n",
      "epoch: 4, batch: 579,                 loss: 0.01387237426042075, training accuracy: 0.9969827586206896\n",
      "epoch: 4, batch: 599,                 loss: 0.013705621066619642, training accuracy: 0.9969791666666666\n",
      "epoch: 4, batch: 619,                 loss: 0.013578969128842976, training accuracy: 0.9969758064516129\n",
      "epoch: 4, batch: 639,                 loss: 0.013408502081256301, training accuracy: 0.99697265625\n",
      "epoch: 4, batch: 659,                 loss: 0.01328374735277259, training accuracy: 0.997064393939394\n",
      "epoch: 4, batch: 679,                 loss: 0.013419243465828271, training accuracy: 0.9969669117647059\n",
      "epoch: 4, batch: 699,                 loss: 0.013376349598069543, training accuracy: 0.9969642857142857\n",
      "epoch: 4, batch: 719,                 loss: 0.013167854915405366, training accuracy: 0.9970486111111111\n",
      "epoch: 4, batch: 739,                 loss: 0.013035239144448645, training accuracy: 0.997043918918919\n",
      "epoch: 4, batch: 759,                 loss: 0.013069454705385541, training accuracy: 0.9970394736842105\n",
      "epoch: 4, batch: 779,                 loss: 0.013207167450440092, training accuracy: 0.9969551282051282\n",
      "epoch: 4, batch: 799,                 loss: 0.01316447418081225, training accuracy: 0.996875\n",
      "epoch: 4, batch: 819,                 loss: 0.013531778665634282, training accuracy: 0.996875\n",
      "epoch: 4, batch: 839,                 loss: 0.013533879968980771, training accuracy: 0.996875\n",
      "epoch: 4, batch: 859,                 loss: 0.01349578582841448, training accuracy: 0.9968023255813954\n",
      "epoch: 4, batch: 879,                 loss: 0.01331030385044869, training accuracy: 0.996875\n",
      "epoch: 4, batch: 899,                 loss: 0.013900529793463647, training accuracy: 0.9966666666666667\n",
      "epoch: 4, batch: 919,                 loss: 0.013808278145481145, training accuracy: 0.9967391304347826\n",
      "epoch: 4, batch: 939,                 loss: 0.013715120517658665, training accuracy: 0.9967420212765957\n",
      "epoch: 4, batch: 959,                 loss: 0.013580206698801096, training accuracy: 0.9968098958333333\n",
      "epoch: 4, batch: 979,                 loss: 0.013587917355293104, training accuracy: 0.9968112244897959\n",
      "epoch: 4, batch: 999,                 loss: 0.013708211353630758, training accuracy: 0.99675\n",
      "epoch: 4, batch: 1019,                 loss: 0.013631190816693775, training accuracy: 0.9968137254901961\n",
      "epoch: 4, batch: 1039,                 loss: 0.01357634111448603, training accuracy: 0.9968149038461539\n",
      "epoch: 4, batch: 1059,                 loss: 0.01346535706246834, training accuracy: 0.996875\n",
      "epoch: 4, batch: 1079,                 loss: 0.013367971983906398, training accuracy: 0.996875\n",
      "epoch: 4, batch: 1099,                 loss: 0.013313350813907825, training accuracy: 0.9969318181818182\n",
      "epoch: 4, batch: 1119,                 loss: 0.013155435824800017, training accuracy: 0.9969866071428571\n",
      "epoch: 4, batch: 1139,                 loss: 0.013004080344730858, training accuracy: 0.9970394736842105\n",
      "epoch: 4, batch: 1159,                 loss: 0.012993154980960816, training accuracy: 0.9970366379310345\n",
      "epoch: 4, batch: 1179,                 loss: 0.012866435367249, training accuracy: 0.9970868644067796\n",
      "epoch: 4, batch: 1199,                 loss: 0.01279484893559129, training accuracy: 0.9970833333333333\n",
      "epoch: 4, batch: 1219,                 loss: 0.012722403901632966, training accuracy: 0.9970799180327868\n",
      "epoch: 4, batch: 1239,                 loss: 0.012598167621763422, training accuracy: 0.9971270161290322\n",
      "epoch: 4, batch: 1259,                 loss: 0.012566200546303113, training accuracy: 0.997172619047619\n",
      "epoch: 4, batch: 1279,                 loss: 0.012627533266913816, training accuracy: 0.99716796875\n",
      "epoch: 4, batch: 1299,                 loss: 0.012832744100954956, training accuracy: 0.9970673076923077\n",
      "validation accuracy 0.9932\n",
      "test_accuracy 0.5889\n",
      "Saved weights/densenet121-epoch-3-valid_acc=0.9932-test_acc=0.5889.pt\n",
      "epoch: 5, batch: 19,                 loss: 0.01536566712311469, training accuracy: 0.99375\n",
      "epoch: 5, batch: 39,                 loss: 0.01931735494872555, training accuracy: 0.99375\n",
      "epoch: 5, batch: 59,                 loss: 0.01626219117315486, training accuracy: 0.9947916666666666\n",
      "epoch: 5, batch: 79,                 loss: 0.014463204765343107, training accuracy: 0.9953125\n",
      "epoch: 5, batch: 99,                 loss: 0.015465449003968387, training accuracy: 0.995\n",
      "epoch: 5, batch: 119,                 loss: 0.01386022254882846, training accuracy: 0.9958333333333333\n",
      "epoch: 5, batch: 139,                 loss: 0.0138087334069756, training accuracy: 0.9955357142857143\n",
      "epoch: 5, batch: 159,                 loss: 0.0137645593698835, training accuracy: 0.9953125\n",
      "epoch: 5, batch: 179,                 loss: 0.012792803580588144, training accuracy: 0.9958333333333333\n",
      "epoch: 5, batch: 199,                 loss: 0.012163220087531955, training accuracy: 0.99625\n",
      "epoch: 5, batch: 219,                 loss: 0.012355536066884682, training accuracy: 0.9957386363636364\n",
      "epoch: 5, batch: 239,                 loss: 0.011925105439634839, training accuracy: 0.9958333333333333\n",
      "epoch: 5, batch: 259,                 loss: 0.011934109472741301, training accuracy: 0.9959134615384615\n",
      "epoch: 5, batch: 279,                 loss: 0.011645792943558523, training accuracy: 0.9959821428571428\n",
      "epoch: 5, batch: 299,                 loss: 0.011221538598959645, training accuracy: 0.99625\n",
      "epoch: 5, batch: 319,                 loss: 0.010712199886256712, training accuracy: 0.996484375\n",
      "epoch: 5, batch: 339,                 loss: 0.01043994385879213, training accuracy: 0.9966911764705882\n",
      "epoch: 5, batch: 359,                 loss: 0.01089964981155289, training accuracy: 0.9965277777777778\n",
      "epoch: 5, batch: 379,                 loss: 0.011475797412200145, training accuracy: 0.9965460526315789\n",
      "epoch: 5, batch: 399,                 loss: 0.0114243807089224, training accuracy: 0.9965625\n",
      "epoch: 5, batch: 419,                 loss: 0.011251646164566323, training accuracy: 0.9965773809523809\n",
      "epoch: 5, batch: 439,                 loss: 0.011156736648593903, training accuracy: 0.9965909090909091\n",
      "epoch: 5, batch: 459,                 loss: 0.011096175817479176, training accuracy: 0.9967391304347826\n",
      "epoch: 5, batch: 479,                 loss: 0.01128539338533301, training accuracy: 0.9966145833333333\n",
      "epoch: 5, batch: 499,                 loss: 0.011065180245321243, training accuracy: 0.99675\n",
      "epoch: 5, batch: 519,                 loss: 0.01094248112103042, training accuracy: 0.996875\n",
      "epoch: 5, batch: 539,                 loss: 0.010784770224967764, training accuracy: 0.9969907407407408\n",
      "epoch: 5, batch: 559,                 loss: 0.010523433631065667, training accuracy: 0.9970982142857143\n",
      "epoch: 5, batch: 579,                 loss: 0.010261198446648356, training accuracy: 0.997198275862069\n",
      "epoch: 5, batch: 599,                 loss: 0.010108157257394244, training accuracy: 0.9972916666666667\n",
      "epoch: 5, batch: 619,                 loss: 0.009909929972491228, training accuracy: 0.9973790322580646\n",
      "epoch: 5, batch: 639,                 loss: 0.009801285086268763, training accuracy: 0.99736328125\n",
      "epoch: 5, batch: 659,                 loss: 0.009634475468633217, training accuracy: 0.9974431818181818\n",
      "epoch: 5, batch: 679,                 loss: 0.009967439919059603, training accuracy: 0.9972426470588235\n",
      "epoch: 5, batch: 699,                 loss: 0.00977643388348432, training accuracy: 0.9973214285714286\n",
      "epoch: 5, batch: 719,                 loss: 0.009905111121527928, training accuracy: 0.9972222222222222\n",
      "epoch: 5, batch: 739,                 loss: 0.009806097589112264, training accuracy: 0.9972972972972973\n",
      "epoch: 5, batch: 759,                 loss: 0.00973372505962432, training accuracy: 0.9973684210526316\n",
      "epoch: 5, batch: 779,                 loss: 0.009608069308570777, training accuracy: 0.9974358974358974\n",
      "epoch: 5, batch: 799,                 loss: 0.009456697794448701, training accuracy: 0.9975\n",
      "epoch: 5, batch: 819,                 loss: 0.009505744267002361, training accuracy: 0.9974847560975609\n",
      "epoch: 5, batch: 839,                 loss: 0.009868724093359474, training accuracy: 0.9973214285714286\n",
      "epoch: 5, batch: 859,                 loss: 0.0098793061031164, training accuracy: 0.9973110465116279\n",
      "epoch: 5, batch: 879,                 loss: 0.009760843181852993, training accuracy: 0.997372159090909\n",
      "epoch: 5, batch: 899,                 loss: 0.010575897562278745, training accuracy: 0.9970833333333333\n",
      "epoch: 5, batch: 919,                 loss: 0.010650423021908627, training accuracy: 0.9970108695652173\n",
      "epoch: 5, batch: 939,                 loss: 0.010649285723883758, training accuracy: 0.9970744680851064\n",
      "epoch: 5, batch: 959,                 loss: 0.01057498814425344, training accuracy: 0.9970703125\n",
      "epoch: 5, batch: 979,                 loss: 0.010461556831819043, training accuracy: 0.9971301020408163\n",
      "epoch: 5, batch: 999,                 loss: 0.010432078106852713, training accuracy: 0.997125\n",
      "epoch: 5, batch: 1019,                 loss: 0.010335240072591284, training accuracy: 0.9971813725490196\n",
      "epoch: 5, batch: 1039,                 loss: 0.010208362205930126, training accuracy: 0.997235576923077\n",
      "epoch: 5, batch: 1059,                 loss: 0.010283971150166285, training accuracy: 0.9971698113207547\n",
      "epoch: 5, batch: 1079,                 loss: 0.010196627712651174, training accuracy: 0.9972222222222222\n",
      "epoch: 5, batch: 1099,                 loss: 0.010084823186149483, training accuracy: 0.9972727272727273\n",
      "epoch: 5, batch: 1119,                 loss: 0.010185959442553991, training accuracy: 0.997265625\n",
      "epoch: 5, batch: 1139,                 loss: 0.010148959032621382, training accuracy: 0.9973135964912281\n",
      "epoch: 5, batch: 1159,                 loss: 0.010092004934367965, training accuracy: 0.9973599137931034\n",
      "epoch: 5, batch: 1179,                 loss: 0.009989746916058504, training accuracy: 0.9974046610169491\n",
      "epoch: 5, batch: 1199,                 loss: 0.009944705918848436, training accuracy: 0.9974479166666667\n",
      "epoch: 5, batch: 1219,                 loss: 0.009825867131451664, training accuracy: 0.9974897540983606\n",
      "epoch: 5, batch: 1239,                 loss: 0.009737335856264127, training accuracy: 0.9975302419354839\n",
      "epoch: 5, batch: 1259,                 loss: 0.009678021382627314, training accuracy: 0.9975694444444444\n",
      "epoch: 5, batch: 1279,                 loss: 0.009594751741360596, training accuracy: 0.997607421875\n",
      "epoch: 5, batch: 1299,                 loss: 0.009549092499140757, training accuracy: 0.9976442307692308\n",
      "validation accuracy 0.9928\n",
      "test_accuracy 0.5858\n",
      "Saved weights/densenet121-epoch-4-valid_acc=0.9928-test_acc=0.5858.pt\n",
      "epoch: 6, batch: 19,                 loss: 0.02392992691020481, training accuracy: 0.990625\n",
      "epoch: 6, batch: 39,                 loss: 0.015165611859993077, training accuracy: 0.9953125\n",
      "epoch: 6, batch: 59,                 loss: 0.01204161237886486, training accuracy: 0.996875\n",
      "epoch: 6, batch: 79,                 loss: 0.01658202661201358, training accuracy: 0.9953125\n",
      "epoch: 6, batch: 99,                 loss: 0.014355479393852875, training accuracy: 0.99625\n",
      "epoch: 6, batch: 119,                 loss: 0.012672623974018886, training accuracy: 0.996875\n",
      "epoch: 6, batch: 139,                 loss: 0.011921952303548875, training accuracy: 0.996875\n",
      "epoch: 6, batch: 159,                 loss: 0.01063635824029916, training accuracy: 0.997265625\n",
      "epoch: 6, batch: 179,                 loss: 0.010882833650814265, training accuracy: 0.996875\n",
      "epoch: 6, batch: 199,                 loss: 0.010671532147098333, training accuracy: 0.996875\n",
      "epoch: 6, batch: 219,                 loss: 0.010770245558127169, training accuracy: 0.996875\n",
      "epoch: 6, batch: 239,                 loss: 0.010607361437238675, training accuracy: 0.996875\n",
      "epoch: 6, batch: 259,                 loss: 0.010439669874120648, training accuracy: 0.996875\n",
      "epoch: 6, batch: 279,                 loss: 0.009914071542984208, training accuracy: 0.9970982142857143\n",
      "epoch: 6, batch: 299,                 loss: 0.009531893973471596, training accuracy: 0.9972916666666667\n",
      "epoch: 6, batch: 319,                 loss: 0.009173617506894516, training accuracy: 0.9974609375\n",
      "epoch: 6, batch: 339,                 loss: 0.00883858187315876, training accuracy: 0.997610294117647\n",
      "epoch: 6, batch: 359,                 loss: 0.008577793646933667, training accuracy: 0.9977430555555555\n",
      "epoch: 6, batch: 379,                 loss: 0.008331873372662812, training accuracy: 0.9978618421052632\n",
      "epoch: 6, batch: 399,                 loss: 0.00820463033291162, training accuracy: 0.99796875\n",
      "epoch: 6, batch: 419,                 loss: 0.007909354688100783, training accuracy: 0.9980654761904761\n",
      "epoch: 6, batch: 439,                 loss: 0.007618618416150143, training accuracy: 0.9981534090909091\n",
      "epoch: 6, batch: 459,                 loss: 0.0074808182213809745, training accuracy: 0.9982336956521739\n",
      "epoch: 6, batch: 479,                 loss: 0.007300983071521235, training accuracy: 0.9983072916666667\n",
      "epoch: 6, batch: 499,                 loss: 0.007120156741177198, training accuracy: 0.998375\n",
      "epoch: 6, batch: 519,                 loss: 0.0069563732570364105, training accuracy: 0.9984375\n",
      "epoch: 6, batch: 539,                 loss: 0.006955890090547554, training accuracy: 0.9984953703703704\n",
      "epoch: 6, batch: 559,                 loss: 0.006876918932799267, training accuracy: 0.9985491071428572\n",
      "epoch: 6, batch: 579,                 loss: 0.006752092918132207, training accuracy: 0.9985991379310345\n",
      "epoch: 6, batch: 599,                 loss: 0.006764393244714786, training accuracy: 0.9985416666666667\n",
      "epoch: 6, batch: 619,                 loss: 0.006689962513665969, training accuracy: 0.9985887096774193\n",
      "epoch: 6, batch: 639,                 loss: 0.006629997993968573, training accuracy: 0.9986328125\n",
      "epoch: 6, batch: 659,                 loss: 0.00663157810843338, training accuracy: 0.9986742424242424\n",
      "epoch: 6, batch: 679,                 loss: 0.006565942060842644, training accuracy: 0.9987132352941176\n",
      "epoch: 6, batch: 699,                 loss: 0.006481233884904733, training accuracy: 0.99875\n",
      "epoch: 6, batch: 719,                 loss: 0.006502589644555377, training accuracy: 0.9986979166666666\n",
      "epoch: 6, batch: 739,                 loss: 0.006581125664249427, training accuracy: 0.9986486486486487\n",
      "epoch: 6, batch: 759,                 loss: 0.00648735335298146, training accuracy: 0.9986842105263158\n",
      "epoch: 6, batch: 779,                 loss: 0.006477080541177808, training accuracy: 0.9986378205128205\n",
      "epoch: 6, batch: 799,                 loss: 0.006389302056923043, training accuracy: 0.998671875\n",
      "epoch: 6, batch: 819,                 loss: 0.006291091286189707, training accuracy: 0.9987042682926829\n",
      "epoch: 6, batch: 839,                 loss: 0.006187065317048802, training accuracy: 0.998735119047619\n",
      "epoch: 6, batch: 859,                 loss: 0.00613332277432566, training accuracy: 0.998764534883721\n",
      "epoch: 6, batch: 879,                 loss: 0.006119221906026889, training accuracy: 0.9987926136363636\n",
      "epoch: 6, batch: 899,                 loss: 0.006172527761696579, training accuracy: 0.99875\n",
      "epoch: 6, batch: 919,                 loss: 0.00618950854202368, training accuracy: 0.9987092391304347\n",
      "epoch: 6, batch: 939,                 loss: 0.0061687174104860035, training accuracy: 0.9986702127659575\n",
      "epoch: 6, batch: 959,                 loss: 0.006095553314874754, training accuracy: 0.9986979166666666\n",
      "epoch: 6, batch: 979,                 loss: 0.006033635788480751, training accuracy: 0.9987244897959183\n",
      "epoch: 6, batch: 999,                 loss: 0.005965247255924623, training accuracy: 0.99875\n",
      "epoch: 6, batch: 1019,                 loss: 0.0061209613108646815, training accuracy: 0.9986519607843137\n",
      "epoch: 6, batch: 1039,                 loss: 0.006057081953202634, training accuracy: 0.9986778846153846\n",
      "epoch: 6, batch: 1059,                 loss: 0.0060985623071143705, training accuracy: 0.9986438679245283\n",
      "epoch: 6, batch: 1079,                 loss: 0.0060551188575455285, training accuracy: 0.9986689814814815\n",
      "epoch: 6, batch: 1099,                 loss: 0.006135448180747599, training accuracy: 0.9986363636363637\n",
      "epoch: 6, batch: 1119,                 loss: 0.006405325056506886, training accuracy: 0.9986049107142857\n",
      "epoch: 6, batch: 1139,                 loss: 0.0063414382700820605, training accuracy: 0.9986293859649122\n",
      "epoch: 6, batch: 1159,                 loss: 0.0063083250821489795, training accuracy: 0.9985991379310345\n",
      "epoch: 6, batch: 1179,                 loss: 0.006284142032012115, training accuracy: 0.9986228813559322\n",
      "epoch: 6, batch: 1199,                 loss: 0.0062234851788040635, training accuracy: 0.9986458333333333\n",
      "epoch: 6, batch: 1219,                 loss: 0.006174793843987215, training accuracy: 0.9986680327868852\n",
      "epoch: 6, batch: 1239,                 loss: 0.006096652726409957, training accuracy: 0.9986895161290322\n",
      "epoch: 6, batch: 1259,                 loss: 0.0060393856000339995, training accuracy: 0.9987103174603175\n",
      "epoch: 6, batch: 1279,                 loss: 0.006141630852607704, training accuracy: 0.9986328125\n",
      "epoch: 6, batch: 1299,                 loss: 0.006154927324924547, training accuracy: 0.9986057692307693\n",
      "validation accuracy 0.9936\n",
      "test_accuracy 0.584\n",
      "Saved weights/densenet121-epoch-5-valid_acc=0.9936-test_acc=0.584.pt\n",
      "Finished Training: densenet121\n",
      "epoch: 1, batch: 19,                 loss: 0.6393337666988372, training accuracy: 0.68125\n",
      "epoch: 1, batch: 39,                 loss: 0.6017806336283684, training accuracy: 0.7375\n",
      "epoch: 1, batch: 59,                 loss: 0.5715278158585231, training accuracy: 0.7697916666666667\n",
      "epoch: 1, batch: 79,                 loss: 0.5460142310708761, training accuracy: 0.78671875\n",
      "epoch: 1, batch: 99,                 loss: 0.5226942014694214, training accuracy: 0.80625\n",
      "epoch: 1, batch: 119,                 loss: 0.4940251967559258, training accuracy: 0.8229166666666666\n",
      "epoch: 1, batch: 139,                 loss: 0.47144758371370177, training accuracy: 0.8361607142857143\n",
      "epoch: 1, batch: 159,                 loss: 0.4484592051245272, training accuracy: 0.848046875\n",
      "epoch: 1, batch: 179,                 loss: 0.4275351457297802, training accuracy: 0.8583333333333333\n",
      "epoch: 1, batch: 199,                 loss: 0.40790831930935384, training accuracy: 0.8665625\n",
      "epoch: 1, batch: 219,                 loss: 0.3915563242001967, training accuracy: 0.8727272727272727\n",
      "epoch: 1, batch: 239,                 loss: 0.37751664500683546, training accuracy: 0.8778645833333333\n",
      "epoch: 1, batch: 259,                 loss: 0.36485555544495585, training accuracy: 0.8819711538461539\n",
      "epoch: 1, batch: 279,                 loss: 0.35276809672691994, training accuracy: 0.8861607142857143\n",
      "epoch: 1, batch: 299,                 loss: 0.3418156852821509, training accuracy: 0.8895833333333333\n",
      "epoch: 1, batch: 319,                 loss: 0.3298733190749772, training accuracy: 0.894140625\n",
      "epoch: 1, batch: 339,                 loss: 0.32077914064421376, training accuracy: 0.897610294117647\n",
      "epoch: 1, batch: 359,                 loss: 0.3116597638672425, training accuracy: 0.9005208333333333\n",
      "epoch: 1, batch: 379,                 loss: 0.30349109737496627, training accuracy: 0.9029605263157895\n",
      "epoch: 1, batch: 399,                 loss: 0.2965637749992311, training accuracy: 0.9046875\n",
      "epoch: 1, batch: 419,                 loss: 0.2907472372764633, training accuracy: 0.906547619047619\n",
      "epoch: 1, batch: 439,                 loss: 0.2838667855005373, training accuracy: 0.9080965909090909\n",
      "epoch: 1, batch: 459,                 loss: 0.27677940440404675, training accuracy: 0.9103260869565217\n",
      "epoch: 1, batch: 479,                 loss: 0.2703016416324923, training accuracy: 0.9126302083333333\n",
      "epoch: 1, batch: 499,                 loss: 0.26402605885267255, training accuracy: 0.915\n",
      "epoch: 1, batch: 519,                 loss: 0.2606891416443082, training accuracy: 0.9157451923076924\n",
      "epoch: 1, batch: 539,                 loss: 0.25573611633369214, training accuracy: 0.9171296296296296\n",
      "epoch: 1, batch: 559,                 loss: 0.2514175289177469, training accuracy: 0.9184151785714286\n",
      "epoch: 1, batch: 579,                 loss: 0.2464439837358378, training accuracy: 0.9202586206896551\n",
      "epoch: 1, batch: 599,                 loss: 0.24276288718916475, training accuracy: 0.9213541666666667\n",
      "epoch: 1, batch: 619,                 loss: 0.23840461341784366, training accuracy: 0.9227822580645161\n",
      "epoch: 1, batch: 639,                 loss: 0.23433220682491082, training accuracy: 0.9240234375\n",
      "epoch: 1, batch: 659,                 loss: 0.2305156667745023, training accuracy: 0.9250946969696969\n",
      "epoch: 1, batch: 679,                 loss: 0.22691555356552057, training accuracy: 0.9261948529411764\n",
      "epoch: 1, batch: 699,                 loss: 0.224066280182451, training accuracy: 0.9267857142857143\n",
      "epoch: 1, batch: 719,                 loss: 0.22073480388046138, training accuracy: 0.9279513888888888\n",
      "epoch: 1, batch: 739,                 loss: 0.21830063483400924, training accuracy: 0.9283783783783783\n",
      "epoch: 1, batch: 759,                 loss: 0.2149188158371927, training accuracy: 0.9294407894736842\n",
      "epoch: 1, batch: 779,                 loss: 0.211217125514761, training accuracy: 0.9307692307692308\n",
      "epoch: 1, batch: 799,                 loss: 0.20768823816208168, training accuracy: 0.932109375\n",
      "epoch: 1, batch: 819,                 loss: 0.2050621992999279, training accuracy: 0.9327743902439024\n",
      "epoch: 1, batch: 839,                 loss: 0.20235208241889874, training accuracy: 0.9337053571428572\n",
      "epoch: 1, batch: 859,                 loss: 0.19900092330739594, training accuracy: 0.9348837209302325\n",
      "epoch: 1, batch: 879,                 loss: 0.1962447786671956, training accuracy: 0.9357244318181818\n",
      "epoch: 1, batch: 899,                 loss: 0.1935287001170218, training accuracy: 0.9366666666666666\n",
      "epoch: 1, batch: 919,                 loss: 0.1910048789931866, training accuracy: 0.9375\n",
      "epoch: 1, batch: 939,                 loss: 0.18928047562057668, training accuracy: 0.9377659574468085\n",
      "epoch: 1, batch: 959,                 loss: 0.18690291332701842, training accuracy: 0.938671875\n",
      "epoch: 1, batch: 979,                 loss: 0.18554557785962006, training accuracy: 0.9391581632653061\n",
      "epoch: 1, batch: 999,                 loss: 0.18318004574626684, training accuracy: 0.9399375\n",
      "epoch: 1, batch: 1019,                 loss: 0.18051892460287347, training accuracy: 0.9409313725490196\n",
      "epoch: 1, batch: 1039,                 loss: 0.17839204141905962, training accuracy: 0.9417668269230769\n",
      "epoch: 1, batch: 1059,                 loss: 0.17707571887657186, training accuracy: 0.9422759433962264\n",
      "epoch: 1, batch: 1079,                 loss: 0.17505535480773282, training accuracy: 0.9431712962962963\n",
      "epoch: 1, batch: 1099,                 loss: 0.17361940053206953, training accuracy: 0.9436363636363636\n",
      "epoch: 1, batch: 1119,                 loss: 0.17196651530934365, training accuracy: 0.9440290178571429\n",
      "epoch: 1, batch: 1139,                 loss: 0.17059340439410065, training accuracy: 0.9444627192982457\n",
      "epoch: 1, batch: 1159,                 loss: 0.16898256223247354, training accuracy: 0.9450431034482759\n",
      "epoch: 1, batch: 1179,                 loss: 0.1677866002367178, training accuracy: 0.9455508474576271\n",
      "epoch: 1, batch: 1199,                 loss: 0.165865385310802, training accuracy: 0.9463020833333333\n",
      "epoch: 1, batch: 1219,                 loss: 0.16429183226933733, training accuracy: 0.9468237704918033\n",
      "epoch: 1, batch: 1239,                 loss: 0.1625257547388995, training accuracy: 0.9472782258064516\n",
      "epoch: 1, batch: 1259,                 loss: 0.1611033889975044, training accuracy: 0.9477182539682539\n",
      "epoch: 1, batch: 1279,                 loss: 0.16043136184089235, training accuracy: 0.947802734375\n",
      "epoch: 1, batch: 1299,                 loss: 0.15943370691285683, training accuracy: 0.948173076923077\n",
      "validation accuracy 0.9736\n",
      "test_accuracy 0.5851\n",
      "Saved weights/mobilenet-epoch-0-valid_acc=0.9736-test_acc=0.5851.pt\n",
      "epoch: 2, batch: 19,                 loss: 0.04916715265717357, training accuracy: 0.984375\n",
      "epoch: 2, batch: 39,                 loss: 0.05346122722839937, training accuracy: 0.98125\n",
      "epoch: 2, batch: 59,                 loss: 0.06173548811736206, training accuracy: 0.9791666666666666\n",
      "epoch: 2, batch: 79,                 loss: 0.07244463620008901, training accuracy: 0.97578125\n",
      "epoch: 2, batch: 99,                 loss: 0.07060109056532383, training accuracy: 0.975625\n",
      "epoch: 2, batch: 119,                 loss: 0.0691324215537558, training accuracy: 0.9744791666666667\n",
      "epoch: 2, batch: 139,                 loss: 0.06733889056901847, training accuracy: 0.9758928571428571\n",
      "epoch: 2, batch: 159,                 loss: 0.06526141174836084, training accuracy: 0.976953125\n",
      "epoch: 2, batch: 179,                 loss: 0.06555754504580465, training accuracy: 0.9777777777777777\n",
      "epoch: 2, batch: 199,                 loss: 0.06826797380344943, training accuracy: 0.9775\n",
      "epoch: 2, batch: 219,                 loss: 0.07135116861371155, training accuracy: 0.9764204545454546\n",
      "epoch: 2, batch: 239,                 loss: 0.07064233601558953, training accuracy: 0.9765625\n",
      "epoch: 2, batch: 259,                 loss: 0.07350012786471499, training accuracy: 0.9752403846153846\n",
      "epoch: 2, batch: 279,                 loss: 0.07269361666736326, training accuracy: 0.9758928571428571\n",
      "epoch: 2, batch: 299,                 loss: 0.07137665625661611, training accuracy: 0.9760416666666667\n",
      "epoch: 2, batch: 319,                 loss: 0.07003187822556356, training accuracy: 0.9765625\n",
      "epoch: 2, batch: 339,                 loss: 0.06894981406272992, training accuracy: 0.9770220588235294\n",
      "epoch: 2, batch: 359,                 loss: 0.06880106376354686, training accuracy: 0.9767361111111111\n",
      "epoch: 2, batch: 379,                 loss: 0.06819988423345709, training accuracy: 0.9773026315789474\n",
      "epoch: 2, batch: 399,                 loss: 0.06887969259289094, training accuracy: 0.97734375\n",
      "epoch: 2, batch: 419,                 loss: 0.06866183307221425, training accuracy: 0.9773809523809524\n",
      "epoch: 2, batch: 439,                 loss: 0.06737885628297756, training accuracy: 0.977840909090909\n",
      "epoch: 2, batch: 459,                 loss: 0.06649015115310802, training accuracy: 0.978125\n",
      "epoch: 2, batch: 479,                 loss: 0.06535503063544941, training accuracy: 0.9783854166666667\n",
      "epoch: 2, batch: 499,                 loss: 0.06455272604804486, training accuracy: 0.9785\n",
      "epoch: 2, batch: 519,                 loss: 0.06392573232744606, training accuracy: 0.9789663461538461\n",
      "epoch: 2, batch: 539,                 loss: 0.06274930762678936, training accuracy: 0.9792824074074075\n",
      "epoch: 2, batch: 559,                 loss: 0.062481390191741024, training accuracy: 0.9792410714285714\n",
      "epoch: 2, batch: 579,                 loss: 0.062246137616577844, training accuracy: 0.9790948275862069\n",
      "epoch: 2, batch: 599,                 loss: 0.061875293526488045, training accuracy: 0.9789583333333334\n",
      "epoch: 2, batch: 619,                 loss: 0.06149684381145503, training accuracy: 0.9790322580645161\n",
      "epoch: 2, batch: 639,                 loss: 0.061173979458544636, training accuracy: 0.979296875\n",
      "epoch: 2, batch: 659,                 loss: 0.061174977110755265, training accuracy: 0.9793560606060606\n",
      "epoch: 2, batch: 679,                 loss: 0.06097173693500842, training accuracy: 0.9793198529411765\n",
      "epoch: 2, batch: 699,                 loss: 0.06069651969808287, training accuracy: 0.9794642857142857\n",
      "epoch: 2, batch: 719,                 loss: 0.06098272824989787, training accuracy: 0.9795138888888889\n",
      "epoch: 2, batch: 739,                 loss: 0.06156377186589698, training accuracy: 0.9793074324324325\n",
      "epoch: 2, batch: 759,                 loss: 0.06144156523912802, training accuracy: 0.9794407894736842\n",
      "epoch: 2, batch: 779,                 loss: 0.06139228252831321, training accuracy: 0.9794070512820513\n",
      "epoch: 2, batch: 799,                 loss: 0.06165340991312405, training accuracy: 0.97921875\n",
      "epoch: 2, batch: 819,                 loss: 0.061560353686431105, training accuracy: 0.9791920731707318\n",
      "epoch: 2, batch: 839,                 loss: 0.06131541837045613, training accuracy: 0.9792410714285714\n",
      "epoch: 2, batch: 859,                 loss: 0.06104731436921717, training accuracy: 0.979360465116279\n",
      "epoch: 2, batch: 879,                 loss: 0.06072140637737572, training accuracy: 0.9794034090909091\n",
      "epoch: 2, batch: 899,                 loss: 0.060110398165415975, training accuracy: 0.9796527777777778\n",
      "epoch: 2, batch: 919,                 loss: 0.059678308657907034, training accuracy: 0.9796195652173914\n",
      "epoch: 2, batch: 939,                 loss: 0.05993970306714046, training accuracy: 0.9793882978723404\n",
      "epoch: 2, batch: 959,                 loss: 0.060565734190216367, training accuracy: 0.9792317708333333\n",
      "epoch: 2, batch: 979,                 loss: 0.06053174714467545, training accuracy: 0.9792729591836735\n",
      "epoch: 2, batch: 999,                 loss: 0.06005426445440389, training accuracy: 0.9794375\n",
      "epoch: 2, batch: 1019,                 loss: 0.06024409740063015, training accuracy: 0.9794117647058823\n",
      "epoch: 2, batch: 1039,                 loss: 0.05961603006222643, training accuracy: 0.9797475961538461\n",
      "epoch: 2, batch: 1059,                 loss: 0.059866794120116196, training accuracy: 0.9794811320754717\n",
      "epoch: 2, batch: 1079,                 loss: 0.05922088581352943, training accuracy: 0.9796875\n",
      "epoch: 2, batch: 1099,                 loss: 0.05904510844202543, training accuracy: 0.9797727272727272\n",
      "epoch: 2, batch: 1119,                 loss: 0.05903031988501815, training accuracy: 0.9797991071428571\n",
      "epoch: 2, batch: 1139,                 loss: 0.05848528037292948, training accuracy: 0.9799890350877193\n",
      "epoch: 2, batch: 1159,                 loss: 0.058321759321100626, training accuracy: 0.9801185344827587\n",
      "epoch: 2, batch: 1179,                 loss: 0.05791086577159211, training accuracy: 0.9801906779661017\n",
      "epoch: 2, batch: 1199,                 loss: 0.05753993093133128, training accuracy: 0.9804166666666667\n",
      "epoch: 2, batch: 1219,                 loss: 0.05733737525030146, training accuracy: 0.980327868852459\n",
      "epoch: 2, batch: 1239,                 loss: 0.056998755517152826, training accuracy: 0.9805443548387097\n",
      "epoch: 2, batch: 1259,                 loss: 0.05674205420276387, training accuracy: 0.9806051587301587\n",
      "epoch: 2, batch: 1279,                 loss: 0.05670595162800964, training accuracy: 0.9806640625\n",
      "epoch: 2, batch: 1299,                 loss: 0.05656554405604346, training accuracy: 0.9807211538461539\n",
      "validation accuracy 0.9838\n",
      "test_accuracy 0.5875\n",
      "Saved weights/mobilenet-epoch-1-valid_acc=0.9838-test_acc=0.5875.pt\n",
      "epoch: 3, batch: 19,                 loss: 0.03662453537108377, training accuracy: 0.9875\n",
      "epoch: 3, batch: 39,                 loss: 0.0323685017589014, training accuracy: 0.9890625\n",
      "epoch: 3, batch: 59,                 loss: 0.030396194519319884, training accuracy: 0.990625\n",
      "epoch: 3, batch: 79,                 loss: 0.03742759529268369, training accuracy: 0.98671875\n",
      "epoch: 3, batch: 99,                 loss: 0.037456735029118136, training accuracy: 0.985\n",
      "epoch: 3, batch: 119,                 loss: 0.033981433183847304, training accuracy: 0.9875\n",
      "epoch: 3, batch: 139,                 loss: 0.035023053634878516, training accuracy: 0.9875\n",
      "epoch: 3, batch: 159,                 loss: 0.03406731596114696, training accuracy: 0.98828125\n",
      "epoch: 3, batch: 179,                 loss: 0.031824692017269424, training accuracy: 0.9895833333333334\n",
      "epoch: 3, batch: 199,                 loss: 0.033590336326160465, training accuracy: 0.989375\n",
      "epoch: 3, batch: 219,                 loss: 0.03288976636725816, training accuracy: 0.9897727272727272\n",
      "epoch: 3, batch: 239,                 loss: 0.03489311375742545, training accuracy: 0.9890625\n",
      "epoch: 3, batch: 259,                 loss: 0.03687187125772023, training accuracy: 0.9887019230769231\n",
      "epoch: 3, batch: 279,                 loss: 0.03655302217230201, training accuracy: 0.9886160714285714\n",
      "epoch: 3, batch: 299,                 loss: 0.03610707884111131, training accuracy: 0.98875\n",
      "epoch: 3, batch: 319,                 loss: 0.03559938789840089, training accuracy: 0.9890625\n",
      "epoch: 3, batch: 339,                 loss: 0.03593461692045607, training accuracy: 0.9889705882352942\n",
      "epoch: 3, batch: 359,                 loss: 0.03630903906111295, training accuracy: 0.9890625\n",
      "epoch: 3, batch: 379,                 loss: 0.03959119472174758, training accuracy: 0.9886513157894737\n",
      "epoch: 3, batch: 399,                 loss: 0.03911807546042837, training accuracy: 0.98875\n",
      "epoch: 3, batch: 419,                 loss: 0.038364931520274176, training accuracy: 0.9889880952380953\n",
      "epoch: 3, batch: 439,                 loss: 0.03843752150900069, training accuracy: 0.9889204545454545\n",
      "epoch: 3, batch: 459,                 loss: 0.03820978095603135, training accuracy: 0.9889945652173913\n",
      "epoch: 3, batch: 479,                 loss: 0.03823465686533988, training accuracy: 0.9888020833333333\n",
      "epoch: 3, batch: 499,                 loss: 0.038801880191545936, training accuracy: 0.988625\n",
      "epoch: 3, batch: 519,                 loss: 0.03823223837512509, training accuracy: 0.9888221153846154\n",
      "epoch: 3, batch: 539,                 loss: 0.039401719897890604, training accuracy: 0.9884259259259259\n",
      "epoch: 3, batch: 559,                 loss: 0.03845905053208948, training accuracy: 0.9888392857142857\n",
      "epoch: 3, batch: 579,                 loss: 0.038673383048293986, training accuracy: 0.9886853448275862\n",
      "epoch: 3, batch: 599,                 loss: 0.03866325780341867, training accuracy: 0.98875\n",
      "epoch: 3, batch: 619,                 loss: 0.03804540676872186, training accuracy: 0.9889112903225806\n",
      "epoch: 3, batch: 639,                 loss: 0.0374267780347509, training accuracy: 0.9892578125\n",
      "epoch: 3, batch: 659,                 loss: 0.03745257368639365, training accuracy: 0.9890151515151515\n",
      "epoch: 3, batch: 679,                 loss: 0.03762950010594282, training accuracy: 0.9887867647058823\n",
      "epoch: 3, batch: 699,                 loss: 0.037224878144417224, training accuracy: 0.9890178571428572\n",
      "epoch: 3, batch: 719,                 loss: 0.03738907013919541, training accuracy: 0.9889756944444444\n",
      "epoch: 3, batch: 739,                 loss: 0.036944881760722935, training accuracy: 0.9891891891891892\n",
      "epoch: 3, batch: 759,                 loss: 0.03746750824272902, training accuracy: 0.9888157894736842\n",
      "epoch: 3, batch: 779,                 loss: 0.037255531321996105, training accuracy: 0.9887820512820513\n",
      "epoch: 3, batch: 799,                 loss: 0.03714045771630481, training accuracy: 0.98875\n",
      "epoch: 3, batch: 819,                 loss: 0.03812991315953252, training accuracy: 0.9883384146341463\n",
      "epoch: 3, batch: 839,                 loss: 0.03760172637384607, training accuracy: 0.9885416666666667\n",
      "epoch: 3, batch: 859,                 loss: 0.03735648252565392, training accuracy: 0.9886627906976744\n",
      "epoch: 3, batch: 879,                 loss: 0.03748655087269567, training accuracy: 0.9887073863636363\n",
      "epoch: 3, batch: 899,                 loss: 0.0369875832032671, training accuracy: 0.9888194444444445\n",
      "epoch: 3, batch: 919,                 loss: 0.03779615968498705, training accuracy: 0.9885190217391304\n",
      "epoch: 3, batch: 939,                 loss: 0.03794713052636151, training accuracy: 0.9883643617021277\n",
      "epoch: 3, batch: 959,                 loss: 0.037662167090335666, training accuracy: 0.9884765625\n",
      "epoch: 3, batch: 979,                 loss: 0.038243588190454494, training accuracy: 0.9880102040816326\n",
      "epoch: 3, batch: 999,                 loss: 0.037988786891219206, training accuracy: 0.9880625\n",
      "epoch: 3, batch: 1019,                 loss: 0.037743966905947994, training accuracy: 0.9881740196078431\n",
      "epoch: 3, batch: 1039,                 loss: 0.03816703844685645, training accuracy: 0.9879807692307693\n",
      "epoch: 3, batch: 1059,                 loss: 0.03780012794019092, training accuracy: 0.9881485849056604\n",
      "epoch: 3, batch: 1079,                 loss: 0.03760435985966103, training accuracy: 0.9881365740740741\n",
      "epoch: 3, batch: 1099,                 loss: 0.03712791968877851, training accuracy: 0.9883522727272728\n",
      "epoch: 3, batch: 1119,                 loss: 0.03747548262077284, training accuracy: 0.9881696428571428\n",
      "epoch: 3, batch: 1139,                 loss: 0.037946887015724524, training accuracy: 0.9879934210526315\n",
      "epoch: 3, batch: 1159,                 loss: 0.03798535170730059, training accuracy: 0.9879310344827587\n",
      "epoch: 3, batch: 1179,                 loss: 0.0379405845538713, training accuracy: 0.9878707627118644\n",
      "epoch: 3, batch: 1199,                 loss: 0.03779219726255784, training accuracy: 0.9879166666666667\n",
      "epoch: 3, batch: 1219,                 loss: 0.03772296876528255, training accuracy: 0.987858606557377\n",
      "epoch: 3, batch: 1239,                 loss: 0.03743994664250603, training accuracy: 0.9880040322580645\n",
      "epoch: 3, batch: 1259,                 loss: 0.03715268480369732, training accuracy: 0.9880952380952381\n",
      "epoch: 3, batch: 1279,                 loss: 0.03677666477115053, training accuracy: 0.988232421875\n",
      "epoch: 3, batch: 1299,                 loss: 0.03679852460931915, training accuracy: 0.9882211538461538\n",
      "validation accuracy 0.9881\n",
      "test_accuracy 0.5953\n",
      "Saved weights/mobilenet-epoch-2-valid_acc=0.9881-test_acc=0.5953.pt\n",
      "epoch: 4, batch: 19,                 loss: 0.013713648327393458, training accuracy: 0.996875\n",
      "epoch: 4, batch: 39,                 loss: 0.01695883846259676, training accuracy: 0.99375\n",
      "epoch: 4, batch: 59,                 loss: 0.02242323809574979, training accuracy: 0.9916666666666667\n",
      "epoch: 4, batch: 79,                 loss: 0.02232034152984852, training accuracy: 0.9921875\n",
      "epoch: 4, batch: 99,                 loss: 0.024510556230088697, training accuracy: 0.9925\n",
      "epoch: 4, batch: 119,                 loss: 0.024788310558263523, training accuracy: 0.9927083333333333\n",
      "epoch: 4, batch: 139,                 loss: 0.02734381378312329, training accuracy: 0.990625\n",
      "epoch: 4, batch: 159,                 loss: 0.025581314226292305, training accuracy: 0.99140625\n",
      "epoch: 4, batch: 179,                 loss: 0.02550031996603745, training accuracy: 0.9916666666666667\n",
      "epoch: 4, batch: 199,                 loss: 0.024106817288266028, training accuracy: 0.9921875\n",
      "epoch: 4, batch: 219,                 loss: 0.025384305249000053, training accuracy: 0.9920454545454546\n",
      "epoch: 4, batch: 239,                 loss: 0.024580372101384758, training accuracy: 0.9921875\n",
      "epoch: 4, batch: 259,                 loss: 0.02457121533605879, training accuracy: 0.9923076923076923\n",
      "epoch: 4, batch: 279,                 loss: 0.024962969144897734, training accuracy: 0.9921875\n",
      "epoch: 4, batch: 299,                 loss: 0.024963364793802612, training accuracy: 0.9920833333333333\n",
      "epoch: 4, batch: 319,                 loss: 0.024117036785355594, training accuracy: 0.992578125\n",
      "epoch: 4, batch: 339,                 loss: 0.023436518375905616, training accuracy: 0.993014705882353\n",
      "epoch: 4, batch: 359,                 loss: 0.024147998512004658, training accuracy: 0.9928819444444444\n",
      "epoch: 4, batch: 379,                 loss: 0.024187853270191944, training accuracy: 0.9927631578947368\n",
      "epoch: 4, batch: 399,                 loss: 0.025389762858249013, training accuracy: 0.99203125\n",
      "epoch: 4, batch: 419,                 loss: 0.025051982598961332, training accuracy: 0.9921130952380952\n",
      "epoch: 4, batch: 439,                 loss: 0.02575892991907577, training accuracy: 0.9917613636363637\n",
      "epoch: 4, batch: 459,                 loss: 0.025082495628284168, training accuracy: 0.9919836956521739\n",
      "epoch: 4, batch: 479,                 loss: 0.02523062768535359, training accuracy: 0.9920572916666667\n",
      "epoch: 4, batch: 499,                 loss: 0.025511988367768936, training accuracy: 0.991875\n",
      "epoch: 4, batch: 519,                 loss: 0.026038474979689523, training accuracy: 0.9914663461538461\n",
      "epoch: 4, batch: 539,                 loss: 0.02586046648136323, training accuracy: 0.9916666666666667\n",
      "epoch: 4, batch: 559,                 loss: 0.026033642059545465, training accuracy: 0.9915178571428571\n",
      "epoch: 4, batch: 579,                 loss: 0.026244134739430717, training accuracy: 0.9915948275862069\n",
      "epoch: 4, batch: 599,                 loss: 0.025879574755381326, training accuracy: 0.9916666666666667\n",
      "epoch: 4, batch: 619,                 loss: 0.026132478377304882, training accuracy: 0.991633064516129\n",
      "epoch: 4, batch: 639,                 loss: 0.026290535476346123, training accuracy: 0.99150390625\n",
      "epoch: 4, batch: 659,                 loss: 0.02613266386509746, training accuracy: 0.9915719696969697\n",
      "epoch: 4, batch: 679,                 loss: 0.026136444413414745, training accuracy: 0.9916360294117647\n",
      "epoch: 4, batch: 699,                 loss: 0.026171017827748853, training accuracy: 0.9916964285714286\n",
      "epoch: 4, batch: 719,                 loss: 0.02614786455968796, training accuracy: 0.9916666666666667\n",
      "epoch: 4, batch: 739,                 loss: 0.02575226391160647, training accuracy: 0.9918074324324324\n",
      "epoch: 4, batch: 759,                 loss: 0.025406226478164744, training accuracy: 0.9919407894736842\n",
      "epoch: 4, batch: 779,                 loss: 0.02546125468297993, training accuracy: 0.9919070512820513\n",
      "epoch: 4, batch: 799,                 loss: 0.025870219446442206, training accuracy: 0.991796875\n",
      "epoch: 4, batch: 819,                 loss: 0.026141925893579155, training accuracy: 0.9916158536585366\n",
      "epoch: 4, batch: 839,                 loss: 0.02677318096560027, training accuracy: 0.9914434523809523\n",
      "epoch: 4, batch: 859,                 loss: 0.02738494845756958, training accuracy: 0.9913517441860465\n",
      "epoch: 4, batch: 879,                 loss: 0.027041944707955488, training accuracy: 0.99140625\n",
      "epoch: 4, batch: 899,                 loss: 0.027172323021546214, training accuracy: 0.9913888888888889\n",
      "epoch: 4, batch: 919,                 loss: 0.026853450420932623, training accuracy: 0.9915081521739131\n",
      "epoch: 4, batch: 939,                 loss: 0.026646839305225937, training accuracy: 0.9916223404255319\n",
      "epoch: 4, batch: 959,                 loss: 0.026488543679867384, training accuracy: 0.9917317708333333\n",
      "epoch: 4, batch: 979,                 loss: 0.026410652934609227, training accuracy: 0.9917091836734694\n",
      "epoch: 4, batch: 999,                 loss: 0.026318973524088504, training accuracy: 0.991625\n",
      "epoch: 4, batch: 1019,                 loss: 0.026023800149913786, training accuracy: 0.9917892156862745\n",
      "epoch: 4, batch: 1039,                 loss: 0.025849913579105096, training accuracy: 0.9918870192307693\n",
      "epoch: 4, batch: 1059,                 loss: 0.025832955982757925, training accuracy: 0.9919221698113208\n",
      "epoch: 4, batch: 1079,                 loss: 0.02549879134150817, training accuracy: 0.9920717592592593\n",
      "epoch: 4, batch: 1099,                 loss: 0.025173233519361186, training accuracy: 0.9922159090909091\n",
      "epoch: 4, batch: 1119,                 loss: 0.025212918875383496, training accuracy: 0.9921316964285715\n",
      "epoch: 4, batch: 1139,                 loss: 0.025162830510587236, training accuracy: 0.9921052631578947\n",
      "epoch: 4, batch: 1159,                 loss: 0.024939599301282655, training accuracy: 0.9921875\n",
      "epoch: 4, batch: 1179,                 loss: 0.02495169689068847, training accuracy: 0.9921610169491526\n",
      "epoch: 4, batch: 1199,                 loss: 0.02480934486486755, training accuracy: 0.9921875\n",
      "epoch: 4, batch: 1219,                 loss: 0.0246958415230572, training accuracy: 0.9922131147540983\n",
      "epoch: 4, batch: 1239,                 loss: 0.024683687175838128, training accuracy: 0.9922379032258064\n",
      "epoch: 4, batch: 1259,                 loss: 0.025104874470234212, training accuracy: 0.9921626984126984\n",
      "epoch: 4, batch: 1279,                 loss: 0.02480755585129373, training accuracy: 0.99228515625\n",
      "epoch: 4, batch: 1299,                 loss: 0.02458940253055726, training accuracy: 0.9924038461538461\n",
      "validation accuracy 0.9872\n",
      "test_accuracy 0.5899\n",
      "Saved weights/mobilenet-epoch-3-valid_acc=0.9872-test_acc=0.5899.pt\n",
      "epoch: 5, batch: 19,                 loss: 0.025929305038880558, training accuracy: 0.99375\n",
      "epoch: 5, batch: 39,                 loss: 0.017901496292324737, training accuracy: 0.996875\n",
      "epoch: 5, batch: 59,                 loss: 0.01531865174571673, training accuracy: 0.996875\n",
      "epoch: 5, batch: 79,                 loss: 0.01412725790287368, training accuracy: 0.996875\n",
      "epoch: 5, batch: 99,                 loss: 0.020712646811734885, training accuracy: 0.994375\n",
      "epoch: 5, batch: 119,                 loss: 0.020843333073329025, training accuracy: 0.9942708333333333\n",
      "epoch: 5, batch: 139,                 loss: 0.01945650336108104, training accuracy: 0.9946428571428572\n",
      "epoch: 5, batch: 159,                 loss: 0.01960239576546883, training accuracy: 0.99453125\n",
      "epoch: 5, batch: 179,                 loss: 0.019678689178868405, training accuracy: 0.9940972222222222\n",
      "epoch: 5, batch: 199,                 loss: 0.020247478951059748, training accuracy: 0.9940625\n",
      "epoch: 5, batch: 219,                 loss: 0.019108786281536925, training accuracy: 0.9943181818181818\n",
      "epoch: 5, batch: 239,                 loss: 0.017984214112220797, training accuracy: 0.9947916666666666\n",
      "epoch: 5, batch: 259,                 loss: 0.018352570626302623, training accuracy: 0.9944711538461538\n",
      "epoch: 5, batch: 279,                 loss: 0.01888390563815067, training accuracy: 0.99375\n",
      "epoch: 5, batch: 299,                 loss: 0.019422634653941107, training accuracy: 0.99375\n",
      "epoch: 5, batch: 319,                 loss: 0.018939197201143544, training accuracy: 0.9939453125\n",
      "epoch: 5, batch: 339,                 loss: 0.018328807155793422, training accuracy: 0.9943014705882353\n",
      "epoch: 5, batch: 359,                 loss: 0.01778364997557623, training accuracy: 0.9946180555555556\n",
      "epoch: 5, batch: 379,                 loss: 0.01867179286690723, training accuracy: 0.9942434210526315\n",
      "epoch: 5, batch: 399,                 loss: 0.018061322829744313, training accuracy: 0.99453125\n",
      "epoch: 5, batch: 419,                 loss: 0.018034608779375308, training accuracy: 0.9944940476190476\n",
      "epoch: 5, batch: 439,                 loss: 0.018043993106799792, training accuracy: 0.9944602272727273\n",
      "epoch: 5, batch: 459,                 loss: 0.018623784309728882, training accuracy: 0.9944293478260869\n",
      "epoch: 5, batch: 479,                 loss: 0.01845729282188889, training accuracy: 0.99453125\n",
      "epoch: 5, batch: 499,                 loss: 0.018606675858376547, training accuracy: 0.994375\n",
      "epoch: 5, batch: 519,                 loss: 0.018514553958196373, training accuracy: 0.9943509615384616\n",
      "epoch: 5, batch: 539,                 loss: 0.01879295672535793, training accuracy: 0.9942129629629629\n",
      "epoch: 5, batch: 559,                 loss: 0.019132366083691264, training accuracy: 0.9943080357142857\n",
      "epoch: 5, batch: 579,                 loss: 0.01899937388721998, training accuracy: 0.9942887931034483\n",
      "epoch: 5, batch: 599,                 loss: 0.01913221005127222, training accuracy: 0.994375\n",
      "epoch: 5, batch: 619,                 loss: 0.018924288067125504, training accuracy: 0.9944556451612904\n",
      "epoch: 5, batch: 639,                 loss: 0.018887026838456222, training accuracy: 0.99443359375\n",
      "epoch: 5, batch: 659,                 loss: 0.01934747987631426, training accuracy: 0.9943181818181818\n",
      "epoch: 5, batch: 679,                 loss: 0.01916899201768341, training accuracy: 0.9943933823529412\n",
      "epoch: 5, batch: 699,                 loss: 0.019134972775853906, training accuracy: 0.9942857142857143\n",
      "epoch: 5, batch: 719,                 loss: 0.019134181830951193, training accuracy: 0.9942708333333333\n",
      "epoch: 5, batch: 739,                 loss: 0.01926891088329973, training accuracy: 0.9942567567567567\n",
      "epoch: 5, batch: 759,                 loss: 0.01961960193584673, training accuracy: 0.9941611842105263\n",
      "epoch: 5, batch: 779,                 loss: 0.01943800690619705, training accuracy: 0.994150641025641\n",
      "epoch: 5, batch: 799,                 loss: 0.019465325047058286, training accuracy: 0.99421875\n",
      "epoch: 5, batch: 819,                 loss: 0.01949363207989713, training accuracy: 0.9941310975609756\n",
      "epoch: 5, batch: 839,                 loss: 0.01943220595033684, training accuracy: 0.9941964285714285\n",
      "epoch: 5, batch: 859,                 loss: 0.01980679072331377, training accuracy: 0.9941133720930233\n",
      "epoch: 5, batch: 879,                 loss: 0.019618068988678385, training accuracy: 0.9941761363636363\n",
      "epoch: 5, batch: 899,                 loss: 0.019964801002707748, training accuracy: 0.9940277777777777\n",
      "epoch: 5, batch: 919,                 loss: 0.019706407482052504, training accuracy: 0.9941576086956522\n",
      "epoch: 5, batch: 939,                 loss: 0.019771253136283858, training accuracy: 0.9940824468085107\n",
      "epoch: 5, batch: 959,                 loss: 0.019670344514088355, training accuracy: 0.9940755208333333\n",
      "epoch: 5, batch: 979,                 loss: 0.019556913662901413, training accuracy: 0.9941326530612244\n",
      "epoch: 5, batch: 999,                 loss: 0.019397557180025615, training accuracy: 0.9941875\n",
      "epoch: 5, batch: 1019,                 loss: 0.019133871396051664, training accuracy: 0.9943014705882353\n",
      "epoch: 5, batch: 1039,                 loss: 0.019067759961595026, training accuracy: 0.9942908653846154\n",
      "epoch: 5, batch: 1059,                 loss: 0.01899445416171868, training accuracy: 0.9943396226415094\n",
      "epoch: 5, batch: 1079,                 loss: 0.01878526994114509, training accuracy: 0.994386574074074\n",
      "epoch: 5, batch: 1099,                 loss: 0.01858879449134375, training accuracy: 0.9944886363636364\n",
      "epoch: 5, batch: 1119,                 loss: 0.018381086545066084, training accuracy: 0.9945870535714286\n",
      "epoch: 5, batch: 1139,                 loss: 0.018427987097943275, training accuracy: 0.9945175438596491\n",
      "epoch: 5, batch: 1159,                 loss: 0.018377763559817985, training accuracy: 0.9944504310344827\n",
      "epoch: 5, batch: 1179,                 loss: 0.0182148268178719, training accuracy: 0.9944915254237288\n",
      "epoch: 5, batch: 1199,                 loss: 0.018041026567007065, training accuracy: 0.9945833333333334\n",
      "epoch: 5, batch: 1219,                 loss: 0.018306263309610497, training accuracy: 0.9944672131147541\n",
      "epoch: 5, batch: 1239,                 loss: 0.018226660334532366, training accuracy: 0.9944556451612904\n",
      "epoch: 5, batch: 1259,                 loss: 0.018019341100686384, training accuracy: 0.9945436507936508\n",
      "epoch: 5, batch: 1279,                 loss: 0.018001821960820053, training accuracy: 0.99453125\n",
      "epoch: 5, batch: 1299,                 loss: 0.017911979004252666, training accuracy: 0.9945673076923077\n",
      "validation accuracy 0.9902\n",
      "test_accuracy 0.6025\n",
      "Saved weights/mobilenet-epoch-4-valid_acc=0.9902-test_acc=0.6025.pt\n",
      "epoch: 6, batch: 19,                 loss: 0.009286816089297645, training accuracy: 0.996875\n",
      "epoch: 6, batch: 39,                 loss: 0.018796517093142028, training accuracy: 0.9921875\n",
      "epoch: 6, batch: 59,                 loss: 0.018698139968910253, training accuracy: 0.99375\n",
      "epoch: 6, batch: 79,                 loss: 0.01774226042361988, training accuracy: 0.9953125\n",
      "epoch: 6, batch: 99,                 loss: 0.016836445623484905, training accuracy: 0.995\n",
      "epoch: 6, batch: 119,                 loss: 0.015392481249728007, training accuracy: 0.9958333333333333\n",
      "epoch: 6, batch: 139,                 loss: 0.014579398062986521, training accuracy: 0.9964285714285714\n",
      "epoch: 6, batch: 159,                 loss: 0.013207774187867472, training accuracy: 0.996875\n",
      "epoch: 6, batch: 179,                 loss: 0.015484117718006018, training accuracy: 0.9954861111111111\n",
      "epoch: 6, batch: 199,                 loss: 0.014705476335511775, training accuracy: 0.995625\n",
      "epoch: 6, batch: 219,                 loss: 0.013844402521631723, training accuracy: 0.9957386363636364\n",
      "epoch: 6, batch: 239,                 loss: 0.013678332201743615, training accuracy: 0.9958333333333333\n",
      "epoch: 6, batch: 259,                 loss: 0.013598492883633857, training accuracy: 0.9959134615384615\n",
      "epoch: 6, batch: 279,                 loss: 0.013008252635959902, training accuracy: 0.9962053571428572\n",
      "epoch: 6, batch: 299,                 loss: 0.013241375979074897, training accuracy: 0.9958333333333333\n",
      "epoch: 6, batch: 319,                 loss: 0.013628158892424835, training accuracy: 0.9955078125\n",
      "epoch: 6, batch: 339,                 loss: 0.014026688607854713, training accuracy: 0.9954044117647058\n",
      "epoch: 6, batch: 359,                 loss: 0.014204743673649824, training accuracy: 0.9949652777777778\n",
      "epoch: 6, batch: 379,                 loss: 0.014031208717374523, training accuracy: 0.9950657894736842\n",
      "epoch: 6, batch: 399,                 loss: 0.013989457749557914, training accuracy: 0.99515625\n",
      "epoch: 6, batch: 419,                 loss: 0.014619206972981504, training accuracy: 0.9944940476190476\n",
      "epoch: 6, batch: 439,                 loss: 0.014239977386717907, training accuracy: 0.9947443181818182\n",
      "epoch: 6, batch: 459,                 loss: 0.014369781684976973, training accuracy: 0.9947010869565217\n",
      "epoch: 6, batch: 479,                 loss: 0.014250210744194192, training accuracy: 0.9947916666666666\n",
      "epoch: 6, batch: 499,                 loss: 0.013845001793146365, training accuracy: 0.995\n",
      "epoch: 6, batch: 519,                 loss: 0.014072245983725924, training accuracy: 0.994951923076923\n",
      "epoch: 6, batch: 539,                 loss: 0.013678869476926694, training accuracy: 0.9951388888888889\n",
      "epoch: 6, batch: 559,                 loss: 0.013638921279640013, training accuracy: 0.9952008928571429\n",
      "epoch: 6, batch: 579,                 loss: 0.013308570122748718, training accuracy: 0.9953663793103448\n",
      "epoch: 6, batch: 599,                 loss: 0.013014413910204893, training accuracy: 0.9955208333333333\n",
      "epoch: 6, batch: 619,                 loss: 0.012871383869670324, training accuracy: 0.9955645161290323\n",
      "epoch: 6, batch: 639,                 loss: 0.0127917117874631, training accuracy: 0.99560546875\n",
      "epoch: 6, batch: 659,                 loss: 0.01291393303851664, training accuracy: 0.9955492424242425\n",
      "epoch: 6, batch: 679,                 loss: 0.012864464910393615, training accuracy: 0.9955882352941177\n",
      "epoch: 6, batch: 699,                 loss: 0.012870231465473938, training accuracy: 0.995625\n",
      "epoch: 6, batch: 719,                 loss: 0.012707293370981965, training accuracy: 0.9957465277777777\n",
      "epoch: 6, batch: 739,                 loss: 0.01293858050880403, training accuracy: 0.9956925675675675\n",
      "epoch: 6, batch: 759,                 loss: 0.01290421781444533, training accuracy: 0.9956414473684211\n",
      "epoch: 6, batch: 779,                 loss: 0.012805682864769224, training accuracy: 0.9956730769230769\n",
      "epoch: 6, batch: 799,                 loss: 0.012691517931107227, training accuracy: 0.995703125\n",
      "epoch: 6, batch: 819,                 loss: 0.012915576372324721, training accuracy: 0.995579268292683\n",
      "epoch: 6, batch: 839,                 loss: 0.012892833398048727, training accuracy: 0.9955357142857143\n",
      "epoch: 6, batch: 859,                 loss: 0.012851683507476484, training accuracy: 0.9955668604651163\n",
      "epoch: 6, batch: 879,                 loss: 0.012912560689222698, training accuracy: 0.9955965909090909\n",
      "epoch: 6, batch: 899,                 loss: 0.012853272117160183, training accuracy: 0.995625\n",
      "epoch: 6, batch: 919,                 loss: 0.012915793770425017, training accuracy: 0.9956521739130435\n",
      "epoch: 6, batch: 939,                 loss: 0.012781471193460327, training accuracy: 0.9957446808510638\n",
      "epoch: 6, batch: 959,                 loss: 0.012787751589166873, training accuracy: 0.9957682291666666\n",
      "epoch: 6, batch: 979,                 loss: 0.012731147293721287, training accuracy: 0.9957908163265307\n",
      "epoch: 6, batch: 999,                 loss: 0.01272089696265175, training accuracy: 0.9958125\n",
      "epoch: 6, batch: 1019,                 loss: 0.012705347839886706, training accuracy: 0.9958333333333333\n",
      "epoch: 6, batch: 1039,                 loss: 0.012783550902307839, training accuracy: 0.9957932692307693\n",
      "epoch: 6, batch: 1059,                 loss: 0.01266340592306081, training accuracy: 0.995872641509434\n",
      "epoch: 6, batch: 1079,                 loss: 0.013085554498441827, training accuracy: 0.9957175925925926\n",
      "epoch: 6, batch: 1099,                 loss: 0.013003427315720314, training accuracy: 0.9957954545454546\n",
      "epoch: 6, batch: 1119,                 loss: 0.01295674906881946, training accuracy: 0.9958147321428571\n",
      "epoch: 6, batch: 1139,                 loss: 0.012873587564242546, training accuracy: 0.9958333333333333\n",
      "epoch: 6, batch: 1159,                 loss: 0.01301893249012586, training accuracy: 0.9957435344827587\n",
      "epoch: 6, batch: 1179,                 loss: 0.0129148254880728, training accuracy: 0.9958156779661017\n",
      "epoch: 6, batch: 1199,                 loss: 0.012950485397207862, training accuracy: 0.99578125\n",
      "epoch: 6, batch: 1219,                 loss: 0.01288560325173436, training accuracy: 0.9958504098360655\n",
      "epoch: 6, batch: 1239,                 loss: 0.012938329044564236, training accuracy: 0.9958165322580645\n",
      "epoch: 6, batch: 1259,                 loss: 0.013352060036009385, training accuracy: 0.9956845238095238\n",
      "epoch: 6, batch: 1279,                 loss: 0.013604712170126732, training accuracy: 0.995556640625\n",
      "epoch: 6, batch: 1299,                 loss: 0.013665808092247551, training accuracy: 0.9955288461538462\n",
      "validation accuracy 0.9915\n",
      "test_accuracy 0.6045\n",
      "Saved weights/mobilenet-epoch-5-valid_acc=0.9915-test_acc=0.6045.pt\n",
      "Finished Training: mobilenet\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "device = torch.device(\"cuda:0\")\n",
    "is_validating = True\n",
    "is_testing = True\n",
    "\n",
    "history = {\n",
    "    'train_samples': [],\n",
    "    'train_acc': [],\n",
    "    'valid_acc': [],\n",
    "    'test_acc': [],\n",
    "    'loss': []\n",
    "}\n",
    "\n",
    "for b in BACKBONES:\n",
    "\n",
    "    import torch.optim as optim\n",
    "\n",
    "    m = Model(backbone=b)\n",
    "    m = m.to(device)\n",
    "\n",
    "    criterion = torch.nn.BCELoss()\n",
    "    optimizer = optim.Adam(m.parameters(), lr=1e-5, weight_decay=1e-5)\n",
    "\n",
    "    for epoch in range(6):  # epochs\n",
    "\n",
    "        running_loss = []\n",
    "        running_acc = []\n",
    "\n",
    "        # epoch training\n",
    "        for i, data in enumerate(train):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            inputs = data[0].to(device)\n",
    "            labels = data[1].to(device)\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = m(inputs)\n",
    "            loss = criterion(outputs[:,0], labels.type_as(outputs[:,0]))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            acc = accuracy(outputs, labels)\n",
    "            # print statistics\n",
    "            \n",
    "            running_loss.append(loss.item())\n",
    "            running_acc.append(acc)\n",
    "\n",
    "\n",
    "            if i%20 == 19:\n",
    "                print(f'epoch: {epoch+1}, batch: {i}, \\\n",
    "                loss: {np.mean(running_loss)}, training accuracy: {np.mean(running_acc)}')\n",
    "                \n",
    "                history['loss'].append(np.mean(running_loss))\n",
    "                history['train_samples'].append(epoch*len(train)+i)\n",
    "                history['train_acc'].append(np.mean(running_acc))\n",
    "        \n",
    "        # on epoch end:\n",
    "        if is_validating:\n",
    "            valid_acc = []\n",
    "            # epoch validation\n",
    "            for i, data in enumerate(valid):\n",
    "                # get the inputs; data is a list of [inputs, labels]\n",
    "                inputs = data[0].to(device)\n",
    "                labels = data[1].to(device)\n",
    "\n",
    "                # could pehaps do:\n",
    "                # for param in m.parameters():\n",
    "                #     param.requires_grad = False\n",
    "\n",
    "                outputs = m(inputs)\n",
    "                valid_acc.append(accuracy(outputs, labels))\n",
    "            va = round(np.mean(valid_acc), 4)\n",
    "            print(f'validation accuracy {va}')\n",
    "            history['valid_acc'].append(va)\n",
    "        else:\n",
    "            va='-1'\n",
    "            \n",
    "        if is_testing:\n",
    "            test_acc = []\n",
    "            # epoch validation\n",
    "            for i, data in enumerate(test):\n",
    "                # get the inputs; data is a list of [inputs, labels]\n",
    "                inputs = data[0].to(device)\n",
    "                labels = data[1].to(device)\n",
    "\n",
    "                # could pehaps do:\n",
    "                # for param in m.parameters():\n",
    "                #     param.requires_grad = False\n",
    "\n",
    "                outputs = m(inputs)\n",
    "                test_acc.append(accuracy(outputs, labels))\n",
    "            tst = round(np.mean(test_acc), 4)\n",
    "            print(f'test_accuracy {tst}')\n",
    "            history['test_acc'].append(tst)\n",
    "        else:\n",
    "            tst = '-1'\n",
    "            \n",
    "        fname =  f'weights/{b}-epoch-{epoch}-valid_acc={va}-test_acc={tst}.pt'\n",
    "        print(f'Saved {fname}')\n",
    "        torch.save(m, fname)\n",
    "        \n",
    "\n",
    "    print(f'Finished Training: {b}')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "train-pytorch",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
