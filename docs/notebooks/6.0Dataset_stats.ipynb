{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "from datasets.afd import make_afd_loaders\n",
    "from datasets.dunnings import make_dunnings_test_loader, make_dunnings_train_loader\n",
    "from models import FireClassifier\n",
    "from utils import accuracy_gpu\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 10\n",
    "PRINT_EVERY = 20  # batches\n",
    "\n",
    "dataset_paths = {\n",
    "    \"mine\": \"~/pro/fire_aerial2k_dataset/\",\n",
    "    \"dunnings_train\": \"/media/tomek/BIG2/datasets/FIRE/dunnings/fire-dataset-dunnings/images-224x224/train\",\n",
    "    \"dunnings_test\": \"/media/tomek/BIG2/datasets/FIRE/dunnings/fire-dataset-dunnings/images-224x224/test\",\n",
    "}\n",
    "\n",
    "afd_train, afd_val = make_afd_loaders(dataset_paths[\"mine\"], batch_size=BATCH_SIZE)\n",
    "\n",
    "dunnings_train = make_dunnings_train_loader(\n",
    "    dataset_paths[\"dunnings_train\"], batch_size=BATCH_SIZE\n",
    ")\n",
    "\n",
    "dunnings_test = make_dunnings_test_loader(\n",
    "    dataset_paths[\"dunnings_test\"], batch_size=BATCH_SIZE\n",
    ")\n",
    "\n",
    "\n",
    "train_afd = afd_train\n",
    "train_dunnings = dunnings_train\n",
    "valid = afd_val\n",
    "test = dunnings_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_sum = torch.zeros((3, 224, 224))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in afd_train:\n",
    "    img_batch = data[0]\n",
    "    for im in img_batch:        \n",
    "        img_sum += im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in dunnings_train:\n",
    "    img_batch = data[0]\n",
    "    for im in img_batch:        \n",
    "        img_sum += im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_num = len(dunnings_train)*32 + len(afd_train)*32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.4005, 0.3702, 0.3419])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_mean = torch.mean(img_sum,axis=[1,2])/img_num\n",
    "t_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Std devs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 1, 1])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_mean = t_mean[(..., ) + (None, ) * 2] # add two dimensions\n",
    "t_mean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_sq_sum = torch.zeros(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in afd_train:\n",
    "    img_batch = data[0]\n",
    "    for im in img_batch:        \n",
    "        avg_sq_sum += torch.mean(torch.pow(im - t_mean, 2), axis=[1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in dunnings_train:\n",
    "    img_batch = data[0]\n",
    "    for im in img_batch:        \n",
    "        avg_sq_sum += torch.mean(torch.pow(im - t_mean, 2), axis=[1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.2858, 0.2749, 0.2742])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stdev = torch.sqrt(avg_sq_sum / img_num)\n",
    "stdev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.bar(range(3), height=[0.485, 0.456, 0.406])\n",
    "plt.bar(range(3), height=[0.4005, 0.3702, 0.3419])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (224) must match the size of tensor b (3) at non-singleton dimension 2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-60-cf809111fdaf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mim\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.4005\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.3702\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.3419\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (224) must match the size of tensor b (3) at non-singleton dimension 2"
     ]
    }
   ],
   "source": [
    "im - torch.unsqueeze(torch.tensor([0.4005, 0.3702, 0.3419]), dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in afd_train:\n",
    "    img_batch = data[0]\n",
    "    for im in img_batch:        \n",
    "        img_sum += im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Std dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([113.0427, 111.2521, 106.3413])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mean(img_sum,axis=[1,2])/1824 * 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 224, 224])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_sum.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0].max()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
